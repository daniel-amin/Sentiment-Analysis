{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Importing and creating train features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "4PJ8MohpF1Ht"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import glob\n",
    "import os\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "mKHimIdaF1Hy",
    "outputId": "ace05c3c-6a8d-4ec0-8db9-6e016f161f7c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3533945</th>\n",
       "      <td>usability and programming history: This was a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302956</th>\n",
       "      <td>This case is pretty good: Fits gameboy with Pe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3086621</th>\n",
       "      <td>Bones Reds are awesome!: I got these today, an...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946241</th>\n",
       "      <td>This cd rocks hard: i love this cd i can turn ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803661</th>\n",
       "      <td>Too tough: Since I really loved Buffalo Bill's...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  label\n",
       "3533945  usability and programming history: This was a ...      1\n",
       "302956   This case is pretty good: Fits gameboy with Pe...      2\n",
       "3086621  Bones Reds are awesome!: I got these today, an...      2\n",
       "946241   This cd rocks hard: i love this cd i can turn ...      2\n",
       "2803661  Too tough: Since I really loved Buffalo Bill's...      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load training file\n",
    "\n",
    "text_file = open(\"train.txt.txt\", \"r\", encoding=\"utf8\")\n",
    "lines = text_file.read().split('\\n')\n",
    "\n",
    "labels = []\n",
    "for item in lines:\n",
    "    first_four_letters = item[:10]\n",
    "    if first_four_letters == '__label__1':\n",
    "        labels.append(int(1))\n",
    "    else:\n",
    "        labels.append(int(2))\n",
    "        \n",
    "def remove_label(s):\n",
    "    return s[11:]\n",
    "lines = [remove_label(s) for s in lines]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['text'] = lines\n",
    "df['label'] = labels\n",
    "\n",
    "df = df.sample(160000)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "zUTpz7RZF1H1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Clean text\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "#lowercase and remove punctuation, remove stopwords        \n",
    "df['text'] = df['text'].str.lower()\n",
    "df['text'] = df['text'].str.replace('-', ' ')\n",
    "df['text'] = df['text'].str.split(' ')\n",
    "df['text'] = df['text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].apply(lemmatize_text)\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].str.replace('\\\\', ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "v716GFtjF1H4"
   },
   "outputs": [],
   "source": [
    "#Train Word2Vec\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "text = [row.split() for row in df['text']]\n",
    "model_w2v = Word2Vec(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "DeO9W1afF1H6"
   },
   "outputs": [],
   "source": [
    "model_w2v.save('model_w2v.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "okwCWi8WF1H8",
    "outputId": "9de3534a-ed71-436e-8977-6e81c611e796",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c09b3d994294dd185873d8640ad3e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=160000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Average Word2Vec Vectors for BOW\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "text_vec = []\n",
    "text_avg_vec = []\n",
    "count = 0\n",
    "for row in tqdm(range(len(text))):\n",
    "    [word.split(' ', 1) for word in text[row]]\n",
    "  \n",
    "    for i in range(len(text[row])):\n",
    "        try:\n",
    "            text_vec.append(model_w2v[text[row][i]])\n",
    "            count = count + 1\n",
    "        except KeyError as e:\n",
    "            text_vec.append([0]*100)\n",
    "  \n",
    "    average = np.add.reduce(text_vec)\n",
    "    if count==0:\n",
    "        count = 1\n",
    "    average = np.divide(average, count)\n",
    "    text_avg_vec.append(average)\n",
    "    text_vec = []\n",
    "    count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "TEdesJclF1H_"
   },
   "outputs": [],
   "source": [
    "for i in range(len(text_avg_vec)):\n",
    "    if type(text_avg_vec[i]) != np.ndarray:\n",
    "        text_avg_vec[i] = np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.39594962e-02, -3.52297321e-01,  1.82629284e-01,  3.50403552e-02,\n",
       "       -3.42428980e-01,  2.96911069e-01,  3.62364998e-01, -1.40412820e-01,\n",
       "       -2.38565522e-01, -9.53779967e-02, -7.59008595e-02,  2.46695624e-03,\n",
       "       -5.98871699e-02, -3.29450190e-01, -1.35016516e-01, -1.41912155e-01,\n",
       "        2.55528346e-02,  3.11567659e-01, -2.08746480e-01,  1.05372929e-01,\n",
       "        1.42134485e-01, -1.61325655e-01,  9.18009292e-03,  1.58887904e-01,\n",
       "        4.95492782e-01,  1.53667141e-01, -3.70266686e-01,  3.57450015e-01,\n",
       "        1.26190499e-01, -3.48605867e-01, -2.21555804e-01, -1.99812797e-01,\n",
       "        1.80274532e-01,  6.28552006e-01, -1.89942103e-01,  4.37229785e-01,\n",
       "        8.32161781e-02, -1.19431146e-01, -7.16513588e-01, -2.51545378e-01,\n",
       "        4.79025925e-01, -2.21111028e-01, -3.15386977e-04,  2.27327358e-01,\n",
       "       -2.21959181e-01,  1.63623010e-01,  3.95685532e-01, -1.00819586e-01,\n",
       "       -7.88121291e-01,  2.45670173e-01,  1.90602971e-01, -2.31535771e-01,\n",
       "        1.95498465e-02,  2.78641509e-01, -2.68808424e-01, -3.51242900e-01,\n",
       "        1.43664316e-01, -6.45426322e-02, -1.05346115e-01, -2.13707259e-01,\n",
       "       -4.93179110e-01,  5.45761407e-01, -3.95184836e-02,  6.14716917e-01,\n",
       "        4.98392846e-01, -8.38584994e-02,  1.72957985e-02,  1.01551840e-02,\n",
       "       -3.36202965e-01, -9.72444355e-02, -2.09879129e-01,  4.76688023e-02,\n",
       "       -6.35518118e-02,  1.63608013e-01, -6.34592576e-01, -1.81351315e-01,\n",
       "        1.42840338e-01, -3.24894987e-01,  1.48662650e-01,  1.41430050e-01,\n",
       "        2.35694252e-02, -3.75426125e-02, -2.15812878e-02,  3.00980815e-01,\n",
       "        4.41569802e-01,  1.31976961e-03, -2.14450536e-02,  6.87228511e-02,\n",
       "       -4.32921296e-01,  7.22569106e-02, -3.50352505e-01, -4.59975488e-02,\n",
       "       -4.43963241e-01,  2.77739142e-01,  1.86955277e-01,  1.59111585e-01,\n",
       "       -9.26943380e-02, -1.47805802e-01, -3.89637413e-01, -2.83125362e-01])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_avg_vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "LEbtDl_-F1IC",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "x_train = text_avg_vec\n",
    "#x_train = np.c_[x_train]\n",
    "\n",
    "df['label'] = df['label'] - 1\n",
    "\n",
    "y_train= np.asarray(df.label)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=40000, random_state=42)\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "VYOMPOgOF1IE",
    "outputId": "8d45e2c8-90f8-4889-827f-fb462dd3b2ab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Training\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "lr = LogisticRegression().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "6fJCW9CRF1IH"
   },
   "outputs": [],
   "source": [
    "#Naive Bayes Training\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "3i2eWSaLF1IJ",
    "outputId": "291db352-78e8-4a8b-f9ae-a6fceb9d7601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 32)                3232      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 16,993\n",
      "Trainable params: 16,417\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n",
      "Train on 96000 samples, validate on 24000 samples\n",
      "Epoch 1/100\n",
      "95808/96000 [============================>.] - ETA: 0s - loss: 0.4178 - accuracy: 0.8113\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.84704, saving model to NN.model\n",
      "INFO:tensorflow:Assets written to: NN.model/assets\n",
      "96000/96000 [==============================] - 22s 234us/sample - loss: 0.4179 - accuracy: 0.8113 - val_loss: 0.3487 - val_accuracy: 0.8470\n",
      "Epoch 2/100\n",
      "95808/96000 [============================>.] - ETA: 0s - loss: 0.3712 - accuracy: 0.8367\n",
      "Epoch 00002: val_accuracy improved from 0.84704 to 0.85250, saving model to NN.model\n",
      "INFO:tensorflow:Assets written to: NN.model/assets\n",
      "96000/96000 [==============================] - 19s 200us/sample - loss: 0.3711 - accuracy: 0.8367 - val_loss: 0.3367 - val_accuracy: 0.8525\n",
      "Epoch 3/100\n",
      "95808/96000 [============================>.] - ETA: 0s - loss: 0.3660 - accuracy: 0.8386\n",
      "Epoch 00003: val_accuracy did not improve from 0.85250\n",
      "96000/96000 [==============================] - 17s 181us/sample - loss: 0.3658 - accuracy: 0.8387 - val_loss: 0.3490 - val_accuracy: 0.8465\n",
      "Epoch 4/100\n",
      "95776/96000 [============================>.] - ETA: 0s - loss: 0.3609 - accuracy: 0.8422\n",
      "Epoch 00004: val_accuracy improved from 0.85250 to 0.85404, saving model to NN.model\n",
      "INFO:tensorflow:Assets written to: NN.model/assets\n",
      "96000/96000 [==============================] - 20s 210us/sample - loss: 0.3610 - accuracy: 0.8422 - val_loss: 0.3390 - val_accuracy: 0.8540\n",
      "Epoch 5/100\n",
      "95936/96000 [============================>.] - ETA: 0s - loss: 0.3566 - accuracy: 0.8435\n",
      "Epoch 00005: val_accuracy did not improve from 0.85404\n",
      "96000/96000 [==============================] - 17s 175us/sample - loss: 0.3565 - accuracy: 0.8435 - val_loss: 0.3439 - val_accuracy: 0.8518\n",
      "Epoch 6/100\n",
      "95776/96000 [============================>.] - ETA: 0s - loss: 0.3557 - accuracy: 0.8434\n",
      "Epoch 00006: val_accuracy did not improve from 0.85404\n",
      "96000/96000 [==============================] - 17s 175us/sample - loss: 0.3557 - accuracy: 0.8434 - val_loss: 0.3387 - val_accuracy: 0.8507\n",
      "Epoch 7/100\n",
      "95744/96000 [============================>.] - ETA: 0s - loss: 0.3525 - accuracy: 0.8455\n",
      "Epoch 00007: val_accuracy improved from 0.85404 to 0.85425, saving model to NN.model\n",
      "INFO:tensorflow:Assets written to: NN.model/assets\n",
      "96000/96000 [==============================] - 19s 198us/sample - loss: 0.3524 - accuracy: 0.8455 - val_loss: 0.3297 - val_accuracy: 0.8543\n",
      "Epoch 8/100\n",
      "95808/96000 [============================>.] - ETA: 0s - loss: 0.3514 - accuracy: 0.8475\n",
      "Epoch 00008: val_accuracy improved from 0.85425 to 0.85617, saving model to NN.model\n",
      "INFO:tensorflow:Assets written to: NN.model/assets\n",
      "96000/96000 [==============================] - 19s 203us/sample - loss: 0.3514 - accuracy: 0.8475 - val_loss: 0.3311 - val_accuracy: 0.8562\n",
      "Epoch 9/100\n",
      "95936/96000 [============================>.] - ETA: 0s - loss: 0.3494 - accuracy: 0.8476\n",
      "Epoch 00009: val_accuracy improved from 0.85617 to 0.85779, saving model to NN.model\n",
      "INFO:tensorflow:Assets written to: NN.model/assets\n",
      "96000/96000 [==============================] - 20s 207us/sample - loss: 0.3495 - accuracy: 0.8476 - val_loss: 0.3283 - val_accuracy: 0.8578\n",
      "Epoch 10/100\n",
      "95808/96000 [============================>.] - ETA: 0s - loss: 0.3464 - accuracy: 0.8504\n",
      "Epoch 00010: val_accuracy did not improve from 0.85779\n",
      "96000/96000 [==============================] - 17s 178us/sample - loss: 0.3464 - accuracy: 0.8504 - val_loss: 0.3281 - val_accuracy: 0.8574\n",
      "Epoch 11/100\n",
      "95712/96000 [============================>.] - ETA: 0s - loss: 0.3455 - accuracy: 0.8507\n",
      "Epoch 00011: val_accuracy did not improve from 0.85779\n",
      "96000/96000 [==============================] - 17s 181us/sample - loss: 0.3456 - accuracy: 0.8506 - val_loss: 0.3337 - val_accuracy: 0.8545\n",
      "Epoch 12/100\n",
      "95680/96000 [============================>.] - ETA: 0s - loss: 0.3457 - accuracy: 0.8502\n",
      "Epoch 00012: val_accuracy improved from 0.85779 to 0.86042, saving model to NN.model\n",
      "INFO:tensorflow:Assets written to: NN.model/assets\n",
      "96000/96000 [==============================] - 20s 207us/sample - loss: 0.3458 - accuracy: 0.8501 - val_loss: 0.3271 - val_accuracy: 0.8604\n",
      "Epoch 13/100\n",
      "95744/96000 [============================>.] - ETA: 0s - loss: 0.3428 - accuracy: 0.8514\n",
      "Epoch 00013: val_accuracy did not improve from 0.86042\n",
      "96000/96000 [==============================] - 17s 179us/sample - loss: 0.3428 - accuracy: 0.8513 - val_loss: 0.3277 - val_accuracy: 0.8589\n",
      "Epoch 14/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.3428 - accuracy: 0.8526\n",
      "Epoch 00014: val_accuracy did not improve from 0.86042\n",
      "96000/96000 [==============================] - 17s 182us/sample - loss: 0.3428 - accuracy: 0.8526 - val_loss: 0.3280 - val_accuracy: 0.8577\n",
      "Epoch 15/100\n",
      "95648/96000 [============================>.] - ETA: 0s - loss: 0.3393 - accuracy: 0.8539\n",
      "Epoch 00015: val_accuracy did not improve from 0.86042\n",
      "96000/96000 [==============================] - 17s 172us/sample - loss: 0.3394 - accuracy: 0.8538 - val_loss: 0.3305 - val_accuracy: 0.8585\n",
      "Epoch 16/100\n",
      "95936/96000 [============================>.] - ETA: 0s - loss: 0.3407 - accuracy: 0.8539\n",
      "Epoch 00016: val_accuracy did not improve from 0.86042\n",
      "96000/96000 [==============================] - 17s 182us/sample - loss: 0.3407 - accuracy: 0.8539 - val_loss: 0.3253 - val_accuracy: 0.8585\n",
      "Epoch 17/100\n",
      "95744/96000 [============================>.] - ETA: 0s - loss: 0.3395 - accuracy: 0.8547\n",
      "Epoch 00017: val_accuracy did not improve from 0.86042\n",
      "96000/96000 [==============================] - 17s 177us/sample - loss: 0.3395 - accuracy: 0.8547 - val_loss: 0.3268 - val_accuracy: 0.8576\n",
      "Epoch 18/100\n",
      "95776/96000 [============================>.] - ETA: 0s - loss: 0.3384 - accuracy: 0.8549\n",
      "Epoch 00018: val_accuracy did not improve from 0.86042\n",
      "96000/96000 [==============================] - 17s 179us/sample - loss: 0.3386 - accuracy: 0.8548 - val_loss: 0.3267 - val_accuracy: 0.8598\n",
      "Epoch 19/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.3369 - accuracy: 0.8552\n",
      "Epoch 00019: val_accuracy did not improve from 0.86042\n",
      "96000/96000 [==============================] - 17s 175us/sample - loss: 0.3370 - accuracy: 0.8552 - val_loss: 0.3299 - val_accuracy: 0.8584\n",
      "Epoch 20/100\n",
      "95808/96000 [============================>.] - ETA: 0s - loss: 0.3355 - accuracy: 0.8559\n",
      "Epoch 00020: val_accuracy did not improve from 0.86042\n",
      "96000/96000 [==============================] - 17s 176us/sample - loss: 0.3355 - accuracy: 0.8559 - val_loss: 0.3279 - val_accuracy: 0.8577\n",
      "Epoch 21/100\n",
      "95776/96000 [============================>.] - ETA: 0s - loss: 0.3352 - accuracy: 0.8563\n",
      "Epoch 00021: val_accuracy did not improve from 0.86042\n",
      "96000/96000 [==============================] - 17s 177us/sample - loss: 0.3351 - accuracy: 0.8563 - val_loss: 0.3285 - val_accuracy: 0.8583\n",
      "Epoch 22/100\n",
      "95808/96000 [============================>.] - ETA: 0s - loss: 0.3357 - accuracy: 0.8561\n",
      "Epoch 00022: val_accuracy did not improve from 0.86042\n",
      "96000/96000 [==============================] - 17s 180us/sample - loss: 0.3358 - accuracy: 0.8560 - val_loss: 0.3255 - val_accuracy: 0.8604\n",
      "Epoch 23/100\n",
      "95872/96000 [============================>.] - ETA: 0s - loss: 0.3337 - accuracy: 0.8577\n",
      "Epoch 00023: val_accuracy did not improve from 0.86042\n",
      "96000/96000 [==============================] - 17s 178us/sample - loss: 0.3337 - accuracy: 0.8577 - val_loss: 0.3294 - val_accuracy: 0.8569\n",
      "Epoch 24/100\n",
      "95808/96000 [============================>.] - ETA: 0s - loss: 0.3350 - accuracy: 0.8569\n",
      "Epoch 00024: val_accuracy did not improve from 0.86042\n",
      "96000/96000 [==============================] - 16s 172us/sample - loss: 0.3350 - accuracy: 0.8569 - val_loss: 0.3250 - val_accuracy: 0.8595\n",
      "Epoch 25/100\n",
      "95840/96000 [============================>.] - ETA: 0s - loss: 0.3327 - accuracy: 0.8584\n",
      "Epoch 00025: val_accuracy did not improve from 0.86042\n",
      "96000/96000 [==============================] - 17s 178us/sample - loss: 0.3327 - accuracy: 0.8584 - val_loss: 0.3266 - val_accuracy: 0.8592\n",
      "Epoch 26/100\n",
      "95744/96000 [============================>.] - ETA: 0s - loss: 0.3335 - accuracy: 0.8581\n",
      "Epoch 00026: val_accuracy did not improve from 0.86042\n",
      "96000/96000 [==============================] - 18s 183us/sample - loss: 0.3338 - accuracy: 0.8580 - val_loss: 0.3296 - val_accuracy: 0.8584\n",
      "Epoch 27/100\n",
      "95776/96000 [============================>.] - ETA: 0s - loss: 0.3326 - accuracy: 0.8566\n",
      "Epoch 00027: val_accuracy did not improve from 0.86042\n",
      "96000/96000 [==============================] - 17s 174us/sample - loss: 0.3325 - accuracy: 0.8567 - val_loss: 0.3314 - val_accuracy: 0.8571\n",
      "Epoch 28/100\n",
      "95872/96000 [============================>.] - ETA: 0s - loss: 0.3321 - accuracy: 0.8582\n",
      "Epoch 00028: val_accuracy did not improve from 0.86042\n",
      "96000/96000 [==============================] - 18s 183us/sample - loss: 0.3321 - accuracy: 0.8582 - val_loss: 0.3268 - val_accuracy: 0.8546\n",
      "Epoch 29/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.3305 - accuracy: 0.8596\n",
      "Epoch 00029: val_accuracy did not improve from 0.86042\n",
      "96000/96000 [==============================] - 17s 180us/sample - loss: 0.3305 - accuracy: 0.8595 - val_loss: 0.3328 - val_accuracy: 0.8594\n",
      "Epoch 30/100\n",
      "95904/96000 [============================>.] - ETA: 0s - loss: 0.3303 - accuracy: 0.8590\n",
      "Epoch 00030: val_accuracy did not improve from 0.86042\n",
      "96000/96000 [==============================] - 17s 175us/sample - loss: 0.3303 - accuracy: 0.8591 - val_loss: 0.3253 - val_accuracy: 0.8595\n",
      "Epoch 31/100\n",
      "95776/96000 [============================>.] - ETA: 0s - loss: 0.3287 - accuracy: 0.8598\n",
      "Epoch 00031: val_accuracy did not improve from 0.86042\n",
      "96000/96000 [==============================] - 17s 174us/sample - loss: 0.3287 - accuracy: 0.8597 - val_loss: 0.3307 - val_accuracy: 0.8601\n",
      "Epoch 32/100\n",
      "95808/96000 [============================>.] - ETA: 0s - loss: 0.3303 - accuracy: 0.8593\n",
      "Epoch 00032: val_accuracy did not improve from 0.86042\n",
      "96000/96000 [==============================] - 18s 184us/sample - loss: 0.3302 - accuracy: 0.8593 - val_loss: 0.3285 - val_accuracy: 0.8575\n",
      "Epoch 33/100\n",
      "95872/96000 [============================>.] - ETA: 0s - loss: 0.3294 - accuracy: 0.8599\n",
      "Epoch 00033: val_accuracy improved from 0.86042 to 0.86054, saving model to NN.model\n",
      "INFO:tensorflow:Assets written to: NN.model/assets\n",
      "96000/96000 [==============================] - 19s 201us/sample - loss: 0.3295 - accuracy: 0.8599 - val_loss: 0.3254 - val_accuracy: 0.8605\n",
      "Epoch 34/100\n",
      "95904/96000 [============================>.] - ETA: 0s - loss: 0.3284 - accuracy: 0.8597\n",
      "Epoch 00034: val_accuracy improved from 0.86054 to 0.86058, saving model to NN.model\n",
      "INFO:tensorflow:Assets written to: NN.model/assets\n",
      "96000/96000 [==============================] - 20s 205us/sample - loss: 0.3285 - accuracy: 0.8597 - val_loss: 0.3265 - val_accuracy: 0.8606\n",
      "Epoch 35/100\n",
      "95936/96000 [============================>.] - ETA: 0s - loss: 0.3325 - accuracy: 0.8576\n",
      "Epoch 00035: val_accuracy did not improve from 0.86058\n",
      "96000/96000 [==============================] - 17s 175us/sample - loss: 0.3325 - accuracy: 0.8576 - val_loss: 0.3347 - val_accuracy: 0.8593\n",
      "Epoch 36/100\n",
      "95936/96000 [============================>.] - ETA: 0s - loss: 0.3308 - accuracy: 0.8582\n",
      "Epoch 00036: val_accuracy did not improve from 0.86058\n",
      "96000/96000 [==============================] - 17s 175us/sample - loss: 0.3308 - accuracy: 0.8581 - val_loss: 0.3264 - val_accuracy: 0.8587\n",
      "Epoch 37/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.3277 - accuracy: 0.8606\n",
      "Epoch 00037: val_accuracy did not improve from 0.86058\n",
      "96000/96000 [==============================] - 17s 176us/sample - loss: 0.3276 - accuracy: 0.8606 - val_loss: 0.3274 - val_accuracy: 0.8596\n",
      "Epoch 38/100\n",
      "95808/96000 [============================>.] - ETA: 0s - loss: 0.3295 - accuracy: 0.8595\n",
      "Epoch 00038: val_accuracy did not improve from 0.86058\n",
      "96000/96000 [==============================] - 17s 179us/sample - loss: 0.3294 - accuracy: 0.8595 - val_loss: 0.3250 - val_accuracy: 0.8590\n",
      "Epoch 39/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.3306 - accuracy: 0.8576\n",
      "Epoch 00039: val_accuracy did not improve from 0.86058\n",
      "96000/96000 [==============================] - 17s 174us/sample - loss: 0.3305 - accuracy: 0.8576 - val_loss: 0.3293 - val_accuracy: 0.8548\n",
      "Epoch 40/100\n",
      "95808/96000 [============================>.] - ETA: 0s - loss: 0.3309 - accuracy: 0.8581\n",
      "Epoch 00040: val_accuracy did not improve from 0.86058\n",
      "96000/96000 [==============================] - 17s 176us/sample - loss: 0.3309 - accuracy: 0.8581 - val_loss: 1.5805 - val_accuracy: 0.8589\n",
      "Epoch 41/100\n",
      "95648/96000 [============================>.] - ETA: 0s - loss: 0.3304 - accuracy: 0.8592\n",
      "Epoch 00041: val_accuracy did not improve from 0.86058\n",
      "96000/96000 [==============================] - 17s 174us/sample - loss: 0.3303 - accuracy: 0.8592 - val_loss: 0.3269 - val_accuracy: 0.8574\n",
      "Epoch 42/100\n",
      "95936/96000 [============================>.] - ETA: 0s - loss: 0.3293 - accuracy: 0.8605\n",
      "Epoch 00042: val_accuracy did not improve from 0.86058\n",
      "96000/96000 [==============================] - 17s 172us/sample - loss: 0.3293 - accuracy: 0.8604 - val_loss: 0.3528 - val_accuracy: 0.8460\n",
      "Epoch 43/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.3297 - accuracy: 0.8595\n",
      "Epoch 00043: val_accuracy did not improve from 0.86058\n",
      "96000/96000 [==============================] - 17s 172us/sample - loss: 0.3297 - accuracy: 0.8594 - val_loss: 0.7732 - val_accuracy: 0.8593\n",
      "Epoch 44/100\n",
      "95712/96000 [============================>.] - ETA: 0s - loss: 0.3286 - accuracy: 0.8605\n",
      "Epoch 00044: val_accuracy did not improve from 0.86058\n",
      "96000/96000 [==============================] - 17s 175us/sample - loss: 0.3287 - accuracy: 0.8604 - val_loss: 0.3286 - val_accuracy: 0.8596\n",
      "Epoch 45/100\n",
      "95712/96000 [============================>.] - ETA: 0s - loss: 0.3279 - accuracy: 0.8602\n",
      "Epoch 00045: val_accuracy did not improve from 0.86058\n",
      "96000/96000 [==============================] - 17s 174us/sample - loss: 0.3277 - accuracy: 0.8603 - val_loss: 0.3447 - val_accuracy: 0.8531\n",
      "Epoch 46/100\n",
      "95776/96000 [============================>.] - ETA: 0s - loss: 0.3261 - accuracy: 0.8603\n",
      "Epoch 00046: val_accuracy did not improve from 0.86058\n",
      "96000/96000 [==============================] - 17s 176us/sample - loss: 0.3261 - accuracy: 0.8603 - val_loss: 0.3323 - val_accuracy: 0.8601\n",
      "Epoch 47/100\n",
      "95840/96000 [============================>.] - ETA: 0s - loss: 0.3262 - accuracy: 0.8604\n",
      "Epoch 00047: val_accuracy did not improve from 0.86058\n",
      "96000/96000 [==============================] - 17s 174us/sample - loss: 0.3263 - accuracy: 0.8605 - val_loss: 0.3241 - val_accuracy: 0.8596\n",
      "Epoch 48/100\n",
      "95744/96000 [============================>.] - ETA: 0s - loss: 0.3261 - accuracy: 0.8608\n",
      "Epoch 00048: val_accuracy did not improve from 0.86058\n",
      "96000/96000 [==============================] - 17s 174us/sample - loss: 0.3262 - accuracy: 0.8608 - val_loss: 0.3294 - val_accuracy: 0.8594\n",
      "Epoch 49/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.3247 - accuracy: 0.8623\n",
      "Epoch 00049: val_accuracy improved from 0.86058 to 0.86063, saving model to NN.model\n",
      "INFO:tensorflow:Assets written to: NN.model/assets\n",
      "96000/96000 [==============================] - 19s 196us/sample - loss: 0.3248 - accuracy: 0.8622 - val_loss: 0.3766 - val_accuracy: 0.8606\n",
      "Epoch 50/100\n",
      "95744/96000 [============================>.] - ETA: 0s - loss: 0.3267 - accuracy: 0.8612\n",
      "Epoch 00050: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 16s 171us/sample - loss: 0.3267 - accuracy: 0.8612 - val_loss: 0.4556 - val_accuracy: 0.8543\n",
      "Epoch 51/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.3278 - accuracy: 0.8607\n",
      "Epoch 00051: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 175us/sample - loss: 0.3278 - accuracy: 0.8608 - val_loss: 0.3279 - val_accuracy: 0.8578\n",
      "Epoch 52/100\n",
      "95712/96000 [============================>.] - ETA: 0s - loss: 0.3263 - accuracy: 0.8625\n",
      "Epoch 00052: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 175us/sample - loss: 0.3262 - accuracy: 0.8624 - val_loss: 0.3251 - val_accuracy: 0.8581\n",
      "Epoch 53/100\n",
      "95648/96000 [============================>.] - ETA: 0s - loss: 0.3264 - accuracy: 0.8602\n",
      "Epoch 00053: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 173us/sample - loss: 0.3262 - accuracy: 0.8603 - val_loss: 1.6039 - val_accuracy: 0.8578\n",
      "Epoch 54/100\n",
      "95744/96000 [============================>.] - ETA: 0s - loss: 0.3232 - accuracy: 0.8615\n",
      "Epoch 00054: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 175us/sample - loss: 0.3231 - accuracy: 0.8616 - val_loss: 0.3319 - val_accuracy: 0.8569\n",
      "Epoch 55/100\n",
      "95776/96000 [============================>.] - ETA: 0s - loss: 0.3268 - accuracy: 0.8617\n",
      "Epoch 00055: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 173us/sample - loss: 0.3268 - accuracy: 0.8617 - val_loss: 0.3957 - val_accuracy: 0.8575\n",
      "Epoch 56/100\n",
      "95712/96000 [============================>.] - ETA: 0s - loss: 0.3256 - accuracy: 0.8614\n",
      "Epoch 00056: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 177us/sample - loss: 0.3255 - accuracy: 0.8614 - val_loss: 0.4153 - val_accuracy: 0.8603\n",
      "Epoch 57/100\n",
      "95872/96000 [============================>.] - ETA: 0s - loss: 0.3236 - accuracy: 0.8624\n",
      "Epoch 00057: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 173us/sample - loss: 0.3235 - accuracy: 0.8624 - val_loss: 0.3261 - val_accuracy: 0.8605\n",
      "Epoch 58/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.3228 - accuracy: 0.8619\n",
      "Epoch 00058: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 174us/sample - loss: 0.3228 - accuracy: 0.8619 - val_loss: 0.5037 - val_accuracy: 0.8606\n",
      "Epoch 59/100\n",
      "95680/96000 [============================>.] - ETA: 0s - loss: 0.3244 - accuracy: 0.8624\n",
      "Epoch 00059: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 16s 172us/sample - loss: 0.3248 - accuracy: 0.8622 - val_loss: 0.3324 - val_accuracy: 0.8585\n",
      "Epoch 60/100\n",
      "95808/96000 [============================>.] - ETA: 0s - loss: 0.3230 - accuracy: 0.8632\n",
      "Epoch 00060: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 172us/sample - loss: 0.3231 - accuracy: 0.8631 - val_loss: 0.3553 - val_accuracy: 0.8580\n",
      "Epoch 61/100\n",
      "95840/96000 [============================>.] - ETA: 0s - loss: 0.3235 - accuracy: 0.8621\n",
      "Epoch 00061: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 175us/sample - loss: 0.3236 - accuracy: 0.8621 - val_loss: 0.9798 - val_accuracy: 0.8547\n",
      "Epoch 62/100\n",
      "95744/96000 [============================>.] - ETA: 0s - loss: 0.3250 - accuracy: 0.8617\n",
      "Epoch 00062: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 172us/sample - loss: 0.3251 - accuracy: 0.8617 - val_loss: 0.4018 - val_accuracy: 0.8588\n",
      "Epoch 63/100\n",
      "95840/96000 [============================>.] - ETA: 0s - loss: 0.3237 - accuracy: 0.8624\n",
      "Epoch 00063: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 173us/sample - loss: 0.3237 - accuracy: 0.8624 - val_loss: 0.3311 - val_accuracy: 0.8583\n",
      "Epoch 64/100\n",
      "95776/96000 [============================>.] - ETA: 0s - loss: 0.3248 - accuracy: 0.8616\n",
      "Epoch 00064: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 174us/sample - loss: 0.3248 - accuracy: 0.8616 - val_loss: 0.3301 - val_accuracy: 0.8562\n",
      "Epoch 65/100\n",
      "95904/96000 [============================>.] - ETA: 0s - loss: 0.3236 - accuracy: 0.8629\n",
      "Epoch 00065: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 177us/sample - loss: 0.3237 - accuracy: 0.8628 - val_loss: 0.3284 - val_accuracy: 0.8572\n",
      "Epoch 66/100\n",
      "95936/96000 [============================>.] - ETA: 0s - loss: 0.3233 - accuracy: 0.8619\n",
      "Epoch 00066: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 174us/sample - loss: 0.3233 - accuracy: 0.8618 - val_loss: 0.3400 - val_accuracy: 0.8573\n",
      "Epoch 67/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.3218 - accuracy: 0.8639\n",
      "Epoch 00067: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 175us/sample - loss: 0.3218 - accuracy: 0.8639 - val_loss: 0.3272 - val_accuracy: 0.8584\n",
      "Epoch 68/100\n",
      "95808/96000 [============================>.] - ETA: 0s - loss: 0.3255 - accuracy: 0.8609\n",
      "Epoch 00068: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 175us/sample - loss: 0.3254 - accuracy: 0.8610 - val_loss: 0.3297 - val_accuracy: 0.8583\n",
      "Epoch 69/100\n",
      "95936/96000 [============================>.] - ETA: 0s - loss: 0.3213 - accuracy: 0.8632\n",
      "Epoch 00069: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 178us/sample - loss: 0.3213 - accuracy: 0.8632 - val_loss: 0.3411 - val_accuracy: 0.8473\n",
      "Epoch 70/100\n",
      "95712/96000 [============================>.] - ETA: 0s - loss: 0.3230 - accuracy: 0.8618\n",
      "Epoch 00070: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 176us/sample - loss: 0.3230 - accuracy: 0.8618 - val_loss: 0.3246 - val_accuracy: 0.8587\n",
      "Epoch 71/100\n",
      "95872/96000 [============================>.] - ETA: 0s - loss: 0.3260 - accuracy: 0.8614\n",
      "Epoch 00071: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 175us/sample - loss: 0.3260 - accuracy: 0.8615 - val_loss: 0.3342 - val_accuracy: 0.8589\n",
      "Epoch 72/100\n",
      "95840/96000 [============================>.] - ETA: 0s - loss: 0.3235 - accuracy: 0.8626\n",
      "Epoch 00072: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 16s 172us/sample - loss: 0.3237 - accuracy: 0.8625 - val_loss: 0.3993 - val_accuracy: 0.8587\n",
      "Epoch 73/100\n",
      "95904/96000 [============================>.] - ETA: 0s - loss: 0.3231 - accuracy: 0.8626\n",
      "Epoch 00073: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 172us/sample - loss: 0.3231 - accuracy: 0.8626 - val_loss: 0.3259 - val_accuracy: 0.8589\n",
      "Epoch 74/100\n",
      "95872/96000 [============================>.] - ETA: 0s - loss: 0.3226 - accuracy: 0.8625\n",
      "Epoch 00074: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 175us/sample - loss: 0.3225 - accuracy: 0.8625 - val_loss: 0.5345 - val_accuracy: 0.8588\n",
      "Epoch 75/100\n",
      "95936/96000 [============================>.] - ETA: 0s - loss: 0.3228 - accuracy: 0.8633\n",
      "Epoch 00075: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 173us/sample - loss: 0.3227 - accuracy: 0.8634 - val_loss: 0.3862 - val_accuracy: 0.8588\n",
      "Epoch 76/100\n",
      "95680/96000 [============================>.] - ETA: 0s - loss: 0.3210 - accuracy: 0.8631\n",
      "Epoch 00076: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 172us/sample - loss: 0.3209 - accuracy: 0.8632 - val_loss: 2.1161 - val_accuracy: 0.8595\n",
      "Epoch 77/100\n",
      "95840/96000 [============================>.] - ETA: 0s - loss: 0.3217 - accuracy: 0.8635\n",
      "Epoch 00077: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 176us/sample - loss: 0.3218 - accuracy: 0.8634 - val_loss: 0.3355 - val_accuracy: 0.8583\n",
      "Epoch 78/100\n",
      "95776/96000 [============================>.] - ETA: 0s - loss: 0.3223 - accuracy: 0.8631\n",
      "Epoch 00078: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 172us/sample - loss: 0.3223 - accuracy: 0.8632 - val_loss: 0.3324 - val_accuracy: 0.8595\n",
      "Epoch 79/100\n",
      "95936/96000 [============================>.] - ETA: 0s - loss: 0.3211 - accuracy: 0.8632\n",
      "Epoch 00079: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 172us/sample - loss: 0.3211 - accuracy: 0.8632 - val_loss: 0.3464 - val_accuracy: 0.8584\n",
      "Epoch 80/100\n",
      "95776/96000 [============================>.] - ETA: 0s - loss: 0.3210 - accuracy: 0.8639\n",
      "Epoch 00080: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 178us/sample - loss: 0.3210 - accuracy: 0.8639 - val_loss: 0.3425 - val_accuracy: 0.8597\n",
      "Epoch 81/100\n",
      "95808/96000 [============================>.] - ETA: 0s - loss: 0.3210 - accuracy: 0.8637\n",
      "Epoch 00081: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 16s 172us/sample - loss: 0.3209 - accuracy: 0.8637 - val_loss: 0.3273 - val_accuracy: 0.8598\n",
      "Epoch 82/100\n",
      "95872/96000 [============================>.] - ETA: 0s - loss: 0.3197 - accuracy: 0.8641\n",
      "Epoch 00082: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 175us/sample - loss: 0.3197 - accuracy: 0.8641 - val_loss: 0.3298 - val_accuracy: 0.8561\n",
      "Epoch 83/100\n",
      "95744/96000 [============================>.] - ETA: 0s - loss: 0.3197 - accuracy: 0.8643\n",
      "Epoch 00083: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 173us/sample - loss: 0.3198 - accuracy: 0.8643 - val_loss: 1.9804 - val_accuracy: 0.8576\n",
      "Epoch 84/100\n",
      "95840/96000 [============================>.] - ETA: 0s - loss: 0.3201 - accuracy: 0.8637\n",
      "Epoch 00084: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 173us/sample - loss: 0.3200 - accuracy: 0.8637 - val_loss: 0.3293 - val_accuracy: 0.8586\n",
      "Epoch 85/100\n",
      "95712/96000 [============================>.] - ETA: 0s - loss: 0.3207 - accuracy: 0.8628\n",
      "Epoch 00085: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 16s 170us/sample - loss: 0.3205 - accuracy: 0.8628 - val_loss: 1.2762 - val_accuracy: 0.8590\n",
      "Epoch 86/100\n",
      "95712/96000 [============================>.] - ETA: 0s - loss: 0.3174 - accuracy: 0.8656\n",
      "Epoch 00086: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 173us/sample - loss: 0.3176 - accuracy: 0.8655 - val_loss: 4.7551 - val_accuracy: 0.8592\n",
      "Epoch 87/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.3206 - accuracy: 0.8638\n",
      "Epoch 00087: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 16s 171us/sample - loss: 0.3205 - accuracy: 0.8638 - val_loss: 0.6558 - val_accuracy: 0.8574\n",
      "Epoch 88/100\n",
      "95872/96000 [============================>.] - ETA: 0s - loss: 0.3186 - accuracy: 0.8642\n",
      "Epoch 00088: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 16s 172us/sample - loss: 0.3186 - accuracy: 0.8642 - val_loss: 0.3336 - val_accuracy: 0.8578\n",
      "Epoch 89/100\n",
      "95744/96000 [============================>.] - ETA: 0s - loss: 0.3193 - accuracy: 0.8642\n",
      "Epoch 00089: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 173us/sample - loss: 0.3194 - accuracy: 0.8642 - val_loss: 0.3333 - val_accuracy: 0.8569\n",
      "Epoch 90/100\n",
      "95648/96000 [============================>.] - ETA: 0s - loss: 0.3205 - accuracy: 0.8628\n",
      "Epoch 00090: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 175us/sample - loss: 0.3204 - accuracy: 0.8628 - val_loss: 0.3262 - val_accuracy: 0.8597\n",
      "Epoch 91/100\n",
      "95840/96000 [============================>.] - ETA: 0s - loss: 0.3203 - accuracy: 0.8631\n",
      "Epoch 00091: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 178us/sample - loss: 0.3205 - accuracy: 0.8631 - val_loss: 0.4272 - val_accuracy: 0.8568\n",
      "Epoch 92/100\n",
      "95744/96000 [============================>.] - ETA: 0s - loss: 0.3212 - accuracy: 0.8630\n",
      "Epoch 00092: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 18s 185us/sample - loss: 0.3211 - accuracy: 0.8630 - val_loss: 0.3521 - val_accuracy: 0.8600\n",
      "Epoch 93/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.3221 - accuracy: 0.8629\n",
      "Epoch 00093: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 19s 200us/sample - loss: 0.3221 - accuracy: 0.8629 - val_loss: 0.3278 - val_accuracy: 0.8584\n",
      "Epoch 94/100\n",
      "95776/96000 [============================>.] - ETA: 0s - loss: 0.3183 - accuracy: 0.8646\n",
      "Epoch 00094: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 180us/sample - loss: 0.3182 - accuracy: 0.8647 - val_loss: 0.3309 - val_accuracy: 0.8595\n",
      "Epoch 95/100\n",
      "95840/96000 [============================>.] - ETA: 0s - loss: 0.3183 - accuracy: 0.8644\n",
      "Epoch 00095: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 18s 182us/sample - loss: 0.3183 - accuracy: 0.8644 - val_loss: 2.6574 - val_accuracy: 0.8589\n",
      "Epoch 96/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.3176 - accuracy: 0.8657\n",
      "Epoch 00096: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 18s 188us/sample - loss: 0.3176 - accuracy: 0.8657 - val_loss: 0.3273 - val_accuracy: 0.8592\n",
      "Epoch 97/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.3195 - accuracy: 0.8632\n",
      "Epoch 00097: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 18s 184us/sample - loss: 0.3196 - accuracy: 0.8631 - val_loss: 0.3307 - val_accuracy: 0.8583\n",
      "Epoch 98/100\n",
      "95936/96000 [============================>.] - ETA: 0s - loss: 0.3183 - accuracy: 0.8646\n",
      "Epoch 00098: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 177us/sample - loss: 0.3184 - accuracy: 0.8646 - val_loss: 2.2439 - val_accuracy: 0.8604\n",
      "Epoch 99/100\n",
      "95936/96000 [============================>.] - ETA: 0s - loss: 0.3179 - accuracy: 0.8649\n",
      "Epoch 00099: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 18s 184us/sample - loss: 0.3179 - accuracy: 0.8649 - val_loss: 0.6588 - val_accuracy: 0.8586\n",
      "Epoch 100/100\n",
      "95648/96000 [============================>.] - ETA: 0s - loss: 0.3202 - accuracy: 0.8637\n",
      "Epoch 00100: val_accuracy did not improve from 0.86063\n",
      "96000/96000 [==============================] - 17s 178us/sample - loss: 0.3202 - accuracy: 0.8637 - val_loss: 0.5610 - val_accuracy: 0.8595\n"
     ]
    }
   ],
   "source": [
    "#Deep Neural net Training\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "\n",
    "# mini batches Nadam optimizer with dropout and batch normalization\n",
    "epochs = 100\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(32, input_dim=100))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(32))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(rate = 0.2))\n",
    "model.add(layers.Dense(32))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(rate = 0.3))\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(rate = 0.4))\n",
    "\n",
    "model.add(layers.Dense(1))\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999),\n",
    "              metrics=['accuracy'])\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"NN.model\", monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "\n",
    "model.summary()\n",
    "model1 = model.fit(x_train, y_train, epochs=epochs, validation_split=0.2, callbacks=[checkpoint])\n",
    "#history = model.fit(x_train, y_train, epochs = epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "mk1DENr1F1IM",
    "outputId": "400fe73d-38e3-440a-c119-54e9a7f673cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train1 = x_train.reshape(120000, x_train.shape[1], 1)\n",
    "print(x_train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "LksvhGHzF1IO"
   },
   "outputs": [],
   "source": [
    "#CNN Training\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "shape = (x_train.shape[1], 1)\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv1D(32, kernel_size=3, activation=tf.nn.relu, input_shape=shape))\n",
    "model.add(tf.keras.layers.Conv1D(32, kernel_size=3, activation=tf.nn.relu))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
    "          \n",
    "model.add(tf.keras.layers.Conv1D(64, kernel_size=3, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Conv1D(64, kernel_size=3, activation=tf.nn.relu))\n",
    "          \n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
    "          \n",
    "model.add(tf.keras.layers.Conv1D(128, kernel_size=3, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Conv1D(128, kernel_size=3, activation=tf.nn.relu))\n",
    "          \n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
    "          \n",
    "model.add(tf.keras.layers.Conv1D(256, kernel_size=3, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Conv1D(256, kernel_size=3, activation=tf.nn.relu))\n",
    "          \n",
    "model.add(tf.keras.layers.MaxPooling1D(pool_size=5))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "          \n",
    "model.add(tf.keras.layers.Dense(200, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(100, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "gZsmP3VAF1IQ",
    "outputId": "4be1564e-b6bc-483f-c0b9-876dde82b12b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96000 samples, validate on 24000 samples\n",
      "Epoch 1/100\n",
      "95840/96000 [============================>.] - ETA: 0s - loss: 0.4179 - accuracy: 0.8086\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.83017, saving model to CNN.model\n",
      "INFO:tensorflow:Assets written to: CNN.model/assets\n",
      "96000/96000 [==============================] - 19s 201us/sample - loss: 0.4180 - accuracy: 0.8086 - val_loss: 0.3828 - val_accuracy: 0.8302\n",
      "Epoch 2/100\n",
      "95840/96000 [============================>.] - ETA: 0s - loss: 0.3789 - accuracy: 0.8310\n",
      "Epoch 00002: val_accuracy did not improve from 0.83017\n",
      "96000/96000 [==============================] - 17s 179us/sample - loss: 0.3788 - accuracy: 0.8311 - val_loss: 0.4988 - val_accuracy: 0.7315\n",
      "Epoch 3/100\n",
      "95872/96000 [============================>.] - ETA: 0s - loss: 0.3662 - accuracy: 0.8375\n",
      "Epoch 00003: val_accuracy improved from 0.83017 to 0.84704, saving model to CNN.model\n",
      "INFO:tensorflow:Assets written to: CNN.model/assets\n",
      "96000/96000 [==============================] - 18s 186us/sample - loss: 0.3661 - accuracy: 0.8376 - val_loss: 0.3748 - val_accuracy: 0.8470\n",
      "Epoch 4/100\n",
      "95648/96000 [============================>.] - ETA: 0s - loss: 0.3567 - accuracy: 0.8430\n",
      "Epoch 00004: val_accuracy did not improve from 0.84704\n",
      "96000/96000 [==============================] - 16s 169us/sample - loss: 0.3567 - accuracy: 0.8430 - val_loss: 0.3489 - val_accuracy: 0.8432\n",
      "Epoch 5/100\n",
      "95936/96000 [============================>.] - ETA: 0s - loss: 0.3509 - accuracy: 0.8442\n",
      "Epoch 00005: val_accuracy did not improve from 0.84704\n",
      "96000/96000 [==============================] - 17s 178us/sample - loss: 0.3510 - accuracy: 0.8442 - val_loss: 0.4477 - val_accuracy: 0.7830\n",
      "Epoch 6/100\n",
      "95712/96000 [============================>.] - ETA: 0s - loss: 0.3475 - accuracy: 0.8472\n",
      "Epoch 00006: val_accuracy did not improve from 0.84704\n",
      "96000/96000 [==============================] - 16s 166us/sample - loss: 0.3475 - accuracy: 0.8471 - val_loss: 0.3644 - val_accuracy: 0.8428\n",
      "Epoch 7/100\n",
      "95840/96000 [============================>.] - ETA: 0s - loss: 0.3419 - accuracy: 0.8496\n",
      "Epoch 00007: val_accuracy improved from 0.84704 to 0.84800, saving model to CNN.model\n",
      "INFO:tensorflow:Assets written to: CNN.model/assets\n",
      "96000/96000 [==============================] - 16s 169us/sample - loss: 0.3420 - accuracy: 0.8496 - val_loss: 0.3433 - val_accuracy: 0.8480\n",
      "Epoch 8/100\n",
      "95840/96000 [============================>.] - ETA: 0s - loss: 0.3391 - accuracy: 0.8511\n",
      "Epoch 00008: val_accuracy improved from 0.84800 to 0.84808, saving model to CNN.model\n",
      "INFO:tensorflow:Assets written to: CNN.model/assets\n",
      "96000/96000 [==============================] - 18s 185us/sample - loss: 0.3390 - accuracy: 0.8511 - val_loss: 0.3443 - val_accuracy: 0.8481\n",
      "Epoch 9/100\n",
      "95808/96000 [============================>.] - ETA: 0s - loss: 0.3344 - accuracy: 0.8540\n",
      "Epoch 00009: val_accuracy did not improve from 0.84808\n",
      "96000/96000 [==============================] - 16s 168us/sample - loss: 0.3345 - accuracy: 0.8540 - val_loss: 0.3547 - val_accuracy: 0.8426\n",
      "Epoch 10/100\n",
      "95744/96000 [============================>.] - ETA: 0s - loss: 0.3414 - accuracy: 0.8506\n",
      "Epoch 00010: val_accuracy did not improve from 0.84808\n",
      "96000/96000 [==============================] - 15s 157us/sample - loss: 0.3416 - accuracy: 0.8505 - val_loss: 0.4350 - val_accuracy: 0.8138\n",
      "Epoch 11/100\n",
      "95808/96000 [============================>.] - ETA: 0s - loss: 0.3336 - accuracy: 0.8531\n",
      "Epoch 00011: val_accuracy improved from 0.84808 to 0.85071, saving model to CNN.model\n",
      "INFO:tensorflow:Assets written to: CNN.model/assets\n",
      "96000/96000 [==============================] - 16s 170us/sample - loss: 0.3336 - accuracy: 0.8531 - val_loss: 0.3367 - val_accuracy: 0.8507\n",
      "Epoch 12/100\n",
      "95744/96000 [============================>.] - ETA: 0s - loss: 0.3289 - accuracy: 0.8561\n",
      "Epoch 00012: val_accuracy did not improve from 0.85071\n",
      "96000/96000 [==============================] - 16s 169us/sample - loss: 0.3289 - accuracy: 0.8561 - val_loss: 0.3924 - val_accuracy: 0.8449\n",
      "Epoch 13/100\n",
      "95712/96000 [============================>.] - ETA: 0s - loss: 0.3258 - accuracy: 0.8580\n",
      "Epoch 00013: val_accuracy did not improve from 0.85071\n",
      "96000/96000 [==============================] - 16s 170us/sample - loss: 0.3258 - accuracy: 0.8580 - val_loss: 0.3425 - val_accuracy: 0.8488\n",
      "Epoch 14/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.3241 - accuracy: 0.8592\n",
      "Epoch 00014: val_accuracy did not improve from 0.85071\n",
      "96000/96000 [==============================] - 15s 161us/sample - loss: 0.3241 - accuracy: 0.8592 - val_loss: 0.3445 - val_accuracy: 0.8465\n",
      "Epoch 15/100\n",
      "95840/96000 [============================>.] - ETA: 0s - loss: 0.3208 - accuracy: 0.8602\n",
      "Epoch 00015: val_accuracy improved from 0.85071 to 0.85362, saving model to CNN.model\n",
      "INFO:tensorflow:Assets written to: CNN.model/assets\n",
      "96000/96000 [==============================] - 17s 174us/sample - loss: 0.3208 - accuracy: 0.8602 - val_loss: 0.3372 - val_accuracy: 0.8536\n",
      "Epoch 16/100\n",
      "95680/96000 [============================>.] - ETA: 0s - loss: 0.3179 - accuracy: 0.8626\n",
      "Epoch 00016: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 16s 162us/sample - loss: 0.3179 - accuracy: 0.8626 - val_loss: 0.3440 - val_accuracy: 0.8490\n",
      "Epoch 17/100\n",
      "95872/96000 [============================>.] - ETA: 0s - loss: 0.3157 - accuracy: 0.8618\n",
      "Epoch 00017: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 16s 166us/sample - loss: 0.3159 - accuracy: 0.8617 - val_loss: 0.3430 - val_accuracy: 0.8471\n",
      "Epoch 18/100\n",
      "95648/96000 [============================>.] - ETA: 0s - loss: 0.3124 - accuracy: 0.8639\n",
      "Epoch 00018: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 17s 173us/sample - loss: 0.3123 - accuracy: 0.8640 - val_loss: 0.3887 - val_accuracy: 0.8316\n",
      "Epoch 19/100\n",
      "95872/96000 [============================>.] - ETA: 0s - loss: 0.3103 - accuracy: 0.8637\n",
      "Epoch 00019: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 160us/sample - loss: 0.3103 - accuracy: 0.8637 - val_loss: 0.3445 - val_accuracy: 0.8489\n",
      "Epoch 20/100\n",
      "95936/96000 [============================>.] - ETA: 0s - loss: 0.3082 - accuracy: 0.8673\n",
      "Epoch 00020: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 159us/sample - loss: 0.3082 - accuracy: 0.8673 - val_loss: 0.3420 - val_accuracy: 0.8515\n",
      "Epoch 21/100\n",
      "95648/96000 [============================>.] - ETA: 0s - loss: 0.3046 - accuracy: 0.8684\n",
      "Epoch 00021: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 17s 175us/sample - loss: 0.3044 - accuracy: 0.8684 - val_loss: 0.3594 - val_accuracy: 0.8493\n",
      "Epoch 22/100\n",
      "95872/96000 [============================>.] - ETA: 0s - loss: 0.3027 - accuracy: 0.8682\n",
      "Epoch 00022: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 16s 169us/sample - loss: 0.3027 - accuracy: 0.8683 - val_loss: 0.3493 - val_accuracy: 0.8509\n",
      "Epoch 23/100\n",
      "95776/96000 [============================>.] - ETA: 0s - loss: 0.3003 - accuracy: 0.8702\n",
      "Epoch 00023: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 16s 164us/sample - loss: 0.3005 - accuracy: 0.8701 - val_loss: 0.3554 - val_accuracy: 0.8456\n",
      "Epoch 24/100\n",
      "95584/96000 [============================>.] - ETA: 0s - loss: 0.2970 - accuracy: 0.8712\n",
      "Epoch 00024: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 16s 162us/sample - loss: 0.2972 - accuracy: 0.8712 - val_loss: 0.3451 - val_accuracy: 0.8496\n",
      "Epoch 25/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.2939 - accuracy: 0.8719\n",
      "Epoch 00025: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 156us/sample - loss: 0.2939 - accuracy: 0.8719 - val_loss: 0.3592 - val_accuracy: 0.8447\n",
      "Epoch 26/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.2938 - accuracy: 0.8722\n",
      "Epoch 00026: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 160us/sample - loss: 0.2938 - accuracy: 0.8722 - val_loss: 0.3678 - val_accuracy: 0.8384\n",
      "Epoch 27/100\n",
      "95808/96000 [============================>.] - ETA: 0s - loss: 0.2888 - accuracy: 0.8746\n",
      "Epoch 00027: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 160us/sample - loss: 0.2887 - accuracy: 0.8747 - val_loss: 0.3530 - val_accuracy: 0.8498\n",
      "Epoch 28/100\n",
      "95872/96000 [============================>.] - ETA: 0s - loss: 0.2875 - accuracy: 0.8753\n",
      "Epoch 00028: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 156us/sample - loss: 0.2874 - accuracy: 0.8753 - val_loss: 0.3534 - val_accuracy: 0.8475\n",
      "Epoch 29/100\n",
      "95872/96000 [============================>.] - ETA: 0s - loss: 0.2842 - accuracy: 0.8768\n",
      "Epoch 00029: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 158us/sample - loss: 0.2842 - accuracy: 0.8767 - val_loss: 0.3616 - val_accuracy: 0.8491\n",
      "Epoch 30/100\n",
      "95680/96000 [============================>.] - ETA: 0s - loss: 0.2814 - accuracy: 0.8776\n",
      "Epoch 00030: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 156us/sample - loss: 0.2814 - accuracy: 0.8776 - val_loss: 0.3518 - val_accuracy: 0.8495\n",
      "Epoch 31/100\n",
      "95712/96000 [============================>.] - ETA: 0s - loss: 0.2776 - accuracy: 0.8795\n",
      "Epoch 00031: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 155us/sample - loss: 0.2778 - accuracy: 0.8794 - val_loss: 0.3604 - val_accuracy: 0.8461\n",
      "Epoch 32/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.2764 - accuracy: 0.8806\n",
      "Epoch 00032: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 16s 163us/sample - loss: 0.2764 - accuracy: 0.8806 - val_loss: 0.3666 - val_accuracy: 0.8463\n",
      "Epoch 33/100\n",
      "95744/96000 [============================>.] - ETA: 0s - loss: 0.2735 - accuracy: 0.8818\n",
      "Epoch 00033: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 16s 162us/sample - loss: 0.2736 - accuracy: 0.8818 - val_loss: 0.3764 - val_accuracy: 0.8449\n",
      "Epoch 34/100\n",
      "95744/96000 [============================>.] - ETA: 0s - loss: 0.2708 - accuracy: 0.8834\n",
      "Epoch 00034: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 155us/sample - loss: 0.2708 - accuracy: 0.8834 - val_loss: 0.3706 - val_accuracy: 0.8417\n",
      "Epoch 35/100\n",
      "95904/96000 [============================>.] - ETA: 0s - loss: 0.2683 - accuracy: 0.8837\n",
      "Epoch 00035: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 154us/sample - loss: 0.2683 - accuracy: 0.8837 - val_loss: 0.3733 - val_accuracy: 0.8428\n",
      "Epoch 36/100\n",
      "95808/96000 [============================>.] - ETA: 0s - loss: 0.2662 - accuracy: 0.8843\n",
      "Epoch 00036: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 16s 164us/sample - loss: 0.2662 - accuracy: 0.8842 - val_loss: 0.3945 - val_accuracy: 0.8436\n",
      "Epoch 37/100\n",
      "95712/96000 [============================>.] - ETA: 0s - loss: 0.2640 - accuracy: 0.8851\n",
      "Epoch 00037: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 16s 168us/sample - loss: 0.2640 - accuracy: 0.8850 - val_loss: 0.3906 - val_accuracy: 0.8385\n",
      "Epoch 38/100\n",
      "95872/96000 [============================>.] - ETA: 0s - loss: 0.2614 - accuracy: 0.8868\n",
      "Epoch 00038: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 159us/sample - loss: 0.2614 - accuracy: 0.8869 - val_loss: 0.3779 - val_accuracy: 0.8417\n",
      "Epoch 39/100\n",
      "95904/96000 [============================>.] - ETA: 0s - loss: 0.2572 - accuracy: 0.8883\n",
      "Epoch 00039: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 161us/sample - loss: 0.2574 - accuracy: 0.8882 - val_loss: 0.4085 - val_accuracy: 0.8406\n",
      "Epoch 40/100\n",
      "95712/96000 [============================>.] - ETA: 0s - loss: 0.2560 - accuracy: 0.8897\n",
      "Epoch 00040: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 16s 162us/sample - loss: 0.2559 - accuracy: 0.8897 - val_loss: 0.4031 - val_accuracy: 0.8420\n",
      "Epoch 41/100\n",
      "95904/96000 [============================>.] - ETA: 0s - loss: 0.2542 - accuracy: 0.8898\n",
      "Epoch 00041: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 158us/sample - loss: 0.2541 - accuracy: 0.8898 - val_loss: 0.3894 - val_accuracy: 0.8450\n",
      "Epoch 42/100\n",
      "95616/96000 [============================>.] - ETA: 0s - loss: 0.2505 - accuracy: 0.8919\n",
      "Epoch 00042: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 153us/sample - loss: 0.2505 - accuracy: 0.8919 - val_loss: 0.3951 - val_accuracy: 0.8362\n",
      "Epoch 43/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.2486 - accuracy: 0.8916\n",
      "Epoch 00043: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 14s 149us/sample - loss: 0.2486 - accuracy: 0.8916 - val_loss: 0.4142 - val_accuracy: 0.8434\n",
      "Epoch 44/100\n",
      "95744/96000 [============================>.] - ETA: 0s - loss: 0.2463 - accuracy: 0.8925\n",
      "Epoch 00044: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 152us/sample - loss: 0.2462 - accuracy: 0.8925 - val_loss: 0.4177 - val_accuracy: 0.8430\n",
      "Epoch 45/100\n",
      "95872/96000 [============================>.] - ETA: 0s - loss: 0.2437 - accuracy: 0.8946\n",
      "Epoch 00045: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 160us/sample - loss: 0.2436 - accuracy: 0.8946 - val_loss: 0.4134 - val_accuracy: 0.8398\n",
      "Epoch 46/100\n",
      "95648/96000 [============================>.] - ETA: 0s - loss: 0.2414 - accuracy: 0.8950\n",
      "Epoch 00046: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 154us/sample - loss: 0.2414 - accuracy: 0.8950 - val_loss: 0.4254 - val_accuracy: 0.8419\n",
      "Epoch 47/100\n",
      "95904/96000 [============================>.] - ETA: 0s - loss: 0.2395 - accuracy: 0.8954\n",
      "Epoch 00047: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 157us/sample - loss: 0.2396 - accuracy: 0.8954 - val_loss: 0.4281 - val_accuracy: 0.8414\n",
      "Epoch 48/100\n",
      "95648/96000 [============================>.] - ETA: 0s - loss: 0.2360 - accuracy: 0.8979\n",
      "Epoch 00048: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 16s 164us/sample - loss: 0.2360 - accuracy: 0.8978 - val_loss: 0.4375 - val_accuracy: 0.8322\n",
      "Epoch 49/100\n",
      "95872/96000 [============================>.] - ETA: 0s - loss: 0.2341 - accuracy: 0.8982\n",
      "Epoch 00049: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 16s 163us/sample - loss: 0.2340 - accuracy: 0.8982 - val_loss: 0.4324 - val_accuracy: 0.8372\n",
      "Epoch 50/100\n",
      "95872/96000 [============================>.] - ETA: 0s - loss: 0.2319 - accuracy: 0.8986\n",
      "Epoch 00050: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 161us/sample - loss: 0.2319 - accuracy: 0.8987 - val_loss: 0.4272 - val_accuracy: 0.8390\n",
      "Epoch 51/100\n",
      "95680/96000 [============================>.] - ETA: 0s - loss: 0.2308 - accuracy: 0.8995\n",
      "Epoch 00051: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 156us/sample - loss: 0.2308 - accuracy: 0.8995 - val_loss: 0.4270 - val_accuracy: 0.8384\n",
      "Epoch 52/100\n",
      "95744/96000 [============================>.] - ETA: 0s - loss: 0.2289 - accuracy: 0.9002\n",
      "Epoch 00052: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 157us/sample - loss: 0.2288 - accuracy: 0.9001 - val_loss: 0.4932 - val_accuracy: 0.8332\n",
      "Epoch 53/100\n",
      "95648/96000 [============================>.] - ETA: 0s - loss: 0.2264 - accuracy: 0.9017\n",
      "Epoch 00053: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 14s 150us/sample - loss: 0.2264 - accuracy: 0.9017 - val_loss: 0.4477 - val_accuracy: 0.8429\n",
      "Epoch 54/100\n",
      "95872/96000 [============================>.] - ETA: 0s - loss: 0.2245 - accuracy: 0.9029\n",
      "Epoch 00054: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 155us/sample - loss: 0.2244 - accuracy: 0.9030 - val_loss: 0.4230 - val_accuracy: 0.8370\n",
      "Epoch 55/100\n",
      "95744/96000 [============================>.] - ETA: 0s - loss: 0.2215 - accuracy: 0.9038\n",
      "Epoch 00055: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 14s 149us/sample - loss: 0.2215 - accuracy: 0.9038 - val_loss: 0.5340 - val_accuracy: 0.8271\n",
      "Epoch 56/100\n",
      "95712/96000 [============================>.] - ETA: 0s - loss: 0.2200 - accuracy: 0.9051\n",
      "Epoch 00056: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 159us/sample - loss: 0.2201 - accuracy: 0.9051 - val_loss: 0.4992 - val_accuracy: 0.8387\n",
      "Epoch 57/100\n",
      "95904/96000 [============================>.] - ETA: 0s - loss: 0.2161 - accuracy: 0.9068\n",
      "Epoch 00057: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 151us/sample - loss: 0.2160 - accuracy: 0.9068 - val_loss: 0.4579 - val_accuracy: 0.8380\n",
      "Epoch 58/100\n",
      "95584/96000 [============================>.] - ETA: 0s - loss: 0.2153 - accuracy: 0.9067\n",
      "Epoch 00058: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 153us/sample - loss: 0.2153 - accuracy: 0.9066 - val_loss: 0.4742 - val_accuracy: 0.8321\n",
      "Epoch 59/100\n",
      "95808/96000 [============================>.] - ETA: 0s - loss: 0.2127 - accuracy: 0.9074\n",
      "Epoch 00059: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 157us/sample - loss: 0.2127 - accuracy: 0.9074 - val_loss: 0.5148 - val_accuracy: 0.8314\n",
      "Epoch 60/100\n",
      "95808/96000 [============================>.] - ETA: 0s - loss: 0.2126 - accuracy: 0.9090\n",
      "Epoch 00060: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 155us/sample - loss: 0.2125 - accuracy: 0.9091 - val_loss: 0.4736 - val_accuracy: 0.8365\n",
      "Epoch 61/100\n",
      "95744/96000 [============================>.] - ETA: 0s - loss: 0.2093 - accuracy: 0.9090\n",
      "Epoch 00061: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 14s 150us/sample - loss: 0.2093 - accuracy: 0.9090 - val_loss: 0.4817 - val_accuracy: 0.8370\n",
      "Epoch 62/100\n",
      "95680/96000 [============================>.] - ETA: 0s - loss: 0.2078 - accuracy: 0.9105\n",
      "Epoch 00062: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 155us/sample - loss: 0.2079 - accuracy: 0.9105 - val_loss: 0.4906 - val_accuracy: 0.8355\n",
      "Epoch 63/100\n",
      "95648/96000 [============================>.] - ETA: 0s - loss: 0.2070 - accuracy: 0.9103\n",
      "Epoch 00063: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 14s 149us/sample - loss: 0.2071 - accuracy: 0.9103 - val_loss: 0.4858 - val_accuracy: 0.8334\n",
      "Epoch 64/100\n",
      "95680/96000 [============================>.] - ETA: 0s - loss: 0.2021 - accuracy: 0.9119\n",
      "Epoch 00064: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 14s 149us/sample - loss: 0.2021 - accuracy: 0.9120 - val_loss: 0.4885 - val_accuracy: 0.8291\n",
      "Epoch 65/100\n",
      "95808/96000 [============================>.] - ETA: 0s - loss: 0.2041 - accuracy: 0.9118\n",
      "Epoch 00065: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 153us/sample - loss: 0.2040 - accuracy: 0.9118 - val_loss: 0.4918 - val_accuracy: 0.8398\n",
      "Epoch 66/100\n",
      "95904/96000 [============================>.] - ETA: 0s - loss: 0.1995 - accuracy: 0.9143\n",
      "Epoch 00066: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 14s 149us/sample - loss: 0.1995 - accuracy: 0.9143 - val_loss: 0.4937 - val_accuracy: 0.8255\n",
      "Epoch 67/100\n",
      "95840/96000 [============================>.] - ETA: 0s - loss: 0.1985 - accuracy: 0.9140\n",
      "Epoch 00067: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 14s 151us/sample - loss: 0.1985 - accuracy: 0.9140 - val_loss: 0.5528 - val_accuracy: 0.8378\n",
      "Epoch 68/100\n",
      "95840/96000 [============================>.] - ETA: 0s - loss: 0.1956 - accuracy: 0.9148\n",
      "Epoch 00068: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 14s 148us/sample - loss: 0.1955 - accuracy: 0.9149 - val_loss: 0.4973 - val_accuracy: 0.8317\n",
      "Epoch 69/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.1950 - accuracy: 0.9154\n",
      "Epoch 00069: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 153us/sample - loss: 0.1950 - accuracy: 0.9154 - val_loss: 0.5137 - val_accuracy: 0.8270\n",
      "Epoch 70/100\n",
      "95648/96000 [============================>.] - ETA: 0s - loss: 0.1928 - accuracy: 0.9165\n",
      "Epoch 00070: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 157us/sample - loss: 0.1928 - accuracy: 0.9166 - val_loss: 0.5159 - val_accuracy: 0.8264\n",
      "Epoch 71/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.1922 - accuracy: 0.9170\n",
      "Epoch 00071: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 157us/sample - loss: 0.1922 - accuracy: 0.9170 - val_loss: 0.9014 - val_accuracy: 0.8264\n",
      "Epoch 72/100\n",
      "95776/96000 [============================>.] - ETA: 0s - loss: 0.1914 - accuracy: 0.9173\n",
      "Epoch 00072: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 16s 163us/sample - loss: 0.1915 - accuracy: 0.9172 - val_loss: 0.5106 - val_accuracy: 0.8251\n",
      "Epoch 73/100\n",
      "95680/96000 [============================>.] - ETA: 0s - loss: 0.1886 - accuracy: 0.9188\n",
      "Epoch 00073: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 155us/sample - loss: 0.1886 - accuracy: 0.9188 - val_loss: 0.5354 - val_accuracy: 0.8220\n",
      "Epoch 74/100\n",
      "95840/96000 [============================>.] - ETA: 0s - loss: 0.1880 - accuracy: 0.9190\n",
      "Epoch 00074: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 152us/sample - loss: 0.1880 - accuracy: 0.9189 - val_loss: 0.5211 - val_accuracy: 0.8316\n",
      "Epoch 75/100\n",
      "95776/96000 [============================>.] - ETA: 0s - loss: 0.1860 - accuracy: 0.9194\n",
      "Epoch 00075: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 155us/sample - loss: 0.1858 - accuracy: 0.9195 - val_loss: 0.5368 - val_accuracy: 0.8273\n",
      "Epoch 76/100\n",
      "95616/96000 [============================>.] - ETA: 0s - loss: 0.1838 - accuracy: 0.9200\n",
      "Epoch 00076: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 157us/sample - loss: 0.1839 - accuracy: 0.9199 - val_loss: 0.5445 - val_accuracy: 0.8294\n",
      "Epoch 77/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.1830 - accuracy: 0.9206\n",
      "Epoch 00077: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 17s 172us/sample - loss: 0.1830 - accuracy: 0.9206 - val_loss: 0.5717 - val_accuracy: 0.8326\n",
      "Epoch 78/100\n",
      "95776/96000 [============================>.] - ETA: 0s - loss: 0.1808 - accuracy: 0.9219\n",
      "Epoch 00078: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 156us/sample - loss: 0.1808 - accuracy: 0.9219 - val_loss: 0.5757 - val_accuracy: 0.8341\n",
      "Epoch 79/100\n",
      "95616/96000 [============================>.] - ETA: 0s - loss: 0.1804 - accuracy: 0.9228\n",
      "Epoch 00079: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 158us/sample - loss: 0.1803 - accuracy: 0.9229 - val_loss: 0.5651 - val_accuracy: 0.8278\n",
      "Epoch 80/100\n",
      "95680/96000 [============================>.] - ETA: 0s - loss: 0.1769 - accuracy: 0.9236\n",
      "Epoch 00080: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 16s 162us/sample - loss: 0.1769 - accuracy: 0.9235 - val_loss: 0.5846 - val_accuracy: 0.8272\n",
      "Epoch 81/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.1766 - accuracy: 0.9242\n",
      "Epoch 00081: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 154us/sample - loss: 0.1765 - accuracy: 0.9243 - val_loss: 0.5678 - val_accuracy: 0.8257\n",
      "Epoch 82/100\n",
      "95648/96000 [============================>.] - ETA: 0s - loss: 0.1757 - accuracy: 0.9243\n",
      "Epoch 00082: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 16s 163us/sample - loss: 0.1756 - accuracy: 0.9243 - val_loss: 0.7349 - val_accuracy: 0.8283\n",
      "Epoch 83/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.1741 - accuracy: 0.9258\n",
      "Epoch 00083: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 157us/sample - loss: 0.1741 - accuracy: 0.9258 - val_loss: 0.5583 - val_accuracy: 0.8291\n",
      "Epoch 84/100\n",
      "95936/96000 [============================>.] - ETA: 0s - loss: 0.1727 - accuracy: 0.9251\n",
      "Epoch 00084: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 14s 149us/sample - loss: 0.1727 - accuracy: 0.9251 - val_loss: 0.5827 - val_accuracy: 0.8191\n",
      "Epoch 85/100\n",
      "95776/96000 [============================>.] - ETA: 0s - loss: 0.1699 - accuracy: 0.9274\n",
      "Epoch 00085: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 161us/sample - loss: 0.1698 - accuracy: 0.9274 - val_loss: 0.5887 - val_accuracy: 0.8274\n",
      "Epoch 86/100\n",
      "95680/96000 [============================>.] - ETA: 0s - loss: 0.1704 - accuracy: 0.9268\n",
      "Epoch 00086: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 153us/sample - loss: 0.1706 - accuracy: 0.9267 - val_loss: 0.5894 - val_accuracy: 0.8322\n",
      "Epoch 87/100\n",
      "95680/96000 [============================>.] - ETA: 0s - loss: 0.1680 - accuracy: 0.9277\n",
      "Epoch 00087: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 14s 148us/sample - loss: 0.1679 - accuracy: 0.9277 - val_loss: 0.6177 - val_accuracy: 0.8290\n",
      "Epoch 88/100\n",
      "95648/96000 [============================>.] - ETA: 0s - loss: 0.1664 - accuracy: 0.9282\n",
      "Epoch 00088: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 14s 150us/sample - loss: 0.1664 - accuracy: 0.9282 - val_loss: 0.5839 - val_accuracy: 0.8294\n",
      "Epoch 89/100\n",
      "95872/96000 [============================>.] - ETA: 0s - loss: 0.1669 - accuracy: 0.9279\n",
      "Epoch 00089: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 153us/sample - loss: 0.1669 - accuracy: 0.9278 - val_loss: 0.9700 - val_accuracy: 0.8105\n",
      "Epoch 90/100\n",
      "95776/96000 [============================>.] - ETA: 0s - loss: 0.1648 - accuracy: 0.9292\n",
      "Epoch 00090: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 14s 146us/sample - loss: 0.1647 - accuracy: 0.9292 - val_loss: 0.6576 - val_accuracy: 0.8260\n",
      "Epoch 91/100\n",
      "95616/96000 [============================>.] - ETA: 0s - loss: 0.1640 - accuracy: 0.9302\n",
      "Epoch 00091: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 155us/sample - loss: 0.1639 - accuracy: 0.9303 - val_loss: 0.5789 - val_accuracy: 0.8250\n",
      "Epoch 92/100\n",
      "95744/96000 [============================>.] - ETA: 0s - loss: 0.1636 - accuracy: 0.9294\n",
      "Epoch 00092: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 154us/sample - loss: 0.1636 - accuracy: 0.9294 - val_loss: 0.5957 - val_accuracy: 0.8295\n",
      "Epoch 93/100\n",
      "95744/96000 [============================>.] - ETA: 0s - loss: 0.1606 - accuracy: 0.9314\n",
      "Epoch 00093: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 14s 151us/sample - loss: 0.1607 - accuracy: 0.9312 - val_loss: 0.6080 - val_accuracy: 0.8259\n",
      "Epoch 94/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.1599 - accuracy: 0.9320\n",
      "Epoch 00094: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 158us/sample - loss: 0.1599 - accuracy: 0.9320 - val_loss: 1.2811 - val_accuracy: 0.8257\n",
      "Epoch 95/100\n",
      "95840/96000 [============================>.] - ETA: 0s - loss: 0.1579 - accuracy: 0.9325\n",
      "Epoch 00095: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 156us/sample - loss: 0.1579 - accuracy: 0.9325 - val_loss: 0.5933 - val_accuracy: 0.8280\n",
      "Epoch 96/100\n",
      "95712/96000 [============================>.] - ETA: 0s - loss: 0.1574 - accuracy: 0.9335\n",
      "Epoch 00096: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 154us/sample - loss: 0.1574 - accuracy: 0.9334 - val_loss: 1.5745 - val_accuracy: 0.8277\n",
      "Epoch 97/100\n",
      "95712/96000 [============================>.] - ETA: 0s - loss: 0.1540 - accuracy: 0.9346\n",
      "Epoch 00097: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 159us/sample - loss: 0.1540 - accuracy: 0.9346 - val_loss: 0.6456 - val_accuracy: 0.8255\n",
      "Epoch 98/100\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 0.1568 - accuracy: 0.9341\n",
      "Epoch 00098: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 152us/sample - loss: 0.1569 - accuracy: 0.9340 - val_loss: 0.6258 - val_accuracy: 0.8207\n",
      "Epoch 99/100\n",
      "95712/96000 [============================>.] - ETA: 0s - loss: 0.1528 - accuracy: 0.9348\n",
      "Epoch 00099: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 154us/sample - loss: 0.1528 - accuracy: 0.9348 - val_loss: 0.6323 - val_accuracy: 0.8241\n",
      "Epoch 100/100\n",
      "95904/96000 [============================>.] - ETA: 0s - loss: 0.1526 - accuracy: 0.9358\n",
      "Epoch 00100: val_accuracy did not improve from 0.85362\n",
      "96000/96000 [==============================] - 15s 155us/sample - loss: 0.1526 - accuracy: 0.9358 - val_loss: 0.6435 - val_accuracy: 0.8268\n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\"CNN.model\", monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "model2 = model.fit(x_train1, y_train, epochs=100, validation_split=0.2, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "Rfak2r_3F1IT"
   },
   "outputs": [],
   "source": [
    "#Load and Clean test file\n",
    "\n",
    "text_file = open(\"test.txt.txt\", \"r\", encoding=\"utf8\")\n",
    "lines = text_file.read().split('\\n')\n",
    "\n",
    "labels = []\n",
    "for item in lines:\n",
    "    first_four_letters = item[:10]\n",
    "    if first_four_letters == '__label__1':\n",
    "        labels.append(int(1))\n",
    "    else:\n",
    "        labels.append(int(2))\n",
    "        \n",
    "def remove_label(s):\n",
    "    return s[11:]\n",
    "lines = [remove_label(s) for s in lines]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['text'] = lines\n",
    "df['label'] = labels\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "#lowercase and remove punctuation, remove stopwords        \n",
    "df['text'] = df['text'].str.lower()\n",
    "df['text'] = df['text'].str.replace('-', ' ')\n",
    "df['text'] = df['text'].str.split(' ')\n",
    "df['text'] = df['text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].apply(lemmatize_text)\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].str.replace('\\\\', ' ')\n",
    "\n",
    "df = df.sample(40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "cMhYlNcnF1IV",
    "outputId": "bdb06eba-7493-4e4f-d0f6-f6ab037e7f76",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "899c24b069fa4b0f86804ea8b467948b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Embed Word2Vec and BOW\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "text = [row.split() for row in df['text']]\n",
    "text_vec = []\n",
    "text_avg_vec = []\n",
    "count = 0\n",
    "for row in tqdm(range(len(text))):\n",
    "    [word.split(' ', 1) for word in text[row]]\n",
    "  \n",
    "    for i in range(len(text[row])):\n",
    "        try:\n",
    "            text_vec.append(model_w2v[text[row][i]])\n",
    "            count = count + 1\n",
    "        except KeyError as e:\n",
    "            text_vec.append([0]*100)\n",
    "  \n",
    "    average = np.add.reduce(text_vec)\n",
    "    if count==0:\n",
    "        count = 1\n",
    "    average = np.divide(average, count)\n",
    "    text_avg_vec.append(average)\n",
    "    text_vec = []\n",
    "    count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "U1tz0Ls2F1IY"
   },
   "outputs": [],
   "source": [
    "for i in range(len(text_avg_vec)):\n",
    "    if type(text_avg_vec[i]) != np.ndarray:\n",
    "        text_avg_vec[i] = np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "cPDOp-FDF1Ia"
   },
   "outputs": [],
   "source": [
    "x_test = text_avg_vec\n",
    "#x_test = np.c_[x_test]\n",
    "\n",
    "df['label'] = df['label'] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "8aWBzII0F1Ic"
   },
   "outputs": [],
   "source": [
    "#Logistic Regression Results\n",
    "\n",
    "predicted = lr.predict(x_test)\n",
    "\n",
    "df['prediction'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "-MFxnsMbF1If",
    "outputId": "b3e10d03-5ec1-4f3c-edd3-b49278b13a4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.84831461 0.8540179 ]\n",
      "recall: [0.85460282 0.84770889]\n",
      "fscore: [0.85144711 0.8508517 ]\n",
      "support: [19966 20034]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "predicted = predicted \n",
    "y_test = df['label']\n",
    "\n",
    "precision, recall, fscore, support = score(y_test, predicted, labels=[0, 1])\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "Zy4rr4qUF1Ik",
    "outputId": "4ef95d11-642c-42c3-90a9-df0ccad3440b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.85115\n",
      "False pos: 0.072575\n",
      "False neg: 0.076275\n"
     ]
    }
   ],
   "source": [
    "count_true = 0\n",
    "false_pos = 0\n",
    "false_neg = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['label'] == row['prediction']:\n",
    "        count_true = count_true + 1\n",
    "    elif row['label'] == 0 and row['prediction'] == 1:\n",
    "        false_pos = false_pos + 1\n",
    "    elif row['label'] == 1 and row['prediction'] == 0:\n",
    "        false_neg = false_neg + 1\n",
    "\n",
    "print(\"Accuracy on test set: \" + str(count_true/len(df)))\n",
    "print(\"False pos: \" + str(false_pos/len(df)))\n",
    "print(\"False neg: \" + str(false_neg/len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "xS_UTlNGF1In"
   },
   "outputs": [],
   "source": [
    "#Naive Bayes Results\n",
    "\n",
    "predicted = clf.predict(x_test)\n",
    "\n",
    "df['prediction'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "51HmYgNcF1Iq",
    "outputId": "7acaad1c-92b8-4421-f81f-1d4ffef900f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.731675\n",
      "False pos: 0.13345\n",
      "False neg: 0.134875\n"
     ]
    }
   ],
   "source": [
    "count_true = 0\n",
    "false_pos = 0\n",
    "false_neg = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['label'] == row['prediction']:\n",
    "        count_true = count_true + 1\n",
    "    elif row['label'] == 0 and row['prediction'] == 1:\n",
    "        false_pos = false_pos + 1\n",
    "    elif row['label'] == 1 and row['prediction'] == 0:\n",
    "        false_neg = false_neg + 1\n",
    "\n",
    "print(\"Accuracy on test set: \" + str(count_true/len(df)))\n",
    "print(\"False pos: \" + str(false_pos/len(df)))\n",
    "print(\"False neg: \" + str(false_neg/len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "hq9MOKkNF1Is",
    "outputId": "adc1c3cf-4764-4648-ca9d-5e5088a5e9fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.72965524 0.73368589]\n",
      "recall: [0.73174531 0.73160539]\n",
      "fscore: [0.73069878 0.73264416]\n",
      "support: [19899 20101]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "predicted = predicted \n",
    "y_test = df['label']\n",
    "\n",
    "precision, recall, fscore, support = score(y_test, predicted, labels=[0, 1])\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "WerwnNosF1Iu"
   },
   "outputs": [],
   "source": [
    "#Deep neural network Results\n",
    "\n",
    "nn_model = tf.keras.models.load_model('NN.model')\n",
    "predicted = nn_model.predict_classes(x_test)\n",
    "df['prediction'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "LfQ3hMytF1Iw",
    "outputId": "d96bff4b-8230-4b0e-8ee1-fb3a22ce42ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.861675\n",
      "False pos: 0.069775\n",
      "False neg: 0.06855\n"
     ]
    }
   ],
   "source": [
    "count_true = 0\n",
    "false_pos = 0\n",
    "false_neg = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['label'] == row['prediction']:\n",
    "        count_true = count_true + 1\n",
    "    elif row['label'] == 0 and row['prediction'] == 1:\n",
    "        false_pos = false_pos + 1\n",
    "    elif row['label'] == 1 and row['prediction'] == 0:\n",
    "        false_neg = false_neg + 1\n",
    "\n",
    "print(\"Accuracy on test set: \" + str(count_true/len(df)))\n",
    "print(\"False pos: \" + str(false_pos/len(df)))\n",
    "print(\"False neg: \" + str(false_neg/len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "uewcIZN0F1Iy",
    "outputId": "628013bb-70ab-4698-bef7-54d1c4985588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.86253572 0.86081883]\n",
      "recall: [0.86042208 0.86292741]\n",
      "fscore: [0.86147761 0.86187183]\n",
      "support: [19996 20004]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "predicted = predicted \n",
    "y_test = df['label']\n",
    "\n",
    "precision, recall, fscore, support = score(y_test, predicted, labels=[0, 1])\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "AOxM0zx0F1I1"
   },
   "outputs": [],
   "source": [
    "#CNN Results\n",
    "\n",
    "x_test1 = x_test.reshape(40000, x_test.shape[1], 1)\n",
    "\n",
    "cnn_model = tf.keras.models.load_model('CNN.model')\n",
    "predicted = cnn_model.predict_classes(x_test1)\n",
    "df['prediction'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "51lqmB38F1I3",
    "outputId": "0b25e3e2-6b93-4ca4-e347-fb53adf58f6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.854125\n",
      "False pos: 0.072325\n",
      "False neg: 0.07355\n"
     ]
    }
   ],
   "source": [
    "count_true = 0\n",
    "false_pos = 0\n",
    "false_neg = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['label'] == row['prediction']:\n",
    "        count_true = count_true + 1\n",
    "    elif row['label'] == 0 and row['prediction'] == 1:\n",
    "        false_pos = false_pos + 1\n",
    "    elif row['label'] == 1 and row['prediction'] == 0:\n",
    "        false_neg = false_neg + 1\n",
    "\n",
    "print(\"Accuracy on test set: \" + str(count_true/len(df)))\n",
    "print(\"False pos: \" + str(false_pos/len(df)))\n",
    "print(\"False neg: \" + str(false_neg/len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "8Yyza72TF1I5",
    "outputId": "df8f6b3e-1cbf-484c-8674-341eec3b0aac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.85323023 0.8550238 ]\n",
      "recall: [0.85532106 0.85292941]\n",
      "fscore: [0.85427437 0.85397532]\n",
      "support: [19996 20004]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "predicted = predicted \n",
    "y_test = df['label']\n",
    "\n",
    "precision, recall, fscore, support = score(y_test, predicted, labels=[0, 1])\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "v0EmOIWIF1I7",
    "outputId": "5986c1bc-8a81-48b3-fa1d-8f99fd358cb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training SVM\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "svm_model = svm.SVC(kernel='linear')\n",
    "\n",
    "svm_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "-hu5y0uHF1I9"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the classifier\n",
    "with open('svm_model.pkl', 'wb') as fid:\n",
    "    pickle.dump(svm_model, fid)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "oQLQTQ4jF1JA"
   },
   "outputs": [],
   "source": [
    "#SVM Results\n",
    "\n",
    "predicted = svm_model.predict(x_test)\n",
    "df['prediction'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "gyQmocGLF1JC",
    "outputId": "cc98cd51-c86e-4ef3-bbd9-df71181235f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.849375\n",
      "False pos: 0.071425\n",
      "False neg: 0.0792\n"
     ]
    }
   ],
   "source": [
    "count_true = 0\n",
    "false_pos = 0\n",
    "false_neg = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['label'] == row['prediction']:\n",
    "        count_true = count_true + 1\n",
    "    elif row['label'] == 0 and row['prediction'] == 1:\n",
    "        false_pos = false_pos + 1\n",
    "    elif row['label'] == 1 and row['prediction'] == 0:\n",
    "        false_neg = false_neg + 1\n",
    "\n",
    "print(\"Accuracy on test set: \" + str(count_true/len(df)))\n",
    "print(\"False pos: \" + str(false_pos/len(df)))\n",
    "print(\"False neg: \" + str(false_neg/len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "LLscdhbuF1JE",
    "outputId": "e0aaef82-9256-4441-c63c-052117482b5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.84399468 0.85492307]\n",
      "recall: [0.85712142 0.84163167]\n",
      "fscore: [0.85050741 0.84822531]\n",
      "support: [19996 20004]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "predicted = predicted \n",
    "y_test = df['label']\n",
    "\n",
    "precision, recall, fscore, support = score(y_test, predicted, labels=[0, 1])\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "N81aqGhcF1JG",
    "outputId": "ea601ee6-06ae-4cbe-af15-3b0a24ebc2e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=False, random_state=456,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=500, criterion='entropy', random_state=456)\n",
    "\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "6MsQCBf3F1JI"
   },
   "outputs": [],
   "source": [
    "#Random Forest Results\n",
    "\n",
    "predicted = rf.predict(x_test)\n",
    "df['prediction'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "H7TmpaMBF1JK",
    "outputId": "4de1f2b1-d398-4fde-8ae5-cbf5aef2692d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.832175\n",
      "False pos: 0.078425\n",
      "False neg: 0.0894\n"
     ]
    }
   ],
   "source": [
    "count_true = 0\n",
    "false_pos = 0\n",
    "false_neg = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['label'] == row['prediction']:\n",
    "        count_true = count_true + 1\n",
    "    elif row['label'] == 0 and row['prediction'] == 1:\n",
    "        false_pos = false_pos + 1\n",
    "    elif row['label'] == 1 and row['prediction'] == 0:\n",
    "        false_neg = false_neg + 1\n",
    "\n",
    "print(\"Accuracy on test set: \" + str(count_true/len(df)))\n",
    "print(\"False pos: \" + str(false_pos/len(df)))\n",
    "print(\"False neg: \" + str(false_neg/len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "WU-u8OMPF1JN",
    "outputId": "b94f8431-f099-4157-b6f2-507cdb732d54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.82500612 0.83966266]\n",
      "recall: [0.84311862 0.82123575]\n",
      "fscore: [0.83396404 0.83034699]\n",
      "support: [19996 20004]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "predicted = predicted \n",
    "y_test = df['label']\n",
    "\n",
    "precision, recall, fscore, support = score(y_test, predicted, labels=[0, 1])\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "hq2FXRCjF1JP"
   },
   "outputs": [],
   "source": [
    "#Training second layer Random Forest (Combined models)\n",
    "\n",
    "lr_predict = lr.predict(x_train)\n",
    "nb_predict = clf.predict(x_train)\n",
    "svm_predict = svm_model.predict(x_train)\n",
    "rf_predict = rf.predict(x_train)\n",
    "nn_predict = nn_model.predict_classes(x_train)\n",
    "cnn_predict = cnn_model.predict_classes(x_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "-YT_3kBqF1JS",
    "outputId": "90ecedeb-a70c-4e94-e084-e73b35b7f571"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_predict</th>\n",
       "      <th>nb_predict</th>\n",
       "      <th>svm_predict</th>\n",
       "      <th>rf_predict</th>\n",
       "      <th>nn_predict</th>\n",
       "      <th>cnn_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lr_predict  nb_predict  svm_predict  rf_predict  nn_predict  cnn_predict\n",
       "0           0           0            0           0           0            0\n",
       "1           1           1            1           1           1            1\n",
       "2           1           0            1           0           1            1\n",
       "3           1           1            1           1           1            1\n",
       "4           1           0            1           1           1            1"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features = pd.DataFrame()\n",
    "new_features['lr_predict'] = lr_predict\n",
    "new_features['nb_predict'] = nb_predict\n",
    "new_features['svm_predict'] = svm_predict\n",
    "new_features['rf_predict'] = rf_predict\n",
    "new_features['nn_predict'] = nn_predict\n",
    "new_features['cnn_predict'] = cnn_predict\n",
    "\n",
    "new_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "bURoSX-wF1JU",
    "outputId": "331a754d-14f5-4f4f-9eb9-11328852ca81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_2 = RandomForestClassifier(n_estimators=500, criterion='entropy')\n",
    "\n",
    "rf_2.fit(new_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "80WkqP51F1JW"
   },
   "outputs": [],
   "source": [
    "#Combined model results (2nd layer Random Forest)\n",
    "\n",
    "lr_predict = lr.predict(x_test)\n",
    "nb_predict = clf.predict(x_test)\n",
    "svm_predict = svm_model.predict(x_test)\n",
    "rf_predict = rf.predict(x_test)\n",
    "nn_predict = nn_model.predict_classes(x_test)\n",
    "cnn_predict = cnn_model.predict_classes(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "rIxEnxfQF1JY",
    "outputId": "769539ec-cde6-403d-f71e-be09a01c3c6e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_predict</th>\n",
       "      <th>nb_predict</th>\n",
       "      <th>svm_predict</th>\n",
       "      <th>rf_predict</th>\n",
       "      <th>nn_predict</th>\n",
       "      <th>cnn_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lr_predict  nb_predict  svm_predict  rf_predict  nn_predict  cnn_predict\n",
       "0           1           1            1           1           1            1\n",
       "1           0           0            0           0           0            0\n",
       "2           0           0            0           0           0            0\n",
       "3           1           1            1           1           1            1\n",
       "4           0           0            0           0           0            0"
      ]
     },
     "execution_count": 80,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features = pd.DataFrame()\n",
    "new_features['lr_predict'] = lr_predict\n",
    "new_features['nb_predict'] = nb_predict\n",
    "new_features['svm_predict'] = svm_predict\n",
    "new_features['rf_predict'] = rf_predict\n",
    "new_features['nn_predict'] = nn_predict\n",
    "new_features['cnn_predict'] = cnn_predict\n",
    "\n",
    "new_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "efQi8alRF1Ja"
   },
   "outputs": [],
   "source": [
    "predicted = rf_2.predict(new_features)\n",
    "df['prediction'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "qLjwfpn0F1Jd",
    "outputId": "ff52fff4-afdf-408e-d73a-1741fa971db5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.832175\n",
      "False pos: 0.078425\n",
      "False neg: 0.0894\n"
     ]
    }
   ],
   "source": [
    "count_true = 0\n",
    "false_pos = 0\n",
    "false_neg = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['label'] == row['prediction']:\n",
    "        count_true = count_true + 1\n",
    "    elif row['label'] == 0 and row['prediction'] == 1:\n",
    "        false_pos = false_pos + 1\n",
    "    elif row['label'] == 1 and row['prediction'] == 0:\n",
    "        false_neg = false_neg + 1\n",
    "\n",
    "print(\"Accuracy on test set: \" + str(count_true/len(df)))\n",
    "print(\"False pos: \" + str(false_pos/len(df)))\n",
    "print(\"False neg: \" + str(false_neg/len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "KSsk_Uq3F1Jh",
    "outputId": "25309aea-a722-479d-b107-65b3c6e1f4c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.82500612 0.83966266]\n",
      "recall: [0.84311862 0.82123575]\n",
      "fscore: [0.83396404 0.83034699]\n",
      "support: [19996 20004]\n"
     ]
    }
   ],
   "source": [
    "predicted = predicted \n",
    "y_test = df['label']\n",
    "\n",
    "precision, recall, fscore, support = score(y_test, predicted, labels=[0, 1])\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "pROVhx4tF1Jl",
    "outputId": "227207c0-b229-4d43-dc69-16943fbe6b09"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_predict</th>\n",
       "      <th>nb_predict</th>\n",
       "      <th>svm_predict</th>\n",
       "      <th>rf_predict</th>\n",
       "      <th>nn_predict</th>\n",
       "      <th>cnn_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lr_predict  nb_predict  svm_predict  rf_predict  nn_predict  cnn_predict\n",
       "0           0           0            0           0           0            0\n",
       "1           1           1            1           1           1            1\n",
       "2           1           0            1           0           1            1\n",
       "3           1           1            1           1           1            1\n",
       "4           1           0            1           1           1            1"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trial: Training deep neural net as second layer (Combined models)\n",
    "\n",
    "lr_predict_train = lr.predict(x_train)\n",
    "nb_predict_train = clf.predict(x_train)\n",
    "svm_predict_train = svm_model.predict(x_train)\n",
    "rf_predict_train = rf.predict(x_train)\n",
    "nn_predict_train = nn_model.predict_classes(x_train)\n",
    "cnn_predict_train = cnn_model.predict_classes(x_train1)\n",
    "\n",
    "new_features_train = pd.DataFrame()\n",
    "new_features_train['lr_predict'] = lr_predict_train\n",
    "new_features_train['nb_predict'] = nb_predict_train\n",
    "new_features_train['svm_predict'] = svm_predict_train\n",
    "new_features_train['rf_predict'] = rf_predict_train\n",
    "new_features_train['nn_predict'] = nn_predict_train\n",
    "new_features_train['cnn_predict'] = cnn_predict_train\n",
    "\n",
    "new_features_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "0irBw0OEF1Jn",
    "outputId": "268579ae-d997-45fd-b50d-b87a38ed137e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 16)                112       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,921\n",
      "Trainable params: 3,633\n",
      "Non-trainable params: 288\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 96000 samples, validate on 24000 samples\n",
      "Epoch 1/10\n",
      "95840/96000 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9938\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.99996, saving model to NN2.model\n",
      "INFO:tensorflow:Assets written to: NN2.model/assets\n",
      "96000/96000 [==============================] - 26s 273us/sample - loss: 0.0192 - accuracy: 0.9938 - val_loss: 5.5018e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "95936/96000 [============================>.] - ETA: 0s - loss: 0.0026 - accuracy: 0.9996\n",
      "Epoch 00002: val_accuracy did not improve from 0.99996\n",
      "96000/96000 [==============================] - 22s 229us/sample - loss: 0.0026 - accuracy: 0.9996 - val_loss: 6.4392e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "95776/96000 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9997\n",
      "Epoch 00003: val_accuracy did not improve from 0.99996\n",
      "96000/96000 [==============================] - 23s 236us/sample - loss: 0.0018 - accuracy: 0.9997 - val_loss: 6.4423e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "95872/96000 [============================>.] - ETA: 0s - loss: 8.0100e-04 - accuracy: 0.9999\n",
      "Epoch 00004: val_accuracy did not improve from 0.99996\n",
      "96000/96000 [==============================] - 23s 239us/sample - loss: 7.9994e-04 - accuracy: 0.9999 - val_loss: 6.4297e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "95840/96000 [============================>.] - ETA: 0s - loss: 1.8519e-04 - accuracy: 1.0000\n",
      "Epoch 00005: val_accuracy did not improve from 0.99996\n",
      "96000/96000 [==============================] - 23s 242us/sample - loss: 1.8491e-04 - accuracy: 1.0000 - val_loss: 6.4271e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 6.5417e-04 - accuracy: 0.9999\n",
      "Epoch 00006: val_accuracy did not improve from 0.99996\n",
      "96000/96000 [==============================] - 23s 239us/sample - loss: 6.5395e-04 - accuracy: 0.9999 - val_loss: 6.4271e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "95872/96000 [============================>.] - ETA: 0s - loss: 1.1154e-04 - accuracy: 1.0000\n",
      "Epoch 00007: val_accuracy did not improve from 0.99996\n",
      "96000/96000 [==============================] - 24s 251us/sample - loss: 1.1139e-04 - accuracy: 1.0000 - val_loss: 6.4271e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "95872/96000 [============================>.] - ETA: 0s - loss: 2.8745e-04 - accuracy: 1.0000\n",
      "Epoch 00008: val_accuracy did not improve from 0.99996\n",
      "96000/96000 [==============================] - 24s 247us/sample - loss: 2.8707e-04 - accuracy: 1.0000 - val_loss: 6.4271e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "95968/96000 [============================>.] - ETA: 0s - loss: 3.9127e-04 - accuracy: 1.0000\n",
      "Epoch 00009: val_accuracy did not improve from 0.99996\n",
      "96000/96000 [==============================] - 24s 250us/sample - loss: 3.9114e-04 - accuracy: 1.0000 - val_loss: 6.4271e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "95776/96000 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9999\n",
      "Epoch 00010: val_accuracy did not improve from 0.99996\n",
      "96000/96000 [==============================] - 24s 251us/sample - loss: 0.0011 - accuracy: 0.9999 - val_loss: 6.4271e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# mini batches Nadam optimizer with dropout and batch normalization\n",
    "epochs = 10\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(16, input_dim=6))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(16))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(rate = 0.2))\n",
    "model.add(layers.Dense(16))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(32))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(rate = 0.3))\n",
    "model.add(layers.Dense(32))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(32))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(rate = 0.4))\n",
    "\n",
    "model.add(layers.Dense(1))\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999),\n",
    "              metrics=['accuracy'])\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"NN2.model\", monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "\n",
    "model.summary()\n",
    "model1 = model.fit(new_features_train, y_train, epochs=epochs, validation_split=0.2, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "RC0RNV-cF1Jr",
    "outputId": "d57f7063-852c-4271-ee9e-2258c1b70a3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "#Combined model results (Deep Neural Net 2nd Layer)\n",
    "\n",
    "nn2_model = tf.keras.models.load_model('NN2.model')\n",
    "predicted = nn2_model.predict_classes(new_features)\n",
    "df['prediction'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "0JD3bvyfF1Jt",
    "outputId": "1ff3b0a5-8ea6-4942-e8c2-fd9b8165a3b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.832175\n",
      "False pos: 0.078425\n",
      "False neg: 0.0894\n"
     ]
    }
   ],
   "source": [
    "count_true = 0\n",
    "false_pos = 0\n",
    "false_neg = 0\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['label'] == row['prediction']:\n",
    "        count_true = count_true + 1\n",
    "    elif row['label'] == 0 and row['prediction'] == 1:\n",
    "        false_pos = false_pos + 1\n",
    "    elif row['label'] == 1 and row['prediction'] == 0:\n",
    "        false_neg = false_neg + 1\n",
    "\n",
    "print(\"Accuracy on test set: \" + str(count_true/len(df)))\n",
    "print(\"False pos: \" + str(false_pos/len(df)))\n",
    "print(\"False neg: \" + str(false_neg/len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "5K8etHSUF1Jw",
    "outputId": "c02e5208-69f6-4d58-e861-5c5a4f3c8029"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.82500612 0.83966266]\n",
      "recall: [0.84311862 0.82123575]\n",
      "fscore: [0.83396404 0.83034699]\n",
      "support: [19996 20004]\n"
     ]
    }
   ],
   "source": [
    "predicted = predicted \n",
    "y_test = df['label']\n",
    "\n",
    "precision, recall, fscore, support = score(y_test, predicted, labels=[0, 1])\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Logistic Regression Extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### CV Simple LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cvscores=[]\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "for train_index, val_index in kf.split(x_train, y_train):\n",
    "    x_train_kf, x_val_kf = x_train[train_index], x_train[val_index]\n",
    "    y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    model = LogisticRegression(random_state=42, max_iter=200)\n",
    "    model.fit(x_train_kf, y_train_kf)\n",
    "    \n",
    "    scores = model.score(x_val_kf, y_val_kf)\n",
    "    cvscores.append(scores * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.93% (+/- 0.45%)\n"
     ]
    }
   ],
   "source": [
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Logistic GridSearchCV for L2 and no penalty with compatible solvers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "NPJT_R2BF1Jy",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 32 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "[Parallel(n_jobs=1)]: Done 320 out of 320 | elapsed: 54.1min finished\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-5163982e2ae0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_score'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def pipeline(X_train, X_test, y_train, y_test, model, param_grid, cv=10):\n",
    "    gs = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, verbose=1)\n",
    "\n",
    "    fitted = gs.fit(X_train, y_train)\n",
    "    pred = fitted.predict(X_test)\n",
    "\n",
    "    return fitted, pred\n",
    "\n",
    "\n",
    "param_grid = {'penalty':['l2','none'], 'C':[0.5,0.8,1.0,1.2], 'random_state':[42], 'solver':['newton-cg','lbfgs','sag','saga']}\n",
    "\n",
    "model = LogisticRegression(n_jobs=-1)\n",
    "\n",
    "model, pred = pipeline(x_train, x_val, y_train, y_val, model, param_grid, cv=10)\n",
    "\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8504166666666666\n",
      "{'C': 0.5, 'penalty': 'l2', 'random_state': 42, 'solver': 'sag'}\n"
     ]
    }
   ],
   "source": [
    "print(model.best_score_)\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### GridSearchCV for L1 L2 with liblinear and saga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1539: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 12.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n",
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed: 23.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.849725\n",
      "{'C': 0.8, 'penalty': 'l1', 'random_state': 42, 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def pipeline(X_train, X_test, y_train, y_test, model, param_grid, cv=10):\n",
    "    gs = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, verbose=1)\n",
    "\n",
    "    fitted = gs.fit(X_train, y_train)\n",
    "    pred = fitted.predict(X_test)\n",
    "\n",
    "    return fitted, pred\n",
    "\n",
    "param_grid = {'penalty':['l1','l2'], 'C':[0.5,0.8,1.0,1.2], 'random_state':[42], 'solver':['liblinear','saga']}\n",
    "\n",
    "model = LogisticRegression(n_jobs=-1)\n",
    "\n",
    "model, pred = pipeline(x_train, x_val, y_train, y_val, model, param_grid, cv=10)\n",
    "\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Saga with Elasticnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 16 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed: 11.6min finished\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-74886991f6a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_score'"
     ]
    }
   ],
   "source": [
    "param_grid = {'penalty':['elasticnet'], 'C':[0.5,0.8,1.0,1.2], 'random_state':[42], 'solver':['saga'], 'l1_ratio':[0.2,0.4,0.6,0.8]}\n",
    "\n",
    "model = LogisticRegression(n_jobs=-1)\n",
    "\n",
    "model, pred = pipeline(x_train, x_val, y_train, y_val, model, param_grid, cv=10)\n",
    "\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8497333333333333\n",
      "{'C': 0.5, 'l1_ratio': 0.4, 'penalty': 'elasticnet', 'random_state': 42, 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "print(model.best_score_)\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Evaluate on test set with simple logreg and best params log reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "simple_logreg = LogisticRegression(random_state=42, max_iter=200)\n",
    "best_logreg = LogisticRegression(C=0.5, random_state=42, solver='sag')\n",
    "\n",
    "simple_logreg.fit(x_train, y_train)\n",
    "best_logreg.fit(x_train, y_train)\n",
    "\n",
    "predicted_simple = simple_logreg.predict(x_test)\n",
    "predicted_best = best_logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.851175"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_logreg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85     19966\n",
      "           1       0.85      0.85      0.85     20034\n",
      "\n",
      "    accuracy                           0.85     40000\n",
      "   macro avg       0.85      0.85      0.85     40000\n",
      "weighted avg       0.85      0.85      0.85     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, predicted_simple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85115"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_logreg.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85     19966\n",
      "           1       0.85      0.85      0.85     20034\n",
      "\n",
      "    accuracy                           0.85     40000\n",
      "   macro avg       0.85      0.85      0.85     40000\n",
      "weighted avg       0.85      0.85      0.85     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.851825\n",
      "0.8517\n"
     ]
    }
   ],
   "source": [
    "print(simple_logreg.score(x_val, y_val))\n",
    "print(best_logreg.score(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Modifications with ElasticNet L1 ratio and other parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8526\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "elastic_logreg = LogisticRegression(penalty='elasticnet', C=(1+np.sqrt(5))/2, random_state=42, solver='saga', l1_ratio=0.6)\n",
    "\n",
    "elastic_logreg.fit(x_train, y_train)\n",
    "print(elastic_logreg.score(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.850825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85     20318\n",
      "           1       0.85      0.85      0.85     19682\n",
      "\n",
      "    accuracy                           0.85     40000\n",
      "   macro avg       0.85      0.85      0.85     40000\n",
      "weighted avg       0.85      0.85      0.85     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_test = df['label']\n",
    "predicted = elastic_logreg.predict(x_test)\n",
    "\n",
    "print(elastic_logreg.score(x_test, y_test))\n",
    "print(classification_report(y_test, predicted))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.852525\n"
     ]
    }
   ],
   "source": [
    "elastic_logreg_1 = LogisticRegression(penalty='elasticnet', C=1/((1+np.sqrt(5))/2), random_state=42, solver='saga', l1_ratio=0.4)\n",
    "\n",
    "elastic_logreg_1.fit(x_train, y_train)\n",
    "print(elastic_logreg_1.score(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.850775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85     20318\n",
      "           1       0.85      0.85      0.85     19682\n",
      "\n",
      "    accuracy                           0.85     40000\n",
      "   macro avg       0.85      0.85      0.85     40000\n",
      "weighted avg       0.85      0.85      0.85     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = elastic_logreg_1.predict(x_test)\n",
    "\n",
    "print(elastic_logreg_1.score(x_test, y_test))\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Combined features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Creating train features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_style": "center",
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "4PJ8MohpF1Ht"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import glob\n",
    "import os\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_style": "center",
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "mKHimIdaF1Hy",
    "outputId": "ace05c3c-6a8d-4ec0-8db9-6e016f161f7c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2700725</th>\n",
       "      <td>Bringing out the hidden complexity of Haydn: T...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119872</th>\n",
       "      <td>Not worth the money or the wait: I picked up t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3522157</th>\n",
       "      <td>Great Grilling: Bought this griil for my son a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2657983</th>\n",
       "      <td>Attractive and Good Quality: This pewter bear ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713772</th>\n",
       "      <td>not worth a penny: I wore these boots for the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  label\n",
       "2700725  Bringing out the hidden complexity of Haydn: T...      2\n",
       "2119872  Not worth the money or the wait: I picked up t...      1\n",
       "3522157  Great Grilling: Bought this griil for my son a...      2\n",
       "2657983  Attractive and Good Quality: This pewter bear ...      2\n",
       "713772   not worth a penny: I wore these boots for the ...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load training file\n",
    "\n",
    "text_file = open(\"train.txt.txt\", \"r\", encoding=\"utf8\")\n",
    "lines = text_file.read().split('\\n')\n",
    "\n",
    "labels = []\n",
    "for item in lines:\n",
    "    first_four_letters = item[:10]\n",
    "    if first_four_letters == '__label__1':\n",
    "        labels.append(int(1))\n",
    "    else:\n",
    "        labels.append(int(2))\n",
    "        \n",
    "def remove_label(s):\n",
    "    return s[11:]\n",
    "lines = [remove_label(s) for s in lines]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['text'] = lines\n",
    "df['label'] = labels\n",
    "\n",
    "df = df.sample(160000)\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "zUTpz7RZF1H1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Clean text\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "#lowercase and remove punctuation, remove stopwords        \n",
    "df['text'] = df['text'].str.lower()\n",
    "df['text'] = df['text'].str.replace('-', ' ')\n",
    "df['text'] = df['text'].str.split(' ')\n",
    "df['text'] = df['text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].apply(lemmatize_text)\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].str.replace('\\\\', ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "v716GFtjF1H4"
   },
   "outputs": [],
   "source": [
    "#Train Word2Vec\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "text = [row.split() for row in df['text']]\n",
    "model_w2v = Word2Vec(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "DeO9W1afF1H6"
   },
   "outputs": [],
   "source": [
    "model_w2v.save('model_w2v.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "okwCWi8WF1H8",
    "outputId": "9de3534a-ed71-436e-8977-6e81c611e796",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04579c30c74444ab2d12330a4ef6dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=160000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Average Word2Vec Vectors for BOW\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "text_vec = []\n",
    "text_avg_vec = []\n",
    "count = 0\n",
    "for row in tqdm(range(len(text))):\n",
    "    [word.split(' ', 1) for word in text[row]]\n",
    "  \n",
    "    for i in range(len(text[row])):\n",
    "        try:\n",
    "            text_vec.append(model_w2v[text[row][i]])\n",
    "            count = count + 1\n",
    "        except KeyError as e:\n",
    "            text_vec.append([0]*100)\n",
    "  \n",
    "    average = np.add.reduce(text_vec)\n",
    "    if count==0:\n",
    "        count = 1\n",
    "    average = np.divide(average, count)\n",
    "    text_avg_vec.append(average)\n",
    "    text_vec = []\n",
    "    count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "TEdesJclF1H_"
   },
   "outputs": [],
   "source": [
    "for i in range(len(text_avg_vec)):\n",
    "    if type(text_avg_vec[i]) != np.ndarray:\n",
    "        text_avg_vec[i] = np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.40853754, -0.38679563, -0.95826751, -0.3337734 , -0.20393041,\n",
       "       -0.22012257, -0.32521616, -0.17680886,  0.12652912,  0.53451511,\n",
       "        0.09845188,  0.00559624, -0.56184483,  0.13195313, -0.93501698,\n",
       "        0.13119618,  0.34067749, -0.66382934,  0.27455967, -0.61961251,\n",
       "       -0.01541351, -0.08719711, -0.03395919,  0.2928971 ,  0.4032096 ,\n",
       "        0.45737276, -0.2549706 ,  0.30731208, -0.42949031, -0.10682201,\n",
       "       -0.05644133,  0.10391716, -0.05313593, -0.48116139, -0.0093661 ,\n",
       "        0.24171149,  0.78481103, -0.04739485,  0.02662561, -0.32518936,\n",
       "       -0.79016119,  0.4302174 ,  0.22235376, -0.54802614, -0.1610888 ,\n",
       "       -0.41376326,  0.20082239, -0.57389326, -0.07668226,  1.01035403,\n",
       "       -0.14983318, -0.08995562,  0.13779828, -0.05832776, -0.87467947,\n",
       "       -0.22567286, -0.43352613, -0.17384305, -0.21771592,  0.60231309,\n",
       "       -0.01061233, -0.61366194, -0.60999509, -0.13262224, -0.26967327,\n",
       "        0.03996115,  0.65497345, -0.22238656, -0.04122111,  0.11840897,\n",
       "        0.39895687,  0.44815396, -0.22472042,  0.90747737,  0.31958251,\n",
       "       -0.14155013, -0.69817632, -0.24301972, -0.2605117 ,  0.15782405,\n",
       "       -0.1521483 , -0.46800126,  0.00296922, -0.30987776,  0.84621929,\n",
       "        0.02040247, -0.06908493, -0.62923544,  0.84533902, -0.809288  ,\n",
       "       -0.21081433, -0.34279193,  0.03083434,  0.75118573,  0.80738219,\n",
       "       -0.88965881, -0.26860247,  0.01033185,  0.27364254,  0.08658777])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_avg_vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=2900)\n",
    "\n",
    "tfidf_features = tfidf.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 2900)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = text_avg_vec\n",
    "x_train = np.array(x_train).reshape(-1, 100)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 3000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.concatenate((x_train, tfidf_features.toarray()), axis=1)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "df['label'] = df['label'] - 1\n",
    "\n",
    "y_train= np.asarray(df.label)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=40000, random_state=42)\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Default Logistic Regression on new combined features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 3000 features total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.31% (+/- 0.31%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cvscores=[]\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "for train_index, val_index in kf.split(x_train, y_train):\n",
    "    x_train_kf, x_val_kf = x_train[train_index], x_train[val_index]\n",
    "    y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    model = LogisticRegression(random_state=42, max_iter=2000)\n",
    "    model.fit(x_train_kf, y_train_kf)\n",
    "    \n",
    "    scores = model.score(x_val_kf, y_val_kf)\n",
    "    cvscores.append(scores * 100)\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 5000 features total\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=4900)\n",
    "\n",
    "tfidf_features = tfidf.fit_transform(df['text'])\n",
    "x_train = text_avg_vec\n",
    "x_train = np.array(x_train).reshape(-1, 100)\n",
    "\n",
    "x_train = np.concatenate((x_train, tfidf_features.toarray()), axis=1)\n",
    "\n",
    "y_train= np.asarray(df.label)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=40000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.73% (+/- 0.22%)\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cvscores=[]\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "for train_index, val_index in kf.split(x_train, y_train):\n",
    "    x_train_kf, x_val_kf = x_train[train_index], x_train[val_index]\n",
    "    y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    model = LogisticRegression(random_state=42, max_iter=2000)\n",
    "    model.fit(x_train_kf, y_train_kf)\n",
    "    \n",
    "    scores = model.score(x_val_kf, y_val_kf)\n",
    "    cvscores.append(scores * 100)\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#7500 features total\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=7400)\n",
    "\n",
    "tfidf_features = tfidf.fit_transform(df['text'])\n",
    "x_train = text_avg_vec\n",
    "x_train = np.array(x_train).reshape(-1, 100)\n",
    "\n",
    "x_train = np.concatenate((x_train, tfidf_features.toarray()), axis=1)\n",
    "\n",
    "y_train= np.asarray(df.label)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=40000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.90% (+/- 0.26%)\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cvscores=[]\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "for train_index, val_index in kf.split(x_train, y_train):\n",
    "    x_train_kf, x_val_kf = x_train[train_index], x_train[val_index]\n",
    "    y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    model = LogisticRegression(random_state=42, max_iter=2000)\n",
    "    model.fit(x_train_kf, y_train_kf)\n",
    "    \n",
    "    scores = model.score(x_val_kf, y_val_kf)\n",
    "    cvscores.append(scores * 100)\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 10,000 features total\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=9900)\n",
    "\n",
    "tfidf_features = tfidf.fit_transform(df['text'])\n",
    "x_train = text_avg_vec\n",
    "x_train = np.array(x_train).reshape(-1, 100)\n",
    "\n",
    "x_train = np.concatenate((x_train, tfidf_features.toarray()), axis=1)\n",
    "\n",
    "y_train= np.asarray(df.label)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=40000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.00% (+/- 0.27%)\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cvscores=[]\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "for train_index, val_index in kf.split(x_train, y_train):\n",
    "    x_train_kf, x_val_kf = x_train[train_index], x_train[val_index]\n",
    "    y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    model = LogisticRegression(random_state=42, max_iter=2000)\n",
    "    model.fit(x_train_kf, y_train_kf)\n",
    "    \n",
    "    scores = model.score(x_val_kf, y_val_kf)\n",
    "    cvscores.append(scores * 100)\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 15,000 features total\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=14900)\n",
    "\n",
    "tfidf_features = tfidf.fit_transform(df['text'])\n",
    "x_train = text_avg_vec\n",
    "x_train = np.array(x_train).reshape(-1, 100)\n",
    "\n",
    "x_train = np.concatenate((x_train, tfidf_features.toarray()), axis=1)\n",
    "\n",
    "y_train= np.asarray(df.label)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=40000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.09% (+/- 0.20%)\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cvscores=[]\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "for train_index, val_index in kf.split(x_train, y_train):\n",
    "    x_train_kf, x_val_kf = x_train[train_index], x_train[val_index]\n",
    "    y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    model = LogisticRegression(random_state=42, max_iter=2000)\n",
    "    model.fit(x_train_kf, y_train_kf)\n",
    "    \n",
    "    scores = model.score(x_val_kf, y_val_kf)\n",
    "    cvscores.append(scores * 100)\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 20,000 features total\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=19900)\n",
    "\n",
    "tfidf_features = tfidf.fit_transform(df['text'])\n",
    "x_train = text_avg_vec\n",
    "x_train = np.array(x_train).reshape(-1, 100)\n",
    "\n",
    "x_train = np.concatenate((x_train, tfidf_features.toarray()), axis=1)\n",
    "\n",
    "y_train= np.asarray(df.label)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=40000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.12% (+/- 0.23%)\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cvscores=[]\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "for train_index, val_index in kf.split(x_train, y_train):\n",
    "    x_train_kf, x_val_kf = x_train[train_index], x_train[val_index]\n",
    "    y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    model = LogisticRegression(random_state=42, max_iter=2000)\n",
    "    model.fit(x_train_kf, y_train_kf)\n",
    "    \n",
    "    scores = model.score(x_val_kf, y_val_kf)\n",
    "    cvscores.append(scores * 100)\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#30,000 features total\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=29900)\n",
    "\n",
    "tfidf_features = tfidf.fit_transform(df['text'])\n",
    "x_train = text_avg_vec\n",
    "x_train = np.array(x_train).reshape(-1, 100)\n",
    "\n",
    "x_train = np.concatenate((x_train, tfidf_features.toarray()), axis=1)\n",
    "\n",
    "y_train= np.asarray(df.label)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=40000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.18% (+/- 0.23%)\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cvscores=[]\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "for train_index, val_index in kf.split(x_train, y_train):\n",
    "    x_train_kf, x_val_kf = x_train[train_index], x_train[val_index]\n",
    "    y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    model = LogisticRegression(random_state=42, max_iter=2000)\n",
    "    model.fit(x_train_kf, y_train_kf)\n",
    "    \n",
    "    scores = model.score(x_val_kf, y_val_kf)\n",
    "    cvscores.append(scores * 100)\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 40,000 features total\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=39900)\n",
    "\n",
    "tfidf_features = tfidf.fit_transform(df['text'])\n",
    "x_train = text_avg_vec\n",
    "x_train = np.array(x_train).reshape(-1, 100)\n",
    "x_train = sparse.csr_matrix(x_train)\n",
    "\n",
    "x_train = sparse.hstack([x_train, tfidf_features])\n",
    "\n",
    "y_train= np.asarray(df.label)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=40000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.14% (+/- 0.12%)\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cvscores=[]\n",
    "\n",
    "for train_index, val_index in kf.split(x_train, y_train):\n",
    "    x_train_kf, x_val_kf = x_train[train_index], x_train[val_index]\n",
    "    y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    model = LogisticRegression(random_state=42, max_iter=2000)\n",
    "    model.fit(x_train_kf, y_train_kf)\n",
    "    \n",
    "    scores = model.score(x_val_kf, y_val_kf)\n",
    "    cvscores.append(scores * 100)\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.12% (+/- 0.19%)\n"
     ]
    }
   ],
   "source": [
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 50,000 features total\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=49900)\n",
    "\n",
    "tfidf_features = tfidf.fit_transform(df['text'])\n",
    "x_train = text_avg_vec\n",
    "x_train = np.array(x_train).reshape(-1, 100)\n",
    "x_train = sparse.csr_matrix(x_train)\n",
    "\n",
    "x_train = sparse.hstack([x_train, tfidf_features])\n",
    "y_train= np.asarray(df.label)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=40000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.12% (+/- 0.15%)\n"
     ]
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cvscores=[]\n",
    "\n",
    "for train_index, val_index in kf.split(x_train, y_train):\n",
    "    x_train_kf, x_val_kf = x_train[train_index], x_train[val_index]\n",
    "    y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    model = LogisticRegression(random_state=42, max_iter=2000)\n",
    "    model.fit(x_train_kf, y_train_kf)\n",
    "    \n",
    "    scores = model.score(x_val_kf, y_val_kf)\n",
    "    cvscores.append(scores * 100)\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 2000 features total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.92% (+/- 0.23%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cvscores=[]\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "for train_index, val_index in kf.split(x_train, y_train):\n",
    "    x_train_kf, x_val_kf = x_train[train_index], x_train[val_index]\n",
    "    y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    model = LogisticRegression(random_state=42, max_iter=2000)\n",
    "    model.fit(x_train_kf, y_train_kf)\n",
    "    \n",
    "    scores = model.score(x_val_kf, y_val_kf)\n",
    "    cvscores.append(scores * 100)\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sparse matrix length is ambiguous; use getnnz() or shape[0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-e12a9a89941e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;31m# non-zeros is more important.  For now, raise an exception!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         raise TypeError(\"sparse matrix length is ambiguous; use getnnz()\"\n\u001b[0m\u001b[1;32m    296\u001b[0m                         \" or shape[0]\")\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sparse matrix length is ambiguous; use getnnz() or shape[0]"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "xtrain = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "ytrain= np.asarray(df.label)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xval, ytrain, yval = train_test_split(xtrain, ytrain, test_size=40000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xtest = vectorizer.transform(df['text'])\n",
    "ytest = df['label'] - 1\n",
    "ytrain = ytrain - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "yval = yval-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.888925\n",
      "0.88775\n"
     ]
    }
   ],
   "source": [
    "logreg_eval = LogisticRegression(random_state=42, max_iter=2000)\n",
    "\n",
    "logreg_eval.fit(xtrain, ytrain)\n",
    "\n",
    "print(logreg_eval.score(xval, yval))\n",
    "print(logreg_eval.score(xtest, ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 3406721)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Full TFIDF + Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Training file prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160000\n"
     ]
    }
   ],
   "source": [
    "#Load training file\n",
    "\n",
    "text_file = open(\"train.txt.txt\", \"r\", encoding=\"utf8\")\n",
    "lines = text_file.read().split('\\n')\n",
    "\n",
    "labels = []\n",
    "for item in lines:\n",
    "    first_four_letters = item[:10]\n",
    "    if first_four_letters == '__label__1':\n",
    "        labels.append(int(1))\n",
    "    else:\n",
    "        labels.append(int(2))\n",
    "        \n",
    "def remove_label(s):\n",
    "    return s[11:]\n",
    "lines = [remove_label(s) for s in lines]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['text'] = lines\n",
    "df['label'] = labels\n",
    "\n",
    "df = df.sample(160000)\n",
    "print(len(df))\n",
    "\n",
    "#Clean text\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "#lowercase and remove punctuation, remove stopwords        \n",
    "df['text'] = df['text'].str.lower()\n",
    "df['text'] = df['text'].str.replace('-', ' ')\n",
    "df['text'] = df['text'].str.split(' ')\n",
    "df['text'] = df['text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].apply(lemmatize_text)\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].str.replace('\\\\', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Train Word2Vec\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "text = [row.split() for row in df['text']]\n",
    "model_w2v = Word2Vec(text)\n",
    "\n",
    "model_w2v.save('model_w2v.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5536be66698b4b7d9b4961b86d06494f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=160000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Average Word2Vec Vectors for BOW\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "text_vec = []\n",
    "text_avg_vec = []\n",
    "count = 0\n",
    "for row in tqdm(range(len(text))):\n",
    "    [word.split(' ', 1) for word in text[row]]\n",
    "  \n",
    "    for i in range(len(text[row])):\n",
    "        try:\n",
    "            text_vec.append(model_w2v[text[row][i]])\n",
    "            count = count + 1\n",
    "        except KeyError as e:\n",
    "            text_vec.append([0]*100)\n",
    "  \n",
    "    average = np.add.reduce(text_vec)\n",
    "    if count==0:\n",
    "        count = 1\n",
    "    average = np.divide(average, count)\n",
    "    text_avg_vec.append(average)\n",
    "    text_vec = []\n",
    "    count = 0\n",
    "    \n",
    "for i in range(len(text_avg_vec)):\n",
    "    if type(text_avg_vec[i]) != np.ndarray:\n",
    "        text_avg_vec[i] = np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<160000x3404513 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 12033848 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2))\n",
    "tfidf_train = tfidf.fit_transform(df['text'])\n",
    "\n",
    "tfidf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sparse matrix length is ambiguous; use getnnz() or shape[0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bb70b7c362fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;31m# non-zeros is more important.  For now, raise an exception!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         raise TypeError(\"sparse matrix length is ambiguous; use getnnz()\"\n\u001b[0m\u001b[1;32m    296\u001b[0m                         \" or shape[0]\")\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sparse matrix length is ambiguous; use getnnz() or shape[0]"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "x_train = sparse.csr_matrix(np.array(text_avg_vec).reshape(-1, 100))\n",
    "\n",
    "x_train = sparse.hstack((x_train, tfidf_train))\n",
    "\n",
    "y_train = df['label'] - 1\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=40000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Test file prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Load and Clean test file\n",
    "\n",
    "text_file = open(\"test.txt.txt\", \"r\", encoding=\"utf8\")\n",
    "lines = text_file.read().split('\\n')\n",
    "\n",
    "labels = []\n",
    "for item in lines:\n",
    "    first_four_letters = item[:10]\n",
    "    if first_four_letters == '__label__1':\n",
    "        labels.append(int(1))\n",
    "    else:\n",
    "        labels.append(int(2))\n",
    "        \n",
    "def remove_label(s):\n",
    "    return s[11:]\n",
    "lines = [remove_label(s) for s in lines]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['text'] = lines\n",
    "df['label'] = labels\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "#lowercase and remove punctuation, remove stopwords        \n",
    "df['text'] = df['text'].str.lower()\n",
    "df['text'] = df['text'].str.replace('-', ' ')\n",
    "df['text'] = df['text'].str.split(' ')\n",
    "df['text'] = df['text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].apply(lemmatize_text)\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].str.replace('\\\\', ' ')\n",
    "\n",
    "df = df.sample(40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9321172f0e25447f9758ab947dc70545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Embed Word2Vec and BOW\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "text = [row.split() for row in df['text']]\n",
    "text_vec = []\n",
    "text_avg_vec = []\n",
    "count = 0\n",
    "for row in tqdm(range(len(text))):\n",
    "    [word.split(' ', 1) for word in text[row]]\n",
    "  \n",
    "    for i in range(len(text[row])):\n",
    "        try:\n",
    "            text_vec.append(model_w2v[text[row][i]])\n",
    "            count = count + 1\n",
    "        except KeyError as e:\n",
    "            text_vec.append([0]*100)\n",
    "  \n",
    "    average = np.add.reduce(text_vec)\n",
    "    if count==0:\n",
    "        count = 1\n",
    "    average = np.divide(average, count)\n",
    "    text_avg_vec.append(average)\n",
    "    text_vec = []\n",
    "    count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(text_avg_vec)):\n",
    "    if type(text_avg_vec[i]) != np.ndarray:\n",
    "        text_avg_vec[i] = np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 3404613)\n"
     ]
    }
   ],
   "source": [
    "tfidf_test = tfidf.transform(df['text'])\n",
    "x_test = sparse.csr_matrix(np.array(text_avg_vec).reshape(-1, 100))\n",
    "\n",
    "x_test = sparse.hstack((x_test, tfidf_test))\n",
    "\n",
    "y_test = df['label'] - 1\n",
    "\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Evaluate Default Logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.10% (+/- 0.29%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cvscores=[]\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "for train_index, val_index in kf.split(x_train, y_train):\n",
    "    x_train_kf, x_val_kf = x_train[train_index], x_train[val_index]\n",
    "    y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    model = LogisticRegression(random_state=42, max_iter=2000)\n",
    "    model.fit(x_train_kf, y_train_kf)\n",
    "    \n",
    "    scores = model.score(x_val_kf, y_val_kf)\n",
    "    cvscores.append(scores * 100)\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### 30,000 features with Optimum Logreg from GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\danie\\anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import glob\n",
    "import os\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:64: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc475d9667134d6a9da19c3c696cd795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=160000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:69: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Load training file\n",
    "\n",
    "text_file = open(\"train.txt.txt\", \"r\", encoding=\"utf8\")\n",
    "lines = text_file.read().split('\\n')\n",
    "\n",
    "labels = []\n",
    "for item in lines:\n",
    "    first_four_letters = item[:10]\n",
    "    if first_four_letters == '__label__1':\n",
    "        labels.append(int(1))\n",
    "    else:\n",
    "        labels.append(int(2))\n",
    "        \n",
    "def remove_label(s):\n",
    "    return s[11:]\n",
    "lines = [remove_label(s) for s in lines]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['text'] = lines\n",
    "df['label'] = labels\n",
    "\n",
    "df = df.sample(160000)\n",
    "print(len(df))\n",
    "df.head()\n",
    "\n",
    "#Clean text\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "#lowercase and remove punctuation, remove stopwords        \n",
    "df['text'] = df['text'].str.lower()\n",
    "df['text'] = df['text'].str.replace('-', ' ')\n",
    "df['text'] = df['text'].str.split(' ')\n",
    "df['text'] = df['text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].apply(lemmatize_text)\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].str.replace('\\\\', ' ')\n",
    "\n",
    "\n",
    "#Train Word2Vec\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "text = [row.split() for row in df['text']]\n",
    "model_w2v = Word2Vec(text)\n",
    "\n",
    "model_w2v.save('model_w2v.bin')\n",
    "\n",
    "#Average Word2Vec Vectors for BOW\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "text_vec = []\n",
    "text_avg_vec = []\n",
    "count = 0\n",
    "for row in tqdm(range(len(text))):\n",
    "    [word.split(' ', 1) for word in text[row]]\n",
    "  \n",
    "    for i in range(len(text[row])):\n",
    "        try:\n",
    "            text_vec.append(model_w2v[text[row][i]])\n",
    "            count = count + 1\n",
    "        except KeyError as e:\n",
    "            text_vec.append([0]*100)\n",
    "  \n",
    "    average = np.add.reduce(text_vec)\n",
    "    if count==0:\n",
    "        count = 1\n",
    "    average = np.divide(average, count)\n",
    "    text_avg_vec.append(average)\n",
    "    text_vec = []\n",
    "    count = 0\n",
    "\n",
    "for i in range(len(text_avg_vec)):\n",
    "    if type(text_avg_vec[i]) != np.ndarray:\n",
    "        text_avg_vec[i] = np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=29900)\n",
    "\n",
    "tfidf_features = tfidf.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<160000x29900 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6508195 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 100)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = text_avg_vec\n",
    "x_train = np.array(x_train).reshape(-1, 100)\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "x_train = sparse.csr_matrix(x_train)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 29900)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 30000)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = sparse.hstack([x_train, tfidf_features])\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 30000)\n",
      "(40000, 30000)\n"
     ]
    }
   ],
   "source": [
    "df['label'] = df['label'] - 1\n",
    "\n",
    "y_train= np.asarray(df.label)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=40000, random_state=42)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9164333333333333\n",
      "0.89175\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(random_state=42, max_iter=2000)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(model.score(x_train, y_train))\n",
    "print(model.score(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9025416666666667\n",
      "0.887975\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=42, max_iter=2000, C=0.5, penalty='l2', solver='sag')\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(model.score(x_train, y_train))\n",
    "print(model.score(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.15% (+/- 0.16%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cvscores=[]\n",
    "\n",
    "for train_index, val_index in kf.split(x_train, y_train):\n",
    "    x_train_kf, x_val_kf = x_train[train_index], x_train[val_index]\n",
    "    y_train_kf, y_val_kf = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    model = LogisticRegression(random_state=42, max_iter=2000)\n",
    "    model.fit(x_train_kf, y_train_kf)\n",
    "    \n",
    "    scores = model.score(x_val_kf, y_val_kf)\n",
    "    cvscores.append(scores * 100)\n",
    "    \n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Test Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "Rfak2r_3F1IT"
   },
   "outputs": [],
   "source": [
    "#Load and Clean test file\n",
    "\n",
    "text_file = open(\"test.txt.txt\", \"r\", encoding=\"utf8\")\n",
    "lines = text_file.read().split('\\n')\n",
    "\n",
    "labels = []\n",
    "for item in lines:\n",
    "    first_four_letters = item[:10]\n",
    "    if first_four_letters == '__label__1':\n",
    "        labels.append(int(1))\n",
    "    else:\n",
    "        labels.append(int(2))\n",
    "        \n",
    "def remove_label(s):\n",
    "    return s[11:]\n",
    "lines = [remove_label(s) for s in lines]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['text'] = lines\n",
    "df['label'] = labels\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "#lowercase and remove punctuation, remove stopwords        \n",
    "df['text'] = df['text'].str.lower()\n",
    "df['text'] = df['text'].str.replace('-', ' ')\n",
    "df['text'] = df['text'].str.split(' ')\n",
    "df['text'] = df['text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].apply(lemmatize_text)\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].str.replace('\\\\', ' ')\n",
    "\n",
    "df = df.sample(40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "cMhYlNcnF1IV",
    "outputId": "bdb06eba-7493-4e4f-d0f6-f6ab037e7f76",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91980dad1d724dd3a7f6854d3ea46be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Embed Word2Vec and BOW\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "text = [row.split() for row in df['text']]\n",
    "text_vec = []\n",
    "text_avg_vec = []\n",
    "count = 0\n",
    "for row in tqdm(range(len(text))):\n",
    "    [word.split(' ', 1) for word in text[row]]\n",
    "  \n",
    "    for i in range(len(text[row])):\n",
    "        try:\n",
    "            text_vec.append(model_w2v[text[row][i]])\n",
    "            count = count + 1\n",
    "        except KeyError as e:\n",
    "            text_vec.append([0]*100)\n",
    "  \n",
    "    average = np.add.reduce(text_vec)\n",
    "    if count==0:\n",
    "        count = 1\n",
    "    average = np.divide(average, count)\n",
    "    text_avg_vec.append(average)\n",
    "    text_vec = []\n",
    "    count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "U1tz0Ls2F1IY"
   },
   "outputs": [],
   "source": [
    "for i in range(len(text_avg_vec)):\n",
    "    if type(text_avg_vec[i]) != np.ndarray:\n",
    "        text_avg_vec[i] = np.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "cPDOp-FDF1Ia"
   },
   "outputs": [],
   "source": [
    "x_test = text_avg_vec\n",
    "#x_test = np.c_[x_test]\n",
    "\n",
    "df['label'] = df['label'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 30000)\n"
     ]
    }
   ],
   "source": [
    "tfidf_features = tfidf.transform(df['text'])\n",
    "\n",
    "x_test = np.array(text_avg_vec).reshape(-1, 100)\n",
    "x_test = sparse.csr_matrix(x_test)\n",
    "x_test = sparse.hstack([x_test, tfidf_features])\n",
    "\n",
    "y_test = np.asarray(df['label'])\n",
    "\n",
    "print((x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8927\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89     20068\n",
      "           1       0.89      0.90      0.89     19932\n",
      "\n",
      "    accuracy                           0.89     40000\n",
      "   macro avg       0.89      0.89      0.89     40000\n",
      "weighted avg       0.89      0.89      0.89     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predicted = model.predict(x_test)\n",
    "\n",
    "print(model.score(x_test, y_test))\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Neural Net with new Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Constructing train features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:74: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2d39b28f7a4c12b49620281793c528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=160000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:79: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(120000, 30000)\n",
      "(40000, 30000)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import glob\n",
    "import os\n",
    "import string\n",
    "\n",
    "#Load training file\n",
    "\n",
    "text_file = open(\"train.txt.txt\", \"r\", encoding=\"utf8\")\n",
    "lines = text_file.read().split('\\n')\n",
    "\n",
    "labels = []\n",
    "for item in lines:\n",
    "    first_four_letters = item[:10]\n",
    "    if first_four_letters == '__label__1':\n",
    "        labels.append(int(1))\n",
    "    else:\n",
    "        labels.append(int(2))\n",
    "        \n",
    "def remove_label(s):\n",
    "    return s[11:]\n",
    "lines = [remove_label(s) for s in lines]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['text'] = lines\n",
    "df['label'] = labels\n",
    "\n",
    "df = df.sample(160000)\n",
    "print(len(df))\n",
    "df.head()\n",
    "\n",
    "#Clean text\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "#lowercase and remove punctuation, remove stopwords        \n",
    "df['text'] = df['text'].str.lower()\n",
    "df['text'] = df['text'].str.replace('-', ' ')\n",
    "df['text'] = df['text'].str.split(' ')\n",
    "df['text'] = df['text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].apply(lemmatize_text)\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].str.replace('\\\\', ' ')\n",
    "\n",
    "\n",
    "#Train Word2Vec\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "text = [row.split() for row in df['text']]\n",
    "model_w2v = Word2Vec(text)\n",
    "\n",
    "model_w2v.save('model_w2v.bin')\n",
    "\n",
    "#Average Word2Vec Vectors for BOW\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "text_vec = []\n",
    "text_avg_vec = []\n",
    "count = 0\n",
    "for row in tqdm(range(len(text))):\n",
    "    [word.split(' ', 1) for word in text[row]]\n",
    "  \n",
    "    for i in range(len(text[row])):\n",
    "        try:\n",
    "            text_vec.append(model_w2v[text[row][i]])\n",
    "            count = count + 1\n",
    "        except KeyError as e:\n",
    "            text_vec.append([0]*100)\n",
    "  \n",
    "    average = np.add.reduce(text_vec)\n",
    "    if count==0:\n",
    "        count = 1\n",
    "    average = np.divide(average, count)\n",
    "    text_avg_vec.append(average)\n",
    "    text_vec = []\n",
    "    count = 0\n",
    "\n",
    "for i in range(len(text_avg_vec)):\n",
    "    if type(text_avg_vec[i]) != np.ndarray:\n",
    "        text_avg_vec[i] = np.zeros(100)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=29900)\n",
    "\n",
    "tfidf_features = tfidf.fit_transform(df['text'])\n",
    "\n",
    "x_train = text_avg_vec\n",
    "x_train = np.array(x_train).reshape(-1, 100)\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "x_train = sparse.csr_matrix(x_train)\n",
    "x_train.shape\n",
    "\n",
    "x_train = sparse.hstack([x_train, tfidf_features])\n",
    "x_train.shape\n",
    "\n",
    "df['label'] = df['label'] - 1\n",
    "\n",
    "y_train= np.asarray(df.label)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=40000, random_state=42)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Neural net training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=2, dtype='int32')\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes=2, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size, shuffle):\n",
    "    number_of_batches = X.shape[0]/batch_size\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[batch_index,:].toarray()\n",
    "        y_batch = y[batch_index]\n",
    "        counter += 1\n",
    "        yield X_batch, y_batch\n",
    "        if (counter == number_of_batches):\n",
    "            if shuffle:\n",
    "                np.random.shuffle(sample_index)\n",
    "            counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 32)                960032    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 973,858\n",
      "Trainable params: 973,282\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Deep Neural net Training\n",
    "\n",
    "from keras import layers\n",
    "from keras.models import Sequential, load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# mini batches Nadam optimizer with dropout and batch normalization\n",
    "epochs = 10\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(32, input_dim=30000))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(32))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(rate = 0.2))\n",
    "model.add(layers.Dense(32))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(rate = 0.3))\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "#model.add(layers.Dropout(rate = 0.4))\n",
    "\n",
    "model.add(layers.Dense(2))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999),\n",
    "              metrics=['accuracy'])\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"NN.model\", monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "\n",
    "model.summary()\n",
    "#model1 = model.fit(x_train, y_train, epochs=epochs, validation_split=0.2, callbacks=[checkpoint])\n",
    "#history = model.fit(x_train, y_train, epochs = epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 99s 26ms/step - loss: 0.2772 - accuracy: 0.8855 - val_loss: 0.2656 - val_accuracy: 0.8908\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 132s 35ms/step - loss: 0.2220 - accuracy: 0.9126 - val_loss: 0.2736 - val_accuracy: 0.8847\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 170s 45ms/step - loss: 0.1800 - accuracy: 0.9299 - val_loss: 0.2790 - val_accuracy: 0.8911\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 193s 51ms/step - loss: 0.1431 - accuracy: 0.9442 - val_loss: 0.2914 - val_accuracy: 0.8897\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 193s 51ms/step - loss: 0.1169 - accuracy: 0.9549 - val_loss: 0.3412 - val_accuracy: 0.8825\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 185s 49ms/step - loss: 0.0956 - accuracy: 0.9634 - val_loss: 0.3945 - val_accuracy: 0.8856\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 184s 49ms/step - loss: 0.0797 - accuracy: 0.9701 - val_loss: 0.3603 - val_accuracy: 0.8742\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 226s 60ms/step - loss: 0.0675 - accuracy: 0.9753 - val_loss: 0.4040 - val_accuracy: 0.8778\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 246s 66ms/step - loss: 0.0576 - accuracy: 0.9786 - val_loss: 0.4624 - val_accuracy: 0.8788\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 253s 68ms/step - loss: 0.0511 - accuracy: 0.9817 - val_loss: 0.4815 - val_accuracy: 0.8796\n"
     ]
    }
   ],
   "source": [
    "model1 = model.fit_generator(generator=batch_generator(x_train, y_train, 32, True), validation_data=(x_val, y_val), steps_per_epoch=(x_train.shape[0])/32,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model1.history['accuracy'])\n",
    "plt.plot(model1.history['val_accuracy'])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(model1.history['loss'])\n",
    "plt.plot(model1.history['val_loss'])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 32)                960032    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 973,858\n",
      "Trainable params: 973,282\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# mini batches Nadam optimizer with dropout and batch normalization\n",
    "epochs = 10\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(32, input_dim=30000))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense(32))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense(32))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(rate = 0.4))\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(rate = 0.4))\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(layers.Dense(2))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999),\n",
    "              metrics=['accuracy'])\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"NN.model\", monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 107s 29ms/step - loss: 0.4040 - accuracy: 0.8172 - val_loss: 0.2778 - val_accuracy: 0.8910\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 219s 58ms/step - loss: 0.2982 - accuracy: 0.8791 - val_loss: 0.2587 - val_accuracy: 0.8942\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 195s 52ms/step - loss: 0.2604 - accuracy: 0.8963 - val_loss: 0.2550 - val_accuracy: 0.8965\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 162s 43ms/step - loss: 0.2302 - accuracy: 0.9095 - val_loss: 0.2556 - val_accuracy: 0.8946\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 232s 62ms/step - loss: 0.2071 - accuracy: 0.9205 - val_loss: 0.2667 - val_accuracy: 0.8943\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 246s 65ms/step - loss: 0.1893 - accuracy: 0.9278 - val_loss: 0.2619 - val_accuracy: 0.8943\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 228s 61ms/step - loss: 0.1699 - accuracy: 0.9365 - val_loss: 0.2704 - val_accuracy: 0.8931\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 188s 50ms/step - loss: 0.1584 - accuracy: 0.9408 - val_loss: 0.2763 - val_accuracy: 0.8905\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 179s 48ms/step - loss: 0.1480 - accuracy: 0.9455 - val_loss: 0.2874 - val_accuracy: 0.8911\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 184s 49ms/step - loss: 0.1404 - accuracy: 0.9484 - val_loss: 0.2861 - val_accuracy: 0.8896\n"
     ]
    }
   ],
   "source": [
    "model1 = model.fit_generator(generator=batch_generator(x_train, y_train, 32, True), validation_data=(x_val, y_val), steps_per_epoch=(x_train.shape[0])/32,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model1.history['accuracy'])\n",
    "plt.plot(model1.history['val_accuracy'])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(model1.history['loss'])\n",
    "plt.plot(model1.history['val_loss'])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 32)                960032    \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 973,858\n",
      "Trainable params: 973,282\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# mini batches Nadam optimizer with dropout and batch normalization\n",
    "epochs = 10\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(32, input_dim=30000, activation='relu', kernel_regularizer=keras.regularizers.l2()))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(32, activation='relu', kernel_regularizer=keras.regularizers.l2()))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(32, activation='relu', kernel_regularizer=keras.regularizers.l2()))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2()))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(rate = 0.5))\n",
    "model.add(layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2()))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(rate = 0.5))\n",
    "model.add(layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2()))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Dense(2))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999),\n",
    "              metrics=['accuracy'])\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"NN.model\", monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3750/3750 [==============================] - 114s 30ms/step - loss: 0.8514 - accuracy: 0.7890 - val_loss: 0.5231 - val_accuracy: 0.8493\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.52309, saving model to NN.model\n",
      "Epoch 2/100\n",
      "3750/3750 [==============================] - 160s 43ms/step - loss: 0.5687 - accuracy: 0.8221 - val_loss: 0.5355 - val_accuracy: 0.8444\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.52309\n",
      "Epoch 3/100\n",
      "3750/3750 [==============================] - 164s 44ms/step - loss: 0.5560 - accuracy: 0.8247 - val_loss: 0.5080 - val_accuracy: 0.8478\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.52309 to 0.50798, saving model to NN.model\n",
      "Epoch 4/100\n",
      "3750/3750 [==============================] - 166s 44ms/step - loss: 0.5471 - accuracy: 0.8262 - val_loss: 0.5278 - val_accuracy: 0.8310\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.50798\n",
      "Epoch 5/100\n",
      "3750/3750 [==============================] - 166s 44ms/step - loss: 0.5459 - accuracy: 0.8250 - val_loss: 0.4984 - val_accuracy: 0.8444\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.50798 to 0.49844, saving model to NN.model\n",
      "Epoch 6/100\n",
      "3750/3750 [==============================] - 167s 44ms/step - loss: 0.5443 - accuracy: 0.8272 - val_loss: 0.5045 - val_accuracy: 0.8424\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.49844\n",
      "Epoch 7/100\n",
      "3750/3750 [==============================] - 167s 44ms/step - loss: 0.5443 - accuracy: 0.8276 - val_loss: 0.4856 - val_accuracy: 0.8498\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.49844 to 0.48556, saving model to NN.model\n",
      "Epoch 8/100\n",
      "3750/3750 [==============================] - 167s 44ms/step - loss: 0.5397 - accuracy: 0.8275 - val_loss: 0.4875 - val_accuracy: 0.8472\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.48556\n",
      "Epoch 9/100\n",
      "3750/3750 [==============================] - 167s 45ms/step - loss: 0.5432 - accuracy: 0.8272 - val_loss: 0.5125 - val_accuracy: 0.8464\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.48556\n",
      "Epoch 10/100\n",
      "3750/3750 [==============================] - 168s 45ms/step - loss: 0.5410 - accuracy: 0.8275 - val_loss: 0.5077 - val_accuracy: 0.8436\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.48556\n",
      "Epoch 11/100\n",
      "3750/3750 [==============================] - 167s 45ms/step - loss: 0.5405 - accuracy: 0.8266 - val_loss: 0.4994 - val_accuracy: 0.8483\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.48556\n",
      "Epoch 12/100\n",
      "3750/3750 [==============================] - 168s 45ms/step - loss: 0.5393 - accuracy: 0.8256 - val_loss: 0.5017 - val_accuracy: 0.8482\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.48556\n",
      "Epoch 13/100\n",
      "3750/3750 [==============================] - 169s 45ms/step - loss: 0.5392 - accuracy: 0.8280 - val_loss: 0.4995 - val_accuracy: 0.8429\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.48556\n",
      "Epoch 14/100\n",
      "3750/3750 [==============================] - 169s 45ms/step - loss: 0.5371 - accuracy: 0.8271 - val_loss: 0.4758 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.48556 to 0.47577, saving model to NN.model\n",
      "Epoch 15/100\n",
      "3750/3750 [==============================] - 169s 45ms/step - loss: 0.5347 - accuracy: 0.8279 - val_loss: 0.4979 - val_accuracy: 0.8376\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.47577\n",
      "Epoch 16/100\n",
      "3750/3750 [==============================] - 170s 45ms/step - loss: 0.5337 - accuracy: 0.8270 - val_loss: 0.5020 - val_accuracy: 0.8347\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.47577\n",
      "Epoch 17/100\n",
      "3750/3750 [==============================] - 171s 45ms/step - loss: 0.5325 - accuracy: 0.8271 - val_loss: 0.4830 - val_accuracy: 0.8463\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.47577\n",
      "Epoch 18/100\n",
      "3750/3750 [==============================] - 171s 46ms/step - loss: 0.5318 - accuracy: 0.8267 - val_loss: 0.4972 - val_accuracy: 0.8460\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.47577\n",
      "Epoch 19/100\n",
      "3750/3750 [==============================] - 170s 45ms/step - loss: 0.5329 - accuracy: 0.8272 - val_loss: 0.4949 - val_accuracy: 0.8381\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.47577\n",
      "Epoch 20/100\n",
      "3750/3750 [==============================] - 171s 46ms/step - loss: 0.5305 - accuracy: 0.8263 - val_loss: 0.4807 - val_accuracy: 0.8475\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.47577\n",
      "Epoch 21/100\n",
      "3750/3750 [==============================] - 171s 46ms/step - loss: 0.5304 - accuracy: 0.8267 - val_loss: 0.4975 - val_accuracy: 0.8417\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.47577\n",
      "Epoch 22/100\n",
      "3750/3750 [==============================] - 169s 45ms/step - loss: 0.5315 - accuracy: 0.8282 - val_loss: 0.5301 - val_accuracy: 0.8222\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.47577\n",
      "Epoch 23/100\n",
      "3750/3750 [==============================] - 170s 45ms/step - loss: 0.5323 - accuracy: 0.8276 - val_loss: 0.4941 - val_accuracy: 0.8492\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.47577\n",
      "Epoch 24/100\n",
      "3750/3750 [==============================] - 170s 45ms/step - loss: 0.5327 - accuracy: 0.8269 - val_loss: 0.5034 - val_accuracy: 0.8341\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.47577\n",
      "Epoch 25/100\n",
      "3750/3750 [==============================] - 171s 46ms/step - loss: 0.5312 - accuracy: 0.8278 - val_loss: 0.5037 - val_accuracy: 0.8369\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.47577\n",
      "Epoch 26/100\n",
      "3750/3750 [==============================] - 170s 45ms/step - loss: 0.5316 - accuracy: 0.8284 - val_loss: 0.4843 - val_accuracy: 0.8438\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.47577\n",
      "Epoch 27/100\n",
      "3750/3750 [==============================] - 170s 45ms/step - loss: 0.5312 - accuracy: 0.8266 - val_loss: 0.4805 - val_accuracy: 0.8478\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.47577\n",
      "Epoch 28/100\n",
      "3750/3750 [==============================] - 171s 46ms/step - loss: 0.5311 - accuracy: 0.8272 - val_loss: 0.4813 - val_accuracy: 0.8468\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.47577\n",
      "Epoch 29/100\n",
      "3750/3750 [==============================] - 171s 45ms/step - loss: 0.5294 - accuracy: 0.8278 - val_loss: 0.4823 - val_accuracy: 0.8427\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.47577\n",
      "Epoch 30/100\n",
      "3750/3750 [==============================] - 170s 45ms/step - loss: 0.5318 - accuracy: 0.8267 - val_loss: 0.4820 - val_accuracy: 0.8497\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.47577\n",
      "Epoch 31/100\n",
      "3750/3750 [==============================] - 170s 45ms/step - loss: 0.5309 - accuracy: 0.8265 - val_loss: 0.5005 - val_accuracy: 0.8396\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.47577\n",
      "Epoch 32/100\n",
      "3750/3750 [==============================] - 170s 45ms/step - loss: 0.5301 - accuracy: 0.8268 - val_loss: 0.4900 - val_accuracy: 0.8382\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.47577\n",
      "Epoch 33/100\n",
      "3750/3750 [==============================] - 171s 45ms/step - loss: 0.5325 - accuracy: 0.8263 - val_loss: 0.4944 - val_accuracy: 0.8482\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.47577\n",
      "Epoch 34/100\n",
      "3750/3750 [==============================] - 170s 45ms/step - loss: 0.5309 - accuracy: 0.8276 - val_loss: 0.4936 - val_accuracy: 0.8440\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.47577\n",
      "Epoch 35/100\n",
      "3750/3750 [==============================] - 170s 45ms/step - loss: 0.5306 - accuracy: 0.8280 - val_loss: 0.4710 - val_accuracy: 0.8449\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.47577 to 0.47103, saving model to NN.model\n",
      "Epoch 36/100\n",
      "3750/3750 [==============================] - 170s 45ms/step - loss: 0.5289 - accuracy: 0.8265 - val_loss: 0.5084 - val_accuracy: 0.8306\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.47103\n",
      "Epoch 37/100\n",
      "3750/3750 [==============================] - 166s 44ms/step - loss: 0.5273 - accuracy: 0.8286 - val_loss: 0.4711 - val_accuracy: 0.8501\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.47103\n",
      "Epoch 38/100\n",
      "3750/3750 [==============================] - 165s 44ms/step - loss: 0.5296 - accuracy: 0.8256 - val_loss: 0.4829 - val_accuracy: 0.8486\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.47103\n",
      "Epoch 39/100\n",
      "3750/3750 [==============================] - 164s 44ms/step - loss: 0.5262 - accuracy: 0.8272 - val_loss: 0.4825 - val_accuracy: 0.8499\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.47103\n",
      "Epoch 40/100\n",
      "3750/3750 [==============================] - 165s 44ms/step - loss: 0.5277 - accuracy: 0.8265 - val_loss: 0.4855 - val_accuracy: 0.8436\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.47103\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3750/3750 [==============================] - 157s 42ms/step - loss: 0.5282 - accuracy: 0.8269 - val_loss: 0.4746 - val_accuracy: 0.8461\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.47103\n",
      "Epoch 42/100\n",
      "3750/3750 [==============================] - 157s 42ms/step - loss: 0.5266 - accuracy: 0.8283 - val_loss: 0.4763 - val_accuracy: 0.8489\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.47103\n",
      "Epoch 43/100\n",
      "3750/3750 [==============================] - 157s 42ms/step - loss: 0.5273 - accuracy: 0.8263 - val_loss: 0.4750 - val_accuracy: 0.8479\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.47103\n",
      "Epoch 44/100\n",
      "3750/3750 [==============================] - 157s 42ms/step - loss: 0.5282 - accuracy: 0.8273 - val_loss: 0.4659 - val_accuracy: 0.8507\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.47103 to 0.46591, saving model to NN.model\n",
      "Epoch 45/100\n",
      "3750/3750 [==============================] - 158s 42ms/step - loss: 0.5276 - accuracy: 0.8274 - val_loss: 0.5004 - val_accuracy: 0.8310\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.46591\n",
      "Epoch 46/100\n",
      "3750/3750 [==============================] - 158s 42ms/step - loss: 0.5270 - accuracy: 0.8272 - val_loss: 0.4781 - val_accuracy: 0.8485\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.46591\n",
      "Epoch 47/100\n",
      "3750/3750 [==============================] - 158s 42ms/step - loss: 0.5293 - accuracy: 0.8256 - val_loss: 0.4905 - val_accuracy: 0.8453\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.46591\n",
      "Epoch 48/100\n",
      "3750/3750 [==============================] - 158s 42ms/step - loss: 0.5287 - accuracy: 0.8258 - val_loss: 0.4649 - val_accuracy: 0.8494\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.46591 to 0.46494, saving model to NN.model\n",
      "Epoch 49/100\n",
      "3750/3750 [==============================] - 158s 42ms/step - loss: 0.5272 - accuracy: 0.8267 - val_loss: 0.4697 - val_accuracy: 0.8516\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.46494\n",
      "Epoch 50/100\n",
      "3750/3750 [==============================] - 159s 42ms/step - loss: 0.5271 - accuracy: 0.8270 - val_loss: 0.4659 - val_accuracy: 0.8479\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.46494\n",
      "Epoch 51/100\n",
      "3750/3750 [==============================] - 159s 42ms/step - loss: 0.5295 - accuracy: 0.8257 - val_loss: 0.4802 - val_accuracy: 0.8432\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.46494\n",
      "Epoch 52/100\n",
      "3750/3750 [==============================] - 159s 42ms/step - loss: 0.5278 - accuracy: 0.8271 - val_loss: 0.4822 - val_accuracy: 0.8470\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.46494\n",
      "Epoch 53/100\n",
      "3750/3750 [==============================] - 159s 43ms/step - loss: 0.5270 - accuracy: 0.8279 - val_loss: 0.4762 - val_accuracy: 0.8482\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.46494\n",
      "Epoch 54/100\n",
      "3750/3750 [==============================] - 160s 43ms/step - loss: 0.5287 - accuracy: 0.8263 - val_loss: 0.4975 - val_accuracy: 0.8408\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.46494\n",
      "Epoch 55/100\n",
      "3750/3750 [==============================] - 160s 43ms/step - loss: 0.5260 - accuracy: 0.8270 - val_loss: 0.4933 - val_accuracy: 0.8469\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.46494\n",
      "Epoch 56/100\n",
      "3750/3750 [==============================] - 160s 43ms/step - loss: 0.5281 - accuracy: 0.8266 - val_loss: 0.4749 - val_accuracy: 0.8502\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.46494\n",
      "Epoch 57/100\n",
      "3750/3750 [==============================] - 160s 43ms/step - loss: 0.5291 - accuracy: 0.8254 - val_loss: 0.5004 - val_accuracy: 0.8392\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.46494\n",
      "Epoch 58/100\n",
      "3750/3750 [==============================] - 160s 43ms/step - loss: 0.5279 - accuracy: 0.8266 - val_loss: 0.4889 - val_accuracy: 0.8487\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.46494\n",
      "Epoch 59/100\n",
      "3750/3750 [==============================] - 160s 43ms/step - loss: 0.5281 - accuracy: 0.8260 - val_loss: 0.4992 - val_accuracy: 0.8420\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.46494\n",
      "Epoch 60/100\n",
      "3750/3750 [==============================] - 160s 43ms/step - loss: 0.5272 - accuracy: 0.8276 - val_loss: 0.4859 - val_accuracy: 0.8436\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.46494\n",
      "Epoch 61/100\n",
      "3750/3750 [==============================] - 161s 43ms/step - loss: 0.5275 - accuracy: 0.8273 - val_loss: 0.4705 - val_accuracy: 0.8501\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.46494\n",
      "Epoch 62/100\n",
      "3750/3750 [==============================] - 160s 43ms/step - loss: 0.5278 - accuracy: 0.8268 - val_loss: 0.4656 - val_accuracy: 0.8460\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.46494\n",
      "Epoch 63/100\n",
      "3750/3750 [==============================] - 160s 43ms/step - loss: 0.5281 - accuracy: 0.8262 - val_loss: 0.4865 - val_accuracy: 0.8486\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.46494\n",
      "Epoch 64/100\n",
      "3750/3750 [==============================] - 160s 43ms/step - loss: 0.5274 - accuracy: 0.8271 - val_loss: 0.4849 - val_accuracy: 0.8428\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.46494\n",
      "Epoch 65/100\n",
      "3750/3750 [==============================] - 161s 43ms/step - loss: 0.5280 - accuracy: 0.8263 - val_loss: 0.5218 - val_accuracy: 0.8231\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.46494\n",
      "Epoch 66/100\n",
      "3750/3750 [==============================] - 160s 43ms/step - loss: 0.5286 - accuracy: 0.8260 - val_loss: 0.4742 - val_accuracy: 0.8454\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.46494\n",
      "Epoch 67/100\n",
      "3750/3750 [==============================] - 162s 43ms/step - loss: 0.5268 - accuracy: 0.8259 - val_loss: 0.4798 - val_accuracy: 0.8470\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.46494\n",
      "Epoch 68/100\n",
      "3750/3750 [==============================] - 162s 43ms/step - loss: 0.5285 - accuracy: 0.8263 - val_loss: 0.4879 - val_accuracy: 0.8468\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.46494\n",
      "Epoch 69/100\n",
      "3750/3750 [==============================] - 161s 43ms/step - loss: 0.5280 - accuracy: 0.8260 - val_loss: 0.4724 - val_accuracy: 0.8484\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.46494\n",
      "Epoch 70/100\n",
      "3750/3750 [==============================] - 161s 43ms/step - loss: 0.5278 - accuracy: 0.8273 - val_loss: 0.4751 - val_accuracy: 0.8485\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.46494\n",
      "Epoch 71/100\n",
      "3750/3750 [==============================] - 162s 43ms/step - loss: 0.5277 - accuracy: 0.8271 - val_loss: 0.4826 - val_accuracy: 0.8437\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.46494\n",
      "Epoch 72/100\n",
      "3750/3750 [==============================] - 162s 43ms/step - loss: 0.5290 - accuracy: 0.8252 - val_loss: 0.4965 - val_accuracy: 0.8396\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.46494\n",
      "Epoch 73/100\n",
      "3750/3750 [==============================] - 161s 43ms/step - loss: 0.5274 - accuracy: 0.8285 - val_loss: 0.4767 - val_accuracy: 0.8490\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.46494\n",
      "Epoch 74/100\n",
      "3750/3750 [==============================] - 162s 43ms/step - loss: 0.5268 - accuracy: 0.8268 - val_loss: 0.5227 - val_accuracy: 0.8317\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.46494\n",
      "Epoch 75/100\n",
      "3750/3750 [==============================] - 162s 43ms/step - loss: 0.5283 - accuracy: 0.8260 - val_loss: 0.4773 - val_accuracy: 0.8507\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.46494\n",
      "Epoch 76/100\n",
      "3750/3750 [==============================] - 162s 43ms/step - loss: 0.5277 - accuracy: 0.8256 - val_loss: 0.4867 - val_accuracy: 0.8433\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.46494\n",
      "Epoch 77/100\n",
      "3750/3750 [==============================] - 162s 43ms/step - loss: 0.5280 - accuracy: 0.8280 - val_loss: 0.4927 - val_accuracy: 0.8456\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.46494\n",
      "Epoch 78/100\n",
      "3750/3750 [==============================] - 162s 43ms/step - loss: 0.5298 - accuracy: 0.8258 - val_loss: 0.5024 - val_accuracy: 0.8283\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.46494\n",
      "Epoch 79/100\n",
      "3750/3750 [==============================] - 162s 43ms/step - loss: 0.5287 - accuracy: 0.8264 - val_loss: 0.4783 - val_accuracy: 0.8500\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.46494\n",
      "Epoch 80/100\n",
      "3750/3750 [==============================] - 162s 43ms/step - loss: 0.5281 - accuracy: 0.8268 - val_loss: 0.4720 - val_accuracy: 0.8486\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.46494\n",
      "Epoch 81/100\n",
      "3750/3750 [==============================] - 162s 43ms/step - loss: 0.5284 - accuracy: 0.8263 - val_loss: 0.4813 - val_accuracy: 0.8468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00081: val_loss did not improve from 0.46494\n",
      "Epoch 82/100\n",
      "3750/3750 [==============================] - 157s 42ms/step - loss: 0.5286 - accuracy: 0.8270 - val_loss: 0.4652 - val_accuracy: 0.8476\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.46494\n",
      "Epoch 83/100\n",
      "3750/3750 [==============================] - 158s 42ms/step - loss: 0.5275 - accuracy: 0.8267 - val_loss: 0.4918 - val_accuracy: 0.8445\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.46494\n",
      "Epoch 84/100\n",
      "3750/3750 [==============================] - 158s 42ms/step - loss: 0.5274 - accuracy: 0.8268 - val_loss: 0.4760 - val_accuracy: 0.8475\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.46494\n",
      "Epoch 85/100\n",
      "3750/3750 [==============================] - 158s 42ms/step - loss: 0.5262 - accuracy: 0.8288 - val_loss: 0.4886 - val_accuracy: 0.8421\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.46494\n",
      "Epoch 86/100\n",
      "3750/3750 [==============================] - 158s 42ms/step - loss: 0.5266 - accuracy: 0.8267 - val_loss: 0.4805 - val_accuracy: 0.8454\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.46494\n",
      "Epoch 87/100\n",
      "3750/3750 [==============================] - 159s 42ms/step - loss: 0.5282 - accuracy: 0.8270 - val_loss: 0.4931 - val_accuracy: 0.8335\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.46494\n",
      "Epoch 88/100\n",
      "3750/3750 [==============================] - 159s 42ms/step - loss: 0.5269 - accuracy: 0.8268 - val_loss: 0.4949 - val_accuracy: 0.8426\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.46494\n",
      "Epoch 89/100\n",
      "3750/3750 [==============================] - 159s 42ms/step - loss: 0.5274 - accuracy: 0.8266 - val_loss: 0.4898 - val_accuracy: 0.8434\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.46494\n",
      "Epoch 90/100\n",
      "3750/3750 [==============================] - 159s 42ms/step - loss: 0.5276 - accuracy: 0.8269 - val_loss: 0.4923 - val_accuracy: 0.8463\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.46494\n",
      "Epoch 91/100\n",
      "3750/3750 [==============================] - 159s 42ms/step - loss: 0.5284 - accuracy: 0.8258 - val_loss: 0.4839 - val_accuracy: 0.8474\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.46494\n",
      "Epoch 92/100\n",
      "3750/3750 [==============================] - 160s 43ms/step - loss: 0.5280 - accuracy: 0.8276 - val_loss: 0.4749 - val_accuracy: 0.8445\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.46494\n",
      "Epoch 93/100\n",
      "3750/3750 [==============================] - 160s 43ms/step - loss: 0.5267 - accuracy: 0.8274 - val_loss: 0.5050 - val_accuracy: 0.8306\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.46494\n",
      "Epoch 94/100\n",
      "3750/3750 [==============================] - 160s 43ms/step - loss: 0.5290 - accuracy: 0.8270 - val_loss: 0.4834 - val_accuracy: 0.8404\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.46494\n",
      "Epoch 95/100\n",
      "3750/3750 [==============================] - 160s 43ms/step - loss: 0.5286 - accuracy: 0.8267 - val_loss: 0.4931 - val_accuracy: 0.8420\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.46494\n",
      "Epoch 96/100\n",
      "3750/3750 [==============================] - 160s 43ms/step - loss: 0.5268 - accuracy: 0.8265 - val_loss: 0.4946 - val_accuracy: 0.8369\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.46494\n",
      "Epoch 97/100\n",
      "3750/3750 [==============================] - 161s 43ms/step - loss: 0.5275 - accuracy: 0.8267 - val_loss: 0.4867 - val_accuracy: 0.8432\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.46494\n",
      "Epoch 98/100\n",
      "3750/3750 [==============================] - 161s 43ms/step - loss: 0.5254 - accuracy: 0.8277 - val_loss: 0.4906 - val_accuracy: 0.8455\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.46494\n",
      "Epoch 99/100\n",
      "3750/3750 [==============================] - 161s 43ms/step - loss: 0.5278 - accuracy: 0.8284 - val_loss: 0.4909 - val_accuracy: 0.8415\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.46494\n",
      "Epoch 100/100\n",
      "3750/3750 [==============================] - 161s 43ms/step - loss: 0.5275 - accuracy: 0.8261 - val_loss: 0.4663 - val_accuracy: 0.8507\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.46494\n"
     ]
    }
   ],
   "source": [
    "model1 = model.fit_generator(generator=batch_generator(x_train, y_train, 32, True), validation_data=(x_val, y_val), steps_per_epoch=(x_train.shape[0])/32,epochs=100, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model1.history['accuracy'])\n",
    "plt.plot(model1.history['val_accuracy'])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(model1.history['loss'])\n",
    "plt.plot(model1.history['val_loss'])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Neural Net features added up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc50c454026244b5bc9b77449d83d066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=160000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:81: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(120000, 30000)\n",
      "(40000, 30000)\n"
     ]
    }
   ],
   "source": [
    "### Constructing train features\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import glob\n",
    "import os\n",
    "import string\n",
    "\n",
    "#Load training file\n",
    "\n",
    "text_file = open(\"train.txt.txt\", \"r\", encoding=\"utf8\")\n",
    "lines = text_file.read().split('\\n')\n",
    "\n",
    "labels = []\n",
    "for item in lines:\n",
    "    first_four_letters = item[:10]\n",
    "    if first_four_letters == '__label__1':\n",
    "        labels.append(int(1))\n",
    "    else:\n",
    "        labels.append(int(2))\n",
    "        \n",
    "def remove_label(s):\n",
    "    return s[11:]\n",
    "lines = [remove_label(s) for s in lines]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['text'] = lines\n",
    "df['label'] = labels\n",
    "\n",
    "df = df.sample(160000)\n",
    "print(len(df))\n",
    "df.head()\n",
    "\n",
    "#Clean text\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "#lowercase and remove punctuation, remove stopwords        \n",
    "df['text'] = df['text'].str.lower()\n",
    "df['text'] = df['text'].str.replace('-', ' ')\n",
    "df['text'] = df['text'].str.split(' ')\n",
    "df['text'] = df['text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].apply(lemmatize_text)\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].str.replace('\\\\', ' ')\n",
    "\n",
    "\n",
    "#Train Word2Vec\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "text = [row.split() for row in df['text']]\n",
    "model_w2v = Word2Vec(text)\n",
    "\n",
    "model_w2v.save('model_w2v.bin')\n",
    "\n",
    "#Average Word2Vec Vectors for BOW\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "text_vec = []\n",
    "text_avg_vec = []\n",
    "count = 0\n",
    "for row in tqdm(range(len(text))):\n",
    "    [word.split(' ', 1) for word in text[row]]\n",
    "  \n",
    "    for i in range(len(text[row])):\n",
    "        try:\n",
    "            text_vec.append(model_w2v[text[row][i]])\n",
    "            count = count + 1\n",
    "        except KeyError as e:\n",
    "            text_vec.append([0]*100)\n",
    "  \n",
    "    average = np.add.reduce(text_vec)\n",
    "    if count==0:\n",
    "        count = 1\n",
    "    average = np.divide(average, count)\n",
    "    text_avg_vec.append(average)\n",
    "    text_vec = []\n",
    "    count = 0\n",
    "\n",
    "for i in range(len(text_avg_vec)):\n",
    "    if type(text_avg_vec[i]) != np.ndarray:\n",
    "        text_avg_vec[i] = np.zeros(100)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=29900)\n",
    "\n",
    "tfidf_features = tfidf.fit_transform(df['text'])\n",
    "\n",
    "x_train = text_avg_vec\n",
    "x_train = np.array(x_train).reshape(-1, 100)\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "x_train = sparse.csr_matrix(x_train)\n",
    "x_train.shape\n",
    "\n",
    "x_train = sparse.hstack([x_train, tfidf_features])\n",
    "x_train.shape\n",
    "\n",
    "df['label'] = df['label'] - 1\n",
    "\n",
    "y_train= np.asarray(df.label)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=40000, random_state=42)\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f5ca7abc23a4e65b49d2d3ff3ef8b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=160000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:81: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(120000, 30000)\n",
      "(40000, 30000)\n"
     ]
    }
   ],
   "source": [
    "### Constructing train features\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import glob\n",
    "import os\n",
    "import string\n",
    "\n",
    "#Load training file\n",
    "\n",
    "text_file = open(\"train.txt.txt\", \"r\", encoding=\"utf8\")\n",
    "lines = text_file.read().split('\\n')\n",
    "\n",
    "labels = []\n",
    "for item in lines:\n",
    "    first_four_letters = item[:10]\n",
    "    if first_four_letters == '__label__1':\n",
    "        labels.append(int(1))\n",
    "    else:\n",
    "        labels.append(int(2))\n",
    "        \n",
    "def remove_label(s):\n",
    "    return s[11:]\n",
    "lines = [remove_label(s) for s in lines]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['text'] = lines\n",
    "df['label'] = labels\n",
    "\n",
    "df = df.sample(160000)\n",
    "print(len(df))\n",
    "df.head()\n",
    "\n",
    "#Clean text\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "#lowercase and remove punctuation, remove stopwords        \n",
    "df['text'] = df['text'].str.lower()\n",
    "df['text'] = df['text'].str.replace('-', ' ')\n",
    "df['text'] = df['text'].str.split(' ')\n",
    "df['text'] = df['text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].apply(lemmatize_text)\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].str.replace('\\\\', ' ')\n",
    "\n",
    "\n",
    "#Train Word2Vec\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "text = [row.split() for row in df['text']]\n",
    "model_w2v = Word2Vec(text)\n",
    "\n",
    "model_w2v.save('model_w2v.bin')\n",
    "\n",
    "#Average Word2Vec Vectors for BOW\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "text_vec = []\n",
    "text_avg_vec = []\n",
    "count = 0\n",
    "for row in tqdm(range(len(text))):\n",
    "    [word.split(' ', 1) for word in text[row]]\n",
    "  \n",
    "    for i in range(len(text[row])):\n",
    "        try:\n",
    "            text_vec.append(model_w2v[text[row][i]])\n",
    "            count = count + 1\n",
    "        except KeyError as e:\n",
    "            text_vec.append([0]*100)\n",
    "  \n",
    "    average = np.add.reduce(text_vec)\n",
    "    if count==0:\n",
    "        count = 1\n",
    "    average = np.divide(average, count)\n",
    "    text_avg_vec.append(average)\n",
    "    text_vec = []\n",
    "    count = 0\n",
    "\n",
    "for i in range(len(text_avg_vec)):\n",
    "    if type(text_avg_vec[i]) != np.ndarray:\n",
    "        text_avg_vec[i] = np.zeros(100)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "tfidf = CountVectorizer(ngram_range=(1,2), max_features=29900)\n",
    "\n",
    "tfidf_features = tfidf.fit_transform(df['text'])\n",
    "\n",
    "x_train = text_avg_vec\n",
    "x_train = np.array(x_train).reshape(-1, 100)\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "x_train = sparse.csr_matrix(x_train)\n",
    "x_train.shape\n",
    "\n",
    "x_train = sparse.hstack([x_train, tfidf_features])\n",
    "x_train.shape\n",
    "\n",
    "df['label'] = df['label'] - 1\n",
    "\n",
    "y_train= np.asarray(df.label)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=40000, random_state=42)\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "x_train = normalize(x_train)\n",
    "x_val = normalize(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9021166666666667\n",
      "0.8876\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=42, max_iter=2000)\n",
    "\n",
    "x_train_scaled = normalize(x_train)\n",
    "x_val_scaled = normalize(x_val)\n",
    "\n",
    "logreg.fit(x_train_scaled, y_train)\n",
    "\n",
    "print(logreg.score(x_train_scaled, y_train))\n",
    "print(logreg.score(x_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 30000)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Neural net training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=2, dtype='int32')\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes=2, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size, shuffle):\n",
    "    number_of_batches = X.shape[0]/batch_size\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[batch_index,:].toarray()\n",
    "        y_batch = y[batch_index]\n",
    "        counter += 1\n",
    "        yield X_batch, y_batch\n",
    "        if (counter == number_of_batches):\n",
    "            if shuffle:\n",
    "                np.random.shuffle(sample_index)\n",
    "            counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                480016    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 483,858\n",
      "Trainable params: 483,570\n",
      "Non-trainable params: 288\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "epochs = 10\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(16, input_dim=30000, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(rate = 0.4))\n",
    "model.add(layers.Dense(32, activation='relu', ))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(rate = 0.4))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999),\n",
    "              metrics=['accuracy'])\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"NN1.model\", monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 76s 20ms/step - loss: 0.4443 - accuracy: 0.7965 - val_loss: 0.3010 - val_accuracy: 0.8780\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.30105, saving model to NN1.model\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 77s 20ms/step - loss: 0.3229 - accuracy: 0.8710 - val_loss: 0.2836 - val_accuracy: 0.8831\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.30105 to 0.28357, saving model to NN1.model\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 80s 21ms/step - loss: 0.2913 - accuracy: 0.8848 - val_loss: 0.2791 - val_accuracy: 0.8910\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.28357 to 0.27910, saving model to NN1.model\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 83s 22ms/step - loss: 0.2706 - accuracy: 0.8951 - val_loss: 0.2855 - val_accuracy: 0.8888\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27910\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 83s 22ms/step - loss: 0.2583 - accuracy: 0.9019 - val_loss: 0.2953 - val_accuracy: 0.8848\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27910\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 110s 29ms/step - loss: 0.2448 - accuracy: 0.9082 - val_loss: 0.2897 - val_accuracy: 0.8875\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27910\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 150s 40ms/step - loss: 0.2360 - accuracy: 0.9116 - val_loss: 0.2839 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27910\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 151s 40ms/step - loss: 0.2270 - accuracy: 0.9160 - val_loss: 0.3008 - val_accuracy: 0.8874\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27910\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 151s 40ms/step - loss: 0.2238 - accuracy: 0.9168 - val_loss: 0.3023 - val_accuracy: 0.8738\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.27910\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 151s 40ms/step - loss: 0.2168 - accuracy: 0.9205 - val_loss: 0.2862 - val_accuracy: 0.8869\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.27910\n"
     ]
    }
   ],
   "source": [
    "model1 = model.fit_generator(generator=batch_generator(x_train, y_train, 32, True), validation_data=(x_val, y_val), steps_per_epoch=(x_train.shape[0])/32,epochs=10, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model1.history['accuracy'])\n",
    "plt.plot(model1.history['val_accuracy'])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(model1.history['loss'])\n",
    "plt.plot(model1.history['val_loss'])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_57 (Dense)             (None, 64)                1920064   \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 2)                 258       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 1,972,290\n",
      "Trainable params: 1,971,138\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, input_dim=30000))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.4))\n",
    "model.add(layers.Dense(128))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(rate = 0.4))\n",
    "model.add(layers.Dense(128))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(rate = 0.4))\n",
    "model.add(layers.Dense(128))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(layers.Dense(2))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999),\n",
    "              metrics=['accuracy'])\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"NN2.model\", monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 97s 26ms/step - loss: 0.3722 - accuracy: 0.8396 - val_loss: 0.2678 - val_accuracy: 0.8910\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.26779, saving model to NN2.model\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 162s 43ms/step - loss: 0.2769 - accuracy: 0.8871 - val_loss: 0.2537 - val_accuracy: 0.8963\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.26779 to 0.25369, saving model to NN2.model\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 222s 59ms/step - loss: 0.2337 - accuracy: 0.9082 - val_loss: 0.2547 - val_accuracy: 0.8952\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.25369\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 228s 61ms/step - loss: 0.2021 - accuracy: 0.9220 - val_loss: 0.2575 - val_accuracy: 0.8951\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.25369\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 232s 62ms/step - loss: 0.1736 - accuracy: 0.9337 - val_loss: 0.2632 - val_accuracy: 0.8941\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.25369\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 699s 186ms/step - loss: 0.1505 - accuracy: 0.9441 - val_loss: 0.2866 - val_accuracy: 0.8838\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.25369\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 583s 156ms/step - loss: 0.1354 - accuracy: 0.9501 - val_loss: 0.2803 - val_accuracy: 0.8906\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.25369\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 584s 156ms/step - loss: 0.1198 - accuracy: 0.9569 - val_loss: 0.2881 - val_accuracy: 0.8908\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.25369\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 588s 157ms/step - loss: 0.1085 - accuracy: 0.9608 - val_loss: 0.2990 - val_accuracy: 0.8888\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.25369\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 588s 157ms/step - loss: 0.0989 - accuracy: 0.9644 - val_loss: 0.3097 - val_accuracy: 0.8879\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.25369\n"
     ]
    }
   ],
   "source": [
    "model1 = model.fit_generator(generator=batch_generator(x_train, y_train, 32, True), validation_data=(x_val, y_val), steps_per_epoch=(x_train.shape[0])/32,epochs=10, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model1.history['accuracy'])\n",
    "plt.plot(model1.history['val_accuracy'])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(model1.history['loss'])\n",
    "plt.plot(model1.history['val_loss'])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_71 (Dense)             (None, 128)               3840128   \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 2)                 514       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 4,042,882\n",
      "Trainable params: 4,040,578\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(128, input_dim=30000))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(256))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(256))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(256))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(layers.Dense(2))\n",
    "model.add(layers.Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999),\n",
    "              metrics=['accuracy'])\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"NN4.model\", monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 67s 36ms/step - loss: 0.3652 - accuracy: 0.8424 - val_loss: 0.2891 - val_accuracy: 0.8806\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.28910, saving model to NN4.model\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 88s 47ms/step - loss: 0.2470 - accuracy: 0.9026 - val_loss: 0.2806 - val_accuracy: 0.8883\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.28910 to 0.28059, saving model to NN4.model\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 147s 79ms/step - loss: 0.2001 - accuracy: 0.9220 - val_loss: 0.2841 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.28059\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 135s 72ms/step - loss: 0.1660 - accuracy: 0.9377 - val_loss: 0.2903 - val_accuracy: 0.8895\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.28059\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 236s 126ms/step - loss: 0.1383 - accuracy: 0.9485 - val_loss: 0.3121 - val_accuracy: 0.8827\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.28059\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 548s 292ms/step - loss: 0.1154 - accuracy: 0.9579 - val_loss: 0.3048 - val_accuracy: 0.8877\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28059\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 386s 206ms/step - loss: 0.0988 - accuracy: 0.9649 - val_loss: 0.3443 - val_accuracy: 0.8867\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.28059\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 394s 210ms/step - loss: 0.0863 - accuracy: 0.9690 - val_loss: 0.3673 - val_accuracy: 0.8848\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.28059\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 394s 210ms/step - loss: 0.0748 - accuracy: 0.9737 - val_loss: 0.3700 - val_accuracy: 0.8843\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.28059\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 390s 208ms/step - loss: 0.0669 - accuracy: 0.9768 - val_loss: 0.4044 - val_accuracy: 0.8838\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.28059\n"
     ]
    }
   ],
   "source": [
    "model1 = model.fit_generator(generator=batch_generator(x_train, y_train, 64, True), validation_data=(x_val, y_val), steps_per_epoch=(x_train.shape[0])/64,epochs=10, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de3xU9Z3/8dcnN3JPIAkBEsIdQriHiHgFQSq6RRS8UWlra6vt1m631t3Fbn9WbXe1l+1lV2vrKlVrKwWv1EWpWpTWemHCVa7GcMkkEEICCSHkMsnn98eZwCQEGSDJSWY+z8cjj5w55zsznxnI+5z5nu+cr6gqxhhjQleE2wUYY4zpWhb0xhgT4izojTEmxFnQG2NMiLOgN8aYEBfldgHtpaen69ChQ90uwxhjepXCwsJDqprR0bYeF/RDhw7F4/G4XYYxxvQqIrL3dNuC6roRkbkislNEikRkSQfbh4jIWyKyWUTeFpHsgG0/FpGtIrJdRP5bROTcXoYxxphzccagF5FI4FHgaiAPWCQiee2a/RR4RlUnAg8CD/nvezFwCTARGA9cAMzotOqNMcacUTBH9NOAIlUtVtVGYBkwv12bPOAt//KagO0KxAIxQB8gGig/36KNMcYEL5g++iygJOC2F7iwXZtNwELgl8D1QJKIpKnqeyKyBtgPCPCIqm4/2yKbmprwer3U19ef7V17rdjYWLKzs4mOjna7FGNMLxdM0HfUp97+Ajn3AI+IyG3AWqAU8InISGAs0Npn/4aIXK6qa9s8gcgdwB0AOTk5pzyZ1+slKSmJoUOHEg5d/KpKZWUlXq+XYcOGuV2OMaaXC6brxgsMDridDZQFNlDVMlVdoKpTgH/3r6vGObp/X1VrVbUWeA2Y3v4JVPVxVS1Q1YKMjFNHB9XX15OWlhYWIQ8gIqSlpYXVJxhjTNcJJujXAaNEZJiIxAC3ACsDG4hIuoi0Pta9wFL/8j5ghohEiUg0zonYs+668T/Hudyt1wq312uM6Tpn7LpRVZ+I3AWsBiKBpaq6VUQeBDyquhKYCTwkIorTdfMN/92fB2YBW3C6e15X1T91/sswxpjep67RR0nVcfZWHmNfVR1xMZHceuGQTn+eoL4wpaqrgFXt1t0XsPw8Tqi3v18zcOd51ui6yspKZs+eDcCBAweIjIyktYvpww8/JCYm5oyP8aUvfYklS5YwZsyYLq3VGNNzqCqVxxrZW1nHvqpj/t917KusY29VHRVHG9q0n5KT6l7Qh7u0tDQ2btwIwP33309iYiL33HNPmzaqiqoSEdFxb9hvf/vbLq/TGNP9mppbKDty/GSIV9Wxt9IJ9ZKqOo41NrdpPzAllsH94pk5OoMhafHkpCUwpF88Of3iSY3vmlF2FvTnoaioiOuuu45LL72UDz74gFdffZUHHniA9evXc/z4cW6++Wbuu8/54HPppZfyyCOPMH78eNLT0/na177Ga6+9Rnx8PK+88gr9+/d3+dUYY06ntsHHvoCj8r1VTojvrayj9MhxmltODkSMiYpgcN84hqQlMH14mhPm/eIZkhZPdt94YqMju73+Xhf0D/xpK9vKajr1MfMGJfP9eePO6b7btm3jt7/9Lb/+9a8BePjhh+nXrx8+n48rrriCG264gby8tl8krq6uZsaMGTz88MPcfffdLF26lCVLTrmyhDGmm6gqFUcb2OsPb6d75Rh7/d0slcca27RPjY9mSL94Jg1OZd6kgQzpl0BOmhPmmUmxRET0rMEUvS7oe5oRI0ZwwQUXnLj93HPP8eSTT+Lz+SgrK2Pbtm2nBH1cXBxXX301AFOnTuWvf/1rt9ZsTDjzNbdQVFHLZm81W7zVbC6tZteBoxxvOtnFEiEwMCWOnH7xzMnLdEK8XwJD0uIZ3C+elLje9UXGXhf053rk3VUSEhJOLH/88cf88pe/5MMPPyQ1NZXFixd3OBY+8ORtZGQkPp+vW2o1Jty0tCjFh46xpfTIiWDfWlZzItQT+0QxPiuZW6YNZmia/6i8n9PFEhMVOtN19Lqg78lqampISkoiOTmZ/fv3s3r1aubOnet2WcaEBVVlX1WdE+il1WwqOcLWshpqG5wDqdjoCMYPSuGWaYOZmJ3CxOxUhqUl9Lhulq5gQd+J8vPzycvLY/z48QwfPpxLLrnE7ZKMCUmqSumR4ye6XrZ4q9nsPUJNvRPqMVER5A1MZkF+FhOynFAfkZFAVGToHKWfDVFtf9kadxUUFGj7iUe2b9/O2LFjXarIPeH6uo1pr7ym3t/1cuREsLeeII2KEHIHJjEhK5WJ2SlMyEphdGZSSHW9BENEClW1oKNtdkRvjOlRDtU2sCXgKH2zt5qD/i8WRQiMzkxiVm5/Jg5OZWJWCmMGJLkyZLE3saA3xrimuq6JzQEnSreUVlN65DgAIjAiI5FLR6YzITuFidkp5A1MIS7GQv1sWdAbY7qcr7mF3YeOsf3AUXbsr2HngaPsOHD0RKgDDE2LJ39IX267eCgTs1MYl5VCYh+LqM5g76IxptOoKhW1DezYf5SdB46y/UANO/YfpehgLY3NLYDTpz4iI5GCoX1ZPGAIE7NTGD8ohZQu+vq/saA3xpyj+qZmPi6vPRHmOw44R+qB3yLNTO5D7oBkLhuVTu7AJHIHJDMiIzHsTpS6zYLeGPOpWlqcoYzbA7pcth+oYc+hY7Re4iU2OoIxmUlcOTbzRKDnDkiib8KZr+xqup4FfZBmzpzJvffey1VXXXVi3S9+8Qt27drFr371qw7vk5iYSG1tbXeVaMx5q6lvcsJ8f82J/vRd5bUnvnQEMCQtntwBSXx24iDGDkgid2AyOf3iiQyDLx71Vhb0QVq0aBHLli1rE/TLli3jJz/5iYtVGXNuAk+O7jzR9dL25GhybBS5A5NZmJ9F7sBkxgxIYkxmEgl2grTXsX+xIN1www1873vfo6GhgT59+rBnzx7KysqYPHkys2fP5vDhwzQ1NfHDH/6Q+fPnu12uMaeoONrAX3aU88a2g/ytqIL6plNPjt46IIexA5LJHZjEgORYm9IyRPS+oH9tCRzY0rmPOWACXP3wpzZJS0tj2rRpvP7668yfP59ly5Zx8803ExcXx0svvURycjKHDh1i+vTpXHvttfYHYlynqnx8sJY3tpXz5vZyNpYcQRWyUuO4qWAwU3JSGZOZzIj+CfSJsrHpoaz3Bb2LWrtvWoN+6dKlqCrf/e53Wbt2LREREZSWllJeXs6AAQPcLteEoabmFtbtqeLNbQd5c3s5+6rqAJiUncLdV47myrxMcgck2YFImOl9QX+GI++udN1113H33XefmEEqPz+fp556ioqKCgoLC4mOjmbo0KEdXprYmK5SU9/E2l0VvLmtnDU7K6g+3kRMVASXjEjjzhnDmZ2byYCUWLfLNC7qfUHvosTERGbOnMmXv/xlFi1aBDizRfXv35/o6GjWrFnD3r17Xa7ShAPv4Tre2u4ctb9fXElTs9IvIYY5eZlcOTaTy0al20lTc0JQ/xNEZC7wSyASeEJVH263fQiwFMgAqoDFqur1b8sBngAGAwpco6p7OusFdLdFixaxYMECli1bBsCtt97KvHnzKCgoYPLkyeTm5rpcoQlFqsqW0mre3FbOG9sPsn2/M53m8IwEvnzpMOaMzWRKTl8b4mg6dMagF5FI4FFgDuAF1onISlXdFtDsp8Azqvq0iMwCHgI+79/2DPAfqvqGiCQCLZ36CrrZ9ddfT+ClndPT03nvvfc6bGtj6M35qG9q5r3iSt70n0wtr2kgQqBgSD++e00us8dmMiIj0e0yTS8QzBH9NKBIVYsBRGQZMB8IDPo84Nv+5TXAy/62eUCUqr4BoKqWfMZ8iqpjjfxlx0He3FbO2o8rqGtsJj4mkhmjM7hybCZX5Pann33b1JylYII+CygJuO0FLmzXZhOwEKd753ogSUTSgNHAERF5ERgGvAksUdXmwDuLyB3AHQA5OTnn8DKM6b2KK04OgSzce5gWhQHJsSzIz+LKsZlMH55m11s35yWYoO+o06/9tFT3AI+IyG3AWqAU8Pkf/zJgCrAP+CNwG/BkmwdTfRx4HJwZpjoqQlXDakhYT5v5y3Se5hZl/b7D/v72coorjgGQNzCZu2aNYs7YTMZnJYfV/3fTtYIJei/OidRW2UBZYANVLQMWAPj74ReqarWIeIENAd0+LwPTaRf0ZxIbG0tlZSVpaWlh8Z9fVamsrCQ21obEhQpVZWPJEZZ9WMIb28upOtZIdKQwfXgat108lNljM8lKjXO7TBOiggn6dcAoERmGc6R+C/C5wAYikg5UqWoLcC/OCJzW+/YVkQxVrQBmAW0nhA1CdnY2Xq+XioqKs71rrxUbG0t2drbbZZjzVNfo45WNZTz7/l62ltWQEBPJnLxM5uQN4PLR6STF2jXYTdc7Y9Crqk9E7gJW4wyvXKqqW0XkQcCjqiuBmcBDIqI4XTff8N+3WUTuAd4S51C8EPjfsy0yOjqaYcOGne3djHHNx+VHefb9vby4vpSjDT5yByTxg+vGc/2ULJs1yXQ76Wl9wQUFBerxnPVBvzGua/S18PrWAzz7/l4+3F1FTGQE10wYwOLpQ5g6pG9YdDsa94hIoaoWdLTNDi2MOU8lVXU89+E+lntKOFTbSE6/eO69OpcbpmaTltjH7fKMsaA35lw0tyjv7DrIs+/vY83Ogwgwe2wmi6cP4bKR6UTYN1RND2JBb8xZOFTbwB/XlfCHD/ZReuQ4GUl9+OYVI7llWg6DbNSM6aEs6I05A1Xlw91VPPvBPl7/aD9NzcpFw9P47jVj+cy4TKIjbaJr07NZ0BtzGjX1Tby0vpTff7CXXeW1JMdGsXj6EG69cAgj+9s1ZkzvYUFvTDsflVbz+w/28vKGMo43NTMxO4UfL5zIvEmDiIuxSxGY3seC3hicK0W+unk/z76/l40lR4iNjuDaSYNYPH0IE7NT3S7PmPNiQW/C2u5Dx/j9+3tZUeil+ngTIzISuO+zeSzMzyYl3r61akKDBb0JO77mFt7cXs6z7+/jb0WHiIoQrho3gFun53DR8PC4npIJLxb0JmwcqK7nuQ/3sWzdPsprGhiUEst35ozm5gsG0z/ZLiBnQpcFvQl5m71H+PU7n7B6azktqlw+KoMfXjeEWbn9beo9ExYs6E1IUlXeLarksXeKeLeokqTYKL5y6TBuvXAIOWnxbpdnTLeyoDchpblFWb31AI+9/QlbSqvpn9SH716Ty6JpOXZJYBO2LOhNSGjwNfPyhlJ+804xxYeOMSw9gYcXTOD6/Cz6RNnYdxPeLOhNr1bb4OO5D/bxxN+KKa9pYHxWMr+6NZ+rxg2w/ndj/CzoTa9UWdvAU3/fw9N/30NNvY+LR6Tx0xsncenIdBseaUw7FvSmVympquOJvxbzR08JDb4WrsobwNdmjmDyYPv2qjGnY0FveoUdB2r4zTvFrNxURoTA9VOyuOPyEXZxMWOCYEFvejTPnioee/sT3tpxkPiYSL508VBuv2wYA1Ps2u/GBMuC3vQ4qsqanQd57O1PWLfnMH3jo7l7zmi+cNEQUuNj3C7PmF4nqKAXkbnAL4FI4AlVfbjd9iHAUiADqAIWq6o3YHsysB14SVXv6qTaTYjxNbfw6ub9/PqdT9hx4ChZqXHcPy+Pmy4YTHyMHZMYc67O+NcjIpHAo8AcwAusE5GVqrotoNlPgWdU9WkRmQU8BHw+YPsPgHc6r2wTSuqbmlnhKeE3a4vxHj7OqP6J/OymScybNMhmbzKmEwRzmDQNKFLVYgARWQbMBwKDPg/4tn95DfBy6wYRmQpkAq8DBZ1QswkR1cebePb9vSz9224qjzWSn5PK/fPGMSu3v02ubUwnCibos4CSgNte4MJ2bTYBC3G6d64HkkQkDTgM/BfO0f3s0z2BiNwB3AGQk5MTbO2mlyqvqWfp33bz+w/2Udvg44oxGXx95kguGNrXxsAb0wWCCfqO/vK03e17gEdE5DZgLVAK+IB/BFapasmn/QGr6uPA4wAFBQXtH9uEiN2HjvH42k94obAUX0sL8yYN4s7LR5A3KNnt0owJacEEvRcYHHA7GygLbKCqZcACABFJBBaqarWIXARcJiL/CCQCMSJSq6pLOqV60yts8Vbz63c+YdVH+4mOjOCmC7K547IRdhVJY7pJMEG/DhglIsNwjtRvAT4X2EBE0oEqVW0B7sUZgYOq3hrQ5jagwEI+fByqbeC+Vz5i1ZYDJPWJ4uszRvClS4aRkdTH7dKMCStnDHpV9YnIXcBqnOGVS1V1q4g8CHhUdSUwE3hIRBSn6+YbXViz6QVe/+gA//7SFo7W+7h7zmhuu2QoyXaZYGNcIao9q0u8oKBAPR6P22WYc1Rd18T9f9rKSxtKGTcomZ/dNJkxA5LcLsuYkCcihara4chG+xaK6TRv7zzIv72wmUO1jXxr9ijumjXSxsEb0wNY0JvzVtvg4z9XbecPH+xjVP9EnvjCBUzITnG7LGOMnwW9OS/vF1fyL89vwnv4OHdePpxvzxlNbLTN6GRMT2JBb85JfVMzP1m9k6Xv7ianXzwr7ryIgqH93C7LGNMBC3pz1jaWHOHu5RsprjjG56cP4d5rcu2iY8b0YPbXaYLW6Gvhv9/6mF+9XURmciy/u30al43KcLssY8wZWNCboGzfX8PdyzexfX8NN0zN5r55eTYu3phewoLefCpfcwu/WVvML97cRUpcDP/7hQLm5GW6XZYx5ixY0JvT+qSilu8s38TGkiP8w4SB/OC68fRLsBmejOltLOjNKVpalKf+vocfvb6DuJhI/mfRFOZNGuR2WcaYc2RBb9ooqarjnhWb+GB3FbNy+/Pwggn0T451uyxjzHmwoDeAMyH3snUl/PDVbYgIP144kRsLsm0iEGNCgAW94UB1PUte3MzbOyu4eEQaP75hItl97VrxxoQKC/owpqq8srGM+175iMbmFh64dhyfnz7E5ms1JsRY0IepytoGvvfyR7z20QHyc1L5r5smMyw9we2yjDFdwII+DK3eeoDvvuhMCrLk6ly+etlwIu0o3piQZUEfRqqPN/HAyq286J8U5A9ftUlBjAkHFvRh4p1dFfzb85upqG3gn2aP4q4rRhITZZOCGBMOLOhD3LEGH//hnxRkZP9EHv/CVCZmp7pdljGmG1nQh7APiiu5xz8pyB2XD+dumxTEmLBkQR+CVJX/fquIX7y1i8F941l+50VcYJOCGBO2guqkFZG5IrJTRIpEZEkH24eIyFsisllE3haRbP/6ySLynohs9W+7ubNfgGmrvqmZby3byM/f3MX1k7N47VuXWcgbE+bOeEQvIpHAo8AcwAusE5GVqrotoNlPgWdU9WkRmQU8BHweqAO+oKofi8ggoFBEVqvqkU5/JYaKow3c8TsPG/Yd4V/njuHrM0bYJQyMMUF13UwDilS1GEBElgHzgcCgzwO+7V9eA7wMoKq7WhuoapmIHAQyAAv6TrbjQA23P+Wh8lgDv16cz9zxA90uyRjTQwTTdZMFlATc9vrXBdoELPQvXw8kiUhaYAMRmQbEAJ+0fwIRuUNEPCLiqaioCLZ24/eXHeUs/NXf8bW0sOLOiy3kjTFtBBP0HX3213a37wFmiMgGYAZQCvhOPIDIQOB3wJdUteWUB1N9XFULVLUgI8PmIA2WqvLk33bzlac9DMtI4JVvXMqE7BS3yzLG9DDBdN14gcEBt7OBssAGqloGLAAQkURgoapW+28nA/8HfE9V3++Mog00Nbfw/ZVb+cMH+7hqXCY/v3ky8TE2iMoYc6pgkmEdMEpEhuEcqd8CfC6wgYikA1X+o/V7gaX+9THASzgnald0ZuHhrLquiX/8QyHvFlXy9Zkj+JfPjLErThpjTuuMQa+qPhG5C1gNRAJLVXWriDwIeFR1JTATeEhEFFgLfMN/95uAy4E0EbnNv+42Vd3YuS8jfOw5dIwvP72Okqo6fnLDRG4sGHzmOxljwpqotu9ud1dBQYF6PB63y+iR3i+u5GvPFiLArxdP5cLhaWe8jzEmPIhIoaoWdLTNOnV7ieWeEv79pS3k9Itn6W0XMCTNrh1vjAmOBX0P19Ki/Gj1Dn7zTjGXjUrnkc/lkxIX7XZZxphexIK+B6tr9PHPyzby523lLJ6ew/fnjSM60i4tbIw5Oxb0PdT+6uN85WkP2/fXcP+8PL548VC7nIEx5pxY0PdAm71H+MrTHuoam3nytgu4Ykx/t0syxvRiFvQ9zKot+7l7+UbSEvrwwtcvtKn+jDHnzYK+h1BVfvX2J/xk9U7yc1J5/AsFpCf2cbssY0wIsKDvARp8zdz7whZe3FDK/MmD+NHCiTYTlDGm01jQu6yytoGvPVvIuj2HuXvOaL45a6SddDXGdCoLehd9XH6ULz+9joM1DTzyuSl8duIgt0syxoQgC3qXvLOrgrt+v54+0ZH88c6LmDw41e2SjDEhyoLeBc+8t4cH/rSNUf0TefK2C8hKjXO7JGNMCLOg70a+5hZ+8Oo2nn5vL1eO7c8vbplCYh/7JzDGdC1LmW5SU9/EXX/YwNpdFXz1smEsuXoskXYNeWNMN7Cg7wYlVXV8+al17D50jIcWTGDRtBy3SzLGhBEL+i62bk8Vd/6ukOYW5Znbp3HxiHS3SzLGhBkL+i704novS17YQlbfOJ78YgHDMxLdLskYE4Ys6LtAS4vyszd28ciaIi4ansZji/NJjY9xuyxjTJiyoO9kjb4W/vmPG1i15QC3XDCYB+ePJybKriFvjHGPBX0ne2mDl1VbDrDk6lzuvHy4Xc7AGOO6oA41RWSuiOwUkSIRWdLB9iEi8paIbBaRt0UkO2DbF0XkY//PFzuz+J5oucfLiIwEC3ljTI9xxqAXkUjgUeBqIA9YJCJ57Zr9FHhGVScCDwIP+e/bD/g+cCEwDfi+iPTtvPJ7lqKDtRTuPcxNBYMt5I0xPUYwR/TTgCJVLVbVRmAZML9dmzzgLf/ymoDtVwFvqGqVqh4G3gDmnn/ZPdPzhV4iI4Tr87PcLsUYY04IJuizgJKA217/ukCbgIX+5euBJBFJC/K+iMgdIuIREU9FRUWwtfcovuYWXljv5Yox/emfFOt2OcYYc0IwQd9RH4S2u30PMENENgAzgFLAF+R9UdXHVbVAVQsyMjKCKKnneWdXBRVHG7ixIPvMjY0xphsFM+rGCwwOuJ0NlAU2UNUyYAGAiCQCC1W1WkS8wMx29337POrtsVZ4vKQnxjAr1ybyNsb0LMEc0a8DRonIMBGJAW4BVgY2EJF0EWl9rHuBpf7l1cBnRKSv/yTsZ/zrQkplbQNvbi/n+ilZREfamHljTM9yxlRSVR9wF05AbweWq+pWEXlQRK71N5sJ7BSRXUAm8B/++1YBP8DZWawDHvSvCykvbSjF16LcWDD4zI2NMaabieopXeauKigoUI/H43YZQVNV5v7ir8TGRPLKNy5xuxxjTJgSkUJVLehom/UznKctpdXsLD/KTXYS1hjTQ1nQn6flnhL6REUwb5JN7G2M6Zks6M9DfVMzr2ws4+rxA0iOjXa7HGOM6ZAF/XlYvfUAR+t93GQnYY0xPZgF/XlY4fGS3TeO6cPT3C7FGGNOy4L+HJVU1fHuJ4e4YWo2ETbJtzGmB7OgP0cvrPcCcMNUG21jjOnZLOjPQUuL8nyhl0tGpJPdN97tcowx5lPZDFPn4P3iSryHj/MvV41xu5SeQxVafOBrgOZG56d1Oa4vJKS7XaExYcuC/hws95SQFBvFVeMGdP+Ttw9UXwM0N4Cvsd3vBmhu6mDZH8Jtlhs7DuhTlv33a7PcdLLNqRcmPWlQPoyeC6OvgoGTwCZmMabbWNCfperjTbz20QFuLMgmNjry1Aa1B2H3WmisbRe6jUGEc/sQPk2Af1qgnq2IKIjsA1ExEBnTbjkGovo4v6PjTy5Hxvjb9PmU5Wh/+z5weA98vBrefgje/k9IGgijPuME//AZEJPQea/HGHMKC/qz9OrmMhp8LW3HztdWwPaVsPUl2PsuaEvHd24TpO1/+5dj4iGyb8C2Pm0DtzU8T3kMf7iesi6m3baA5cgYiOim0zQz/sV5n4regF2vw0cvwvqnnTqGXe4c6Y++ClJzuqee7qYK1SVQttHZmcckODvP6Hjn3zw6vu267vp3MWHBLmp2luY/+i4NTc289pWxyI4/OeG+529OuKeNgvELYMw1kJBxakhbd8VJvkbY93fYtdoJ/qpiZ33/cf7QnwvZBRDRwaem3qC+Gso2gNcDpYXO72MHg79/VNzJHcCJnUFCBzuFuJPLbdq0/o479X72fzEkfdpFzSzoz0LR7j08+cR/c1fmR2Qd9oA2Q9pIGHe989M/z/6AztWhIifwd70Oe//uvLdx/fxdPJ+BEbMhLtXtKjvW3AQHt7UN9UO7ONHFljbK2WllTYWsfIhJhMZj0FQHjXXQdMz/u67jdY3HoOl4wHK7Ns0NZ1evRDo1xKU6J8nj0/2/007+br8uJtH+b/dwFvTn41gl7PgTbH2ZluK1RNBMc9/hRI5f4IR75jj7A+hsx4/AJ39xjvY//jMcr3LCacjFJ4/200a68763dsEEhvr+TeA77myPT/eHeoET6ln5zqijrtTSfBY7iIDfdVVQdwiOHYK6Suf36XYakX38wd8vYCeQDgntdgqty7Gp1v3UzSzoz1ZdFex41emWKX4HtBntN5ylhydTlnU1/+/2Gy3cu0tLsxOmu153gv/gVmd9v+EnR/HkXOycl+gK9dVQuh5KPeAtdMK9tQsmKtYZQZQ11fnJLoDUIb33/4aqM4igrtI5wDmxE2i3M6hr3VYJjUc7fiyJbLdTOM0OIq7vyfNGEdH+c1XR/p8YZ53tMIJiQR+MuirY8X9OuO9+xxnC2HfYiW6Z1ZUZ3Pnsep78YgGzx2Z2f33GcWSfv19/tTO6qbkBYpJg5Cwn+EfOgcRznGC+uQnKtwaEemsXjF9gF0x2AWSOdwIpnDXVBwR/606g8jQ7iENw/PDZP4dEBgR/1MmRX5FRJ3cGbXYOUR3vMAJvt9mxBD5OVNv1HS5H+58j8PnaLbe27cad1KcFfXiPujl++GS4F7/tD/ehcAHHJsgAAA2gSURBVPE3Ie+6NuO9V/x5HRlJfZgx+hxDxHSO1ByY9lXnp/GY84mr9Wh/2yuAOCHc2sWTOb7jI2xVZ6cRGOr7N4Gv3tne2gUz4SbInup8D6CnniNwU3QspGQ5P8Fo9jl/d607geOH/UOKm6Clyb/sc363NPm//+HfHmwbX33wj9PVJOIMO47ogB1DtHOe77M/6/Qywi/ojx+GHasCwr3J+bh90V0w7joYOPmUYDh4tJ41Oyv46mXDibLJv3uOmATIvcb5UXWCunUUz19+6PwkZzmhP+oqp3unNdRLC+FYhfM4rV0wBbc7oZ5V4OxQemsXTE8WGeV84jrXT12dSdXpGmz9QmCLL2An0MGO5ZT17ZbPtP3EcvsdUECbzvyOTIDwCPrjR2CnP9w/WeMP9xyY/nWna2bQlE/9o35pfSnNLcqNNl1gzyUCgyY7PzP/DY6WOydyd70Om/4InqUn26aPdrp4sv1969YFE55E/N02UUBoX7MqqKAXkbnAL4FI4AlVfbjd9hzgaSDV32aJqq4SkWjgCSDf/1zPqOpDnVj/6dVXO0fu216GoreccE/Jgelf84d7flBHbKrKck8JU4f0ZURGYjcUbjpFUibkf9758TXAvvec7zpYF4wJQ2cMehGJBB4F5gBeYJ2IrFTVbQHNvgcsV9XHRCQPWAUMBW4E+qjqBBGJB7aJyHOquqeTX4ejvgZ2vuY/cn/L+XiUnA0X3gnjFjhD3c7y4/j6fUf4pOIYP1o4vEtKNt0gqg8Mn+l2Fca4Jpgj+mlAkaoWA4jIMmA+EBj0CiT7l1OAsoD1CSISBcQBjUBNJ9R9qqrd8Oi0k+E+7Q7nhGp2wXn1tT5fWEJcdCT/MNEm/zbG9E7BBH0WUBJw2wtc2K7N/cCfReSbQAJwpX/98zg7hf04nWDfVtWq8yn4tPoOhcu+AyNmOSfTOmFYU12jjz9t2s81EwaS2Cc8TmcYY0JPMGnY0eFw+1PDi4CnVDUbuAb4nYhE4HwaaAYGAcOA74jIKX0gInKHiHhExFNRUXFWLyDgQWDmEhg8rdPGrr625QC1DT5uspOwxpheLJhE9AIBl2okm5NdM61uB5YDqOp7QCyQDnwOeF1Vm1T1IPAucMqAflV9XFULVLUgI6MHDLvyW1FYwtC0eKYN6+d2KcYYc86CCfp1wCgRGSYiMcAtwMp2bfYBswFEZCxO0Ff4188SRwIwHdjRWcV3pb2Vx3i/uIobCwYjNp7aGNOLnTHoVdUH3AWsBrbjjK7ZKiIPisi1/mbfAb4qIpuA54Db1Lm2wqNAIvARzg7jt6q6uQteR6d7vtBLhMCC/CC/8WeMMT1UUGcYVXUVzpDJwHX3BSxvAy7p4H61OEMse5Vm/+Tfl43KYGBKnNvlGGPMebHv83fg3aJD7K+ubzuLlDHG9FIW9B1Y7ikhNT6aK/P6u12KMcacNwv6do7UNfLnreVcNzmLPlG9dBo7Y4wJYEHfzisby2hsbrELmBljQoYFfTsrCksYNyiZcYNS3C7FGGM6hQV9gK1l1XxUWsONU+1o3hgTOizoA6zweImJjGD+ZBs7b4wJHRb0fg2+Zl7ZWMqccZn0TeiiiaaNMcYFFvR+b20/yOG6Jhs7b4wJORb0fss9JQxMieXSkelul2KMMZ3Kgh44UF3P2l0VLMzPJjLCLmBmjAktFvTAC+u9tCjcYKNtjDEhKOyDXlVZ4Slh2rB+DE1PcLscY4zpdGEf9Ov2HGZPZZ2dhDXGhKywD/oVnhISYiK5ZsIAt0sxxpguEdZBX9vg4/+27GfepEHEx9jk38aY0BTWQb9q837qGpvtAmbGmJAW1kG/3FPC8IwE8nP6ul2KMcZ0mbAN+uKKWjx7D3OTTf5tjAlxYRv0Kwq9REYIC6bYBcyMMaEtLIPe19zCC4VeZo7OoH9yrNvlGGNMlwoq6EVkrojsFJEiEVnSwfYcEVkjIhtEZLOIXBOwbaKIvCciW0Vki4i4nqxrP67g4NEGbrSx88aYMHDGMYUiEgk8CswBvMA6EVmpqtsCmn0PWK6qj4lIHrAKGCoiUcCzwOdVdZOIpAFNnf4qztIKj5e0hBhm5drk38aY0BfMEf00oEhVi1W1EVgGzG/XRoFk/3IKUOZf/gywWVU3Aahqpao2n3/Z566ytoE3t5dz3ZQsYqLCsufKGBNmgkm6LKAk4LbXvy7Q/cBiEfHiHM1/079+NKAislpE1ovIv3b0BCJyh4h4RMRTUVFxVi/gbL28sYymZrVLHhhjwkYwQd/R2ENtd3sR8JSqZgPXAL8TkQicrqFLgVv9v68XkdmnPJjq46paoKoFGRkZZ/UCzkbrBcwmZacwZkBSlz2PMcb0JMEEvRcIPPzN5mTXTKvbgeUAqvoeEAuk++/7jqoeUtU6nKP9/PMt+lx9VFrDjgNH7SSsMSasBBP064BRIjJMRGKAW4CV7drsA2YDiMhYnKCvAFYDE0Uk3n9idgawDZcs95TQJyqCeZMGuVWCMcZ0uzOOulFVn4jchRPakcBSVd0qIg8CHlVdCXwH+F8R+TZOt85tqqrAYRH5Gc7OQoFVqvp/XfViPk19kzP599zxA0iJi3ajBGOMcUVQl2xU1VU43S6B6+4LWN4GXHKa+z6LM8TSVX/eVk5Nvc9Owhpjwk7YjC9c4SkhKzWOi4anuV2KMcZ0q7AIeu/hOv5WdIgbpmYTYZN/G2PCTFgE/QuFpahN/m2MCVMhH/QtLcrz60u4ZGQag/vFu12OMcZ0u5AP+vd3V1JSdZwbp9pJWGNMeAr5oF/h8ZIUG8Xc8Tb5tzEmPIV00NfUN/HaR/u5dtIgYqMj3S7HGGNcEdJB/+qm/dQ3tdjYeWNMWAvpoF/uKWF0ZiITs1PcLsUYY1wTskH/cflRNpYcscm/jTFhL2SDfkWhl6gI4Tqb/NsYE+ZCMuibmlt4cb2XWbn9SU/s43Y5xhjjqpAM+jU7DnKottFOwhpjDCEa9CsKvWQk9WHmmK6brcoYY3qLkAv6g0fr+cuOgyzIzyIqMuRenjHGnLWQS8KXN5TS3KJ2yQNjjPELqaBXVZZ7vOTnpDKyf6Lb5RhjTI8QUkG/seQIRQdr7SSsMcYECKmgX+7xEhcdyT9MHOh2KcYY02OETNAfb2zmT5vKuHrCAJJibfJvY4xpFVTQi8hcEdkpIkUisqSD7TkiskZENojIZhG5poPttSJyT2cV3l5NfRNX5PbnlgtyuuopjDGmV4o6UwMRiQQeBeYAXmCdiKxU1W0Bzb4HLFfVx0QkD1gFDA3Y/nPgtU6rugOZybH8z6IpXfkUxhjTKwVzRD8NKFLVYlVtBJYB89u1USDZv5wClLVuEJHrgGJg6/mXa4wx5mwFE/RZQEnAba9/XaD7gcUi4sU5mv8mgIgkAP8GPPBpTyAid4iIR0Q8FRUVQZZujDEmGMEEfUfX+NV2txcBT6lqNnAN8DsRicAJ+J+rau2nPYGqPq6qBapakJFhly0wxpjOdMY+epwj+MCB6dkEdM343Q7MBVDV90QkFkgHLgRuEJEfA6lAi4jUq+oj5125McaYoAQT9OuAUSIyDCgFbgE+167NPmA28JSIjAVigQpVvay1gYjcD9RayBtjTPc6Y9eNqvqAu4DVwHac0TVbReRBEbnW3+w7wFdFZBPwHHCbqrbv3jHGGOMC6Wl5XFBQoB6Px+0yjDGmVxGRQlUt6GhbyHwz1hhjTMd63BG9iFQAe8/jIdKBQ51UTm9n70Vb9n60Ze/HSaHwXgxR1Q6HLfa4oD9fIuI53ceXcGPvRVv2frRl78dJof5eWNeNMcaEOAt6Y4wJcaEY9I+7XUAPYu9FW/Z+tGXvx0kh/V6EXB+9McaYtkLxiN4YY0wAC3pjjAlxIRP0Z5oFK5yIyGD/jF/bRWSriHzL7ZrcJiKR/hnQXnW7FreJSKqIPC8iO/z/Ry5yuyY3ici3/X8nH4nIc/6LMoaUkAj6gFmwrgbygEX+ma7ClQ/4jqqOBaYD3wjz9wPgWzjXajLwS+B1Vc0FJhHG74uIZAH/BBSo6nggEufCjSElJIKe4GbBChuqul9V1/uXj+L8IbefLCZsiEg28A/AE27X4jYRSQYuB54EUNVGVT3iblWuiwLiRCQKiOfUy7D3eqES9MHMghWWRGQoMAX4wN1KXPUL4F+BFrcL6QGGAxXAb/1dWU/4Z4ILS6paCvwU51Lr+4FqVf2zu1V1vlAJ+mBmwQo7IpIIvAD8s6rWuF2PG0Tks8BBVS10u5YeIgrIBx5T1SnAMSBsz2mJSF+cT//DgEFAgogsdreqzhcqQR/MLFhhRUSicUL+96r6otv1uOgS4FoR2YPTpTdLRJ51tyRXeQGvqrZ+wnseJ/jD1ZXAblWtUNUm4EXgYpdr6nShEvQnZsESkRickykrXa7JNSIiOH2w21X1Z27X4yZVvVdVs1V1KM7/i7+oasgdsQVLVQ8AJSIyxr9qNrDNxZLctg+YLiLx/r+b2YTgyelgphLs8VTVJyKts2BFAktVdavLZbnpEuDzwBYR2ehf911VXeViTabn+Cbwe/9BUTHwJZfrcY2qfiAizwPrcUarbSAEL4dgl0AwxpgQFypdN8YYY07Dgt4YY0KcBb0xxoQ4C3pjjAlxFvTGGBPiLOiNMSbEWdAbY0yI+/9t8qXKzQsFHwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model1.history['accuracy'])\n",
    "plt.plot(model1.history['val_accuracy'])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(model1.history['loss'])\n",
    "plt.plot(model1.history['val_loss'])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Combining Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "chosen_model = keras.models.load_model('NN3.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 32)                960032    \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 973,858\n",
      "Trainable params: 973,282\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "chosen_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 128)               3840128   \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 256)               65792     \n",
      "=================================================================\n",
      "Total params: 4,041,344\n",
      "Trainable params: 4,039,552\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "capped_model = keras.Sequential()\n",
    "\n",
    "for layer in chosen_model.layers[:-4]:\n",
    "    capped_model.add(layer)\n",
    "    \n",
    "capped_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653a35c653c34f6ba1fe35864a0702ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=120000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "y_predict_train = []\n",
    "\n",
    "for i in tqdm(range(x_train.shape[0])):\n",
    "    array = x_train[i].toarray()\n",
    "    prediction = capped_model.predict(array)\n",
    "    y_predict_train.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 1, 256)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_train = np.array(y_predict_train)\n",
    "y_predict_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 256)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_train = y_predict_train.reshape((120000, 256))\n",
    "y_predict_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### PCA to reduce dimensions of TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 29900)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tfidf = x_train[:,100:]\n",
    "x_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=25)\n",
    "\n",
    "svd_data = svd.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 500)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 64)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Combine PCA result with last layer of NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 281)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "x_train_new = np.hstack([svd_data, y_predict_train])\n",
    "x_train_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.argmax(y_train, axis=1)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(random_state=42)\n",
    "x_train = normalize(x_train)\n",
    "\n",
    "svm_model = svm.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.865975"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8fedffb3c5f4dc48472a55d2cce30a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#same process to validation set\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "y_predict_val = []\n",
    "\n",
    "for i in tqdm(range(x_val.shape[0])):\n",
    "    array = x_val[i].toarray()\n",
    "    prediction = capped_model.predict(array)\n",
    "    y_predict_val.append(prediction)\n",
    "\n",
    "y_predict_val = np.array(y_predict_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_val_tfidf = x_val[:,100:]\n",
    "\n",
    "svd_data_val = svd.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_val = y_predict_val.reshape((40000, 256))\n",
    "\n",
    "x_val_new = np.hstack([svd_data_val, y_predict_val])\n",
    "\n",
    "#y_val = np.argmax(y_val, axis=1)\n",
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_val = np.argmax(y_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.526775"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.score(x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Logistic Regression with combined features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 456)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 456)\n",
      "(40000, 456)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "#x_train_new = x_train_new.toarray()\n",
    "#x_val_new = x_val_new.toarray()\n",
    "\n",
    "print(x_train_new.shape)\n",
    "print(x_val_new.shape)\n",
    "\n",
    "x_train_normalized = scaler.fit_transform(x_train_new)\n",
    "x_val_normalized = scaler.transform(x_val_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8797916666666666\n",
      "0.876625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression(random_state=42, max_iter=8000)\n",
    "\n",
    "log_model.fit(x_train_new, y_train)\n",
    "\n",
    "print(log_model.score(x_train_new, y_train))\n",
    "print(log_model.score(x_val_new, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9488916666666667\n",
      "0.89605\n"
     ]
    }
   ],
   "source": [
    "#200 + 128\n",
    "\n",
    "log_model = LogisticRegression(random_state=42, max_iter=8000)\n",
    "\n",
    "log_model.fit(x_train_new, y_train)\n",
    "\n",
    "print(log_model.score(x_train_new, y_train))\n",
    "print(log_model.score(x_val_new, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9503416666666666\n",
      "0.895075\n"
     ]
    }
   ],
   "source": [
    "#500 + 128\n",
    "\n",
    "log_model = LogisticRegression(random_state=42, max_iter=8000)\n",
    "\n",
    "log_model.fit(x_train_new, y_train)\n",
    "\n",
    "print(log_model.score(x_train_new, y_train))\n",
    "print(log_model.score(x_val_new, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95515\n",
      "0.89615\n"
     ]
    }
   ],
   "source": [
    "# 200 + 256\n",
    "\n",
    "log_model = LogisticRegression(random_state=42, max_iter=8000)\n",
    "\n",
    "log_model.fit(x_train_new, y_train)\n",
    "\n",
    "print(log_model.score(x_train_new, y_train))\n",
    "print(log_model.score(x_val_new, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.776825\n",
      "0.7746416666666667\n"
     ]
    }
   ],
   "source": [
    "log_model.fit(y_predict_train, y_train)\n",
    "\n",
    "print(log_model.score(y_predict_val, y_val))\n",
    "print(log_model.score(y_predict_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.948075\n",
      "0.89915\n"
     ]
    }
   ],
   "source": [
    "# Try random forest on 0 + 256\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=5)\n",
    "\n",
    "rf.fit(y_predict_train, y_train)\n",
    "\n",
    "print(rf.score(y_predict_train, y_train))\n",
    "print(rf.score(y_predict_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9480083333333333\n",
      "0.899125\n"
     ]
    }
   ],
   "source": [
    "# Try random forest on 25 + 256\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=5)\n",
    "\n",
    "rf.fit(x_train_new, y_train)\n",
    "\n",
    "print(rf.score(x_train_new, y_train))\n",
    "print(rf.score(x_val_new, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9479916666666667\n",
      "0.899225\n"
     ]
    }
   ],
   "source": [
    "# Try random forest on 50 + 256\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=5)\n",
    "\n",
    "rf.fit(x_train_new, y_train)\n",
    "\n",
    "print(rf.score(x_train_new, y_train))\n",
    "print(rf.score(x_val_new, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.947975\n",
      "0.899125\n"
     ]
    }
   ],
   "source": [
    "# Try random forest on 100 + 256\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=5)\n",
    "\n",
    "rf.fit(x_train_new, y_train)\n",
    "\n",
    "print(rf.score(x_train_new, y_train))\n",
    "print(rf.score(x_val_new, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9479333333333333\n",
      "0.89915\n"
     ]
    }
   ],
   "source": [
    "# Try random forest on 200 + 256\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=5)\n",
    "\n",
    "rf.fit(x_train_new, y_train)\n",
    "\n",
    "print(rf.score(x_train_new, y_train))\n",
    "print(rf.score(x_val_new, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9479333333333333\n",
      "0.89915\n"
     ]
    }
   ],
   "source": [
    "# Try random forest on 500 + 256\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=5)\n",
    "\n",
    "rf.fit(x_train_new, y_train)\n",
    "\n",
    "print(rf.score(x_train_new, y_train))\n",
    "print(rf.score(x_val_new, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9479416666666667\n",
      "0.89915\n"
     ]
    }
   ],
   "source": [
    "# Try random forest on 1000 + 256\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=5)\n",
    "\n",
    "rf.fit(x_train_new, y_train)\n",
    "\n",
    "print(rf.score(x_train_new, y_train))\n",
    "print(rf.score(x_val_new, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9870666666666666\n",
      "0.897825\n"
     ]
    }
   ],
   "source": [
    "# XGB on 200 + 256\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb.fit(x_train_new, y_train)\n",
    "\n",
    "print(xgb.score(x_train_new, y_train))\n",
    "print(xgb.score(x_val_new, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 0.89735 (100 W2V, 100 SVD-TFIDF, 64 Last Layer Output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Neural Net with combined features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=2, dtype='int32')\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes=2, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size, shuffle):\n",
    "    number_of_batches = X.shape[0]/batch_size\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[batch_index,:].toarray()\n",
    "        y_batch = y[batch_index]\n",
    "        counter += 1\n",
    "        yield X_batch, y_batch\n",
    "        if (counter == number_of_batches):\n",
    "            if shuffle:\n",
    "                np.random.shuffle(sample_index)\n",
    "            counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Neural net with previous net output features only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 2)                 66        \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 2)                 6         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 4)                 12        \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 4)                 16        \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 212\n",
      "Trainable params: 176\n",
      "Non-trainable params: 36\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "epochs = 10\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(2, input_dim=32, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(2, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(2, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(rate = 0.2))\n",
    "model.add(layers.Dense(4, activation='relu', ))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(rate = 0.2))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "\n",
    "model.add(layers.Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"NN2.model\", monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler1 = StandardScaler()\n",
    "y_predict_train1 = scaler1.fit_transform(y_predict_train)\n",
    "y_predict_val1 = scaler1.transform(y_predict_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 40000 samples\n",
      "Epoch 1/10\n",
      "120000/120000 [==============================] - 48s 399us/step - loss: 0.6807 - accuracy: 0.5651 - val_loss: 0.6768 - val_accuracy: 0.5749\n",
      "\n",
      "Epoch 00001: val_loss improved from 0.67863 to 0.67681, saving model to NN2.model\n",
      "Epoch 2/10\n",
      "120000/120000 [==============================] - 51s 427us/step - loss: 0.6809 - accuracy: 0.5646 - val_loss: 0.6775 - val_accuracy: 0.5710\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.67681\n",
      "Epoch 3/10\n",
      "120000/120000 [==============================] - 58s 480us/step - loss: 0.6805 - accuracy: 0.5643 - val_loss: 0.6764 - val_accuracy: 0.5763\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.67681 to 0.67639, saving model to NN2.model\n",
      "Epoch 4/10\n",
      "120000/120000 [==============================] - 131s 1ms/step - loss: 0.6800 - accuracy: 0.5691 - val_loss: 0.6773 - val_accuracy: 0.5749\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.67639\n",
      "Epoch 5/10\n",
      "120000/120000 [==============================] - 120s 998us/step - loss: 0.6802 - accuracy: 0.5663 - val_loss: 0.6770 - val_accuracy: 0.5753\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.67639\n",
      "Epoch 6/10\n",
      "120000/120000 [==============================] - 109s 911us/step - loss: 0.6795 - accuracy: 0.5685 - val_loss: 0.6776 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.67639\n",
      "Epoch 7/10\n",
      "120000/120000 [==============================] - 120s 997us/step - loss: 0.6800 - accuracy: 0.5673 - val_loss: 0.6774 - val_accuracy: 0.5702\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.67639\n",
      "Epoch 8/10\n",
      "120000/120000 [==============================] - 112s 934us/step - loss: 0.6793 - accuracy: 0.5713 - val_loss: 0.6766 - val_accuracy: 0.5778\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.67639\n",
      "Epoch 9/10\n",
      "120000/120000 [==============================] - 111s 927us/step - loss: 0.6797 - accuracy: 0.5693 - val_loss: 0.6776 - val_accuracy: 0.5743\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.67639\n",
      "Epoch 10/10\n",
      "120000/120000 [==============================] - 113s 940us/step - loss: 0.6788 - accuracy: 0.5705 - val_loss: 0.6768 - val_accuracy: 0.5750\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.67639\n"
     ]
    }
   ],
   "source": [
    "model1 = model.fit(y_predict_train1, y_train, validation_data=(y_predict_val1, y_val), epochs=10, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model1.history['accuracy'])\n",
    "plt.plot(model1.history['val_accuracy'])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(model1.history['loss'])\n",
    "plt.plot(model1.history['val_loss'])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5747"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=42, max_iter=2000)\n",
    "\n",
    "y_train_label = np.argmax(y_train, 1)\n",
    "y_val_label = np.argmax(y_val, 1)\n",
    "\n",
    "model.fit(y_predict_train, y_train_label)\n",
    "model.score(y_predict_val, y_val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.582125"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(y_predict_train, y_train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160000\n",
      "120000\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import glob\n",
    "import os\n",
    "import string\n",
    "\n",
    "#Load training file\n",
    "\n",
    "text_file = open(\"train.txt.txt\", \"r\", encoding=\"utf8\")\n",
    "lines = text_file.read().split('\\n')\n",
    "\n",
    "labels = []\n",
    "for item in lines:\n",
    "    first_four_letters = item[:10]\n",
    "    if first_four_letters == '__label__1':\n",
    "        labels.append(int(1))\n",
    "    else:\n",
    "        labels.append(int(2))\n",
    "        \n",
    "def remove_label(s):\n",
    "    return s[11:]\n",
    "lines = [remove_label(s) for s in lines]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['text'] = lines\n",
    "df['label'] = labels\n",
    "\n",
    "df = df.sample(160000)\n",
    "print(len(df))\n",
    "df.head()\n",
    "\n",
    "#Clean text\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "#lowercase and remove punctuation, remove stopwords        \n",
    "df['text'] = df['text'].str.lower()\n",
    "df['text'] = df['text'].str.replace('-', ' ')\n",
    "df['text'] = df['text'].str.split(' ')\n",
    "df['text'] = df['text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].apply(lemmatize_text)\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].str.replace('\\\\', ' ')\n",
    "\n",
    "\n",
    "#Train Word2Vec\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "text = [row.split() for row in df['text']]\n",
    "model_w2v = Word2Vec(text)\n",
    "\n",
    "model_w2v.save('model_w2v.bin')\n",
    "\n",
    "x_train = df['text']\n",
    "\n",
    "df['label'] = df['label'] - 1\n",
    "\n",
    "y_train= np.asarray(df.label)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=40000, random_state=42)\n",
    "\n",
    "print(len(x_train))\n",
    "print(len(x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "max_length = 100\n",
    "\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(x_train)\n",
    "\n",
    "encoded_docs = t.texts_to_sequences(x_train)\n",
    "encoded_val = t.texts_to_sequences(x_val)\n",
    "\n",
    "word_index = t.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "padded_val = pad_sequences(encoded_val, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 150897 unknown vocab\n"
     ]
    }
   ],
   "source": [
    "num_words = len(word_index) + 1\n",
    "\n",
    "count =0 \n",
    "\n",
    "embedding_matrix = np.zeros((num_words, 100))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    try:\n",
    "        embedding_matrix[i] = model_w2v[word]\n",
    "    except KeyError as e:\n",
    "        count = count + 1\n",
    "\n",
    "print('Found ' + str(count) + ' unknown vocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187803"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36974"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_w2v.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(t, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# loading\n",
    "#with open('tokenizer.pickle', 'rb') as handle:\n",
    "    #tokenizer = pickle.load(handle)# loading\n",
    "#with open('tokenizer.pickle', 'rb') as handle:\n",
    "    #tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v.save('model_w2v.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=2, dtype='int32')\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes=2, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = model_w2v.wv.get_keras_embedding(train_embeddings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 100)          18780300  \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100, 128)          117248    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 18,947,086\n",
      "Trainable params: 18,947,086\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec Embedding\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, LSTM, Dense, Dropout, SpatialDropout1D\n",
    "from keras.initializers import Constant\n",
    "\n",
    "model = Sequential()\n",
    "e = Embedding(embedding_matrix.shape[0], 100, embeddings_initializer=Constant(embedding_matrix), input_length = max_length, trainable=True)\n",
    "\n",
    "model.add(e)\n",
    "#model.add(SpatialDropout1D(0.3))\n",
    "model.add(LSTM(128, return_sequences=True, activation='tanh', dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(LSTM(64, return_sequences=False, activation='tanh', dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"NN_LSTM.model\", monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 40000 samples\n",
      "Epoch 1/25\n",
      "120000/120000 [==============================] - 780s 6ms/step - loss: 0.5792 - accuracy: 0.7061 - val_loss: 0.5362 - val_accuracy: 0.7514\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.53621, saving model to NN_LSTM.model\n",
      "Epoch 2/25\n",
      "120000/120000 [==============================] - 732s 6ms/step - loss: 0.5634 - accuracy: 0.7264 - val_loss: 0.5400 - val_accuracy: 0.7595\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.53621\n",
      "Epoch 3/25\n",
      "120000/120000 [==============================] - 717s 6ms/step - loss: 0.5737 - accuracy: 0.7111 - val_loss: 0.5435 - val_accuracy: 0.7411\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.53621\n",
      "Epoch 4/25\n",
      "120000/120000 [==============================] - 717s 6ms/step - loss: 0.5957 - accuracy: 0.6830 - val_loss: 0.6195 - val_accuracy: 0.6636\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.53621\n",
      "Epoch 5/25\n",
      "120000/120000 [==============================] - 718s 6ms/step - loss: 0.6306 - accuracy: 0.6469 - val_loss: 0.6194 - val_accuracy: 0.6634\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.53621\n",
      "Epoch 6/25\n",
      "120000/120000 [==============================] - 719s 6ms/step - loss: 0.6307 - accuracy: 0.6474 - val_loss: 0.6176 - val_accuracy: 0.6654\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.53621\n",
      "Epoch 7/25\n",
      "120000/120000 [==============================] - 718s 6ms/step - loss: 0.6263 - accuracy: 0.6547 - val_loss: 0.6157 - val_accuracy: 0.6701\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.53621\n",
      "Epoch 8/25\n",
      "120000/120000 [==============================] - 719s 6ms/step - loss: 0.6254 - accuracy: 0.6601 - val_loss: 0.6126 - val_accuracy: 0.6780\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.53621\n",
      "Epoch 9/25\n",
      "120000/120000 [==============================] - 725s 6ms/step - loss: 0.6212 - accuracy: 0.6703 - val_loss: 0.6067 - val_accuracy: 0.6886\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.53621\n",
      "Epoch 10/25\n",
      "120000/120000 [==============================] - 719s 6ms/step - loss: 0.6175 - accuracy: 0.6784 - val_loss: 0.6016 - val_accuracy: 0.7003\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.53621\n",
      "Epoch 11/25\n",
      "120000/120000 [==============================] - 719s 6ms/step - loss: 0.6177 - accuracy: 0.6829 - val_loss: 0.6050 - val_accuracy: 0.6974\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.53621\n",
      "Epoch 12/25\n",
      "120000/120000 [==============================] - 718s 6ms/step - loss: 0.6211 - accuracy: 0.6740 - val_loss: 0.6164 - val_accuracy: 0.6774\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.53621\n",
      "Epoch 13/25\n",
      "120000/120000 [==============================] - 719s 6ms/step - loss: 0.6275 - accuracy: 0.6619 - val_loss: 0.6180 - val_accuracy: 0.6732\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.53621\n",
      "Epoch 14/25\n",
      "120000/120000 [==============================] - 719s 6ms/step - loss: 0.5979 - accuracy: 0.6898 - val_loss: 0.4678 - val_accuracy: 0.7822\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.53621 to 0.46775, saving model to NN_LSTM.model\n",
      "Epoch 15/25\n",
      "120000/120000 [==============================] - 721s 6ms/step - loss: 0.4172 - accuracy: 0.8227 - val_loss: 0.3155 - val_accuracy: 0.8734\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.46775 to 0.31546, saving model to NN_LSTM.model\n",
      "Epoch 16/25\n",
      "120000/120000 [==============================] - 720s 6ms/step - loss: 0.3211 - accuracy: 0.8701 - val_loss: 0.2823 - val_accuracy: 0.8860\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.31546 to 0.28229, saving model to NN_LSTM.model\n",
      "Epoch 17/25\n",
      "120000/120000 [==============================] - 718s 6ms/step - loss: 0.2756 - accuracy: 0.8916 - val_loss: 0.2628 - val_accuracy: 0.8942\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.28229 to 0.26283, saving model to NN_LSTM.model\n",
      "Epoch 18/25\n",
      "120000/120000 [==============================] - 723s 6ms/step - loss: 0.2379 - accuracy: 0.9100 - val_loss: 0.2648 - val_accuracy: 0.8945\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.26283\n",
      "Epoch 19/25\n",
      "120000/120000 [==============================] - 723s 6ms/step - loss: 0.1970 - accuracy: 0.9281 - val_loss: 0.2726 - val_accuracy: 0.8929\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.26283\n",
      "Epoch 20/25\n",
      "120000/120000 [==============================] - 723s 6ms/step - loss: 0.1583 - accuracy: 0.9437 - val_loss: 0.2948 - val_accuracy: 0.8848\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.26283\n",
      "Epoch 21/25\n",
      "120000/120000 [==============================] - 740s 6ms/step - loss: 0.1282 - accuracy: 0.9556 - val_loss: 0.3123 - val_accuracy: 0.8825\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.26283\n",
      "Epoch 22/25\n",
      "120000/120000 [==============================] - 729s 6ms/step - loss: 0.1046 - accuracy: 0.9641 - val_loss: 0.3584 - val_accuracy: 0.8746\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.26283\n",
      "Epoch 23/25\n",
      "120000/120000 [==============================] - 731s 6ms/step - loss: 0.0893 - accuracy: 0.9696 - val_loss: 0.3604 - val_accuracy: 0.8720\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.26283\n",
      "Epoch 24/25\n",
      "120000/120000 [==============================] - 725s 6ms/step - loss: 0.0765 - accuracy: 0.9743 - val_loss: 0.3980 - val_accuracy: 0.8672\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.26283\n",
      "Epoch 25/25\n",
      "120000/120000 [==============================] - 723s 6ms/step - loss: 0.0695 - accuracy: 0.9763 - val_loss: 0.4148 - val_accuracy: 0.8647\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.26283\n"
     ]
    }
   ],
   "source": [
    "model = model.fit(padded_docs, y_train, batch_size=512, epochs=25, validation_data=[padded_val, y_val], callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXhU5dn48e+dyU4SsrMlISEsgiBbABEU3BBX3AXqbkXr0talb21/rbX29dW2ttVWrUVFRQW0LgWt1hUqKFtYwhIEEiALCWQlkASyzfP74wwQQ5YJTGYmM/fnuuaamXOeM3MfhtzzzHOeRYwxKKWU8h8Bng5AKaWUe2niV0opP6OJXyml/IwmfqWU8jOa+JVSys8EejqAluLj401qaqqnw1BKqW5l3bp1ZcaYBGfKel3iT01NJTMz09NhKKVUtyIiec6W1aYepZTyM5r4lVLKz2jiV0opP+N1bfytaWhooLCwkCNHjng6FLcJDQ0lKSmJoKAgT4eilPIx3SLxFxYWEhkZSWpqKiLi6XC6nDGG8vJyCgsLSUtL83Q4Sikf0y2aeo4cOUJcXJxfJH0AESEuLs6vfuEopdynWyR+wG+S/lH+dr5KKffpFk09SinlSxqb7FTU1FNyqI6y6jrKquspPVRHz7AgZk9I6fL318TvhPLycs4//3wA9u3bh81mIyHBGiC3Zs0agoODO3yN2267jUceeYQhQ4Z0aaxKKc9qsht27D9EdtFBSqvrKD2W3OsoO1RPaXUdlbX1tLYUypiUaE383iIuLo6NGzcC8NhjjxEREcHDDz/8vTLGGIwxBAS03nr26quvdnmcSin3q6ptYH1BJRvyKlmXX0lWQRXVdY3H9ocF2UiIDCE+IpjU+HAyUmOIjwhxbAshITKY+AjrcY8Q96RkTfynICcnhyuvvJLJkyezevVqPvroI37729+yfv16Dh8+zA033MCjjz4KwOTJk3nuuecYPnw48fHx3H333XzyySeEh4ezePFiEhMTPXw2SqmO2O2G3NJq1udXsj7vAOvyK8kpqQbAFiCc1juSq0b3Y2z/GEYk9aR3VKjbknlneF9EHfjth1vJLjro0tcc1jeK31x++kkdm52dzauvvsqLL74IwFNPPUVsbCyNjY2ce+65XHvttQwbNux7x1RVVTFlyhSeeuopHnzwQebNm8cjjzxyyuehlHKthiY7WQUHWJlbTmZeJRvyKzl4xKrNR4cHMSYlhqtG92N0SjQjk6K9Msm3pntE6cXS09MZN27csecLFy7klVdeobGxkaKiIrKzs09I/GFhYVx88cUAjB07luXLl7s1ZqVU6+x2w3f7DvFtbhnf5JSxZncFNfVNiMDgxEguPaMPY1JiGNM/hgHxPbpt77tul/hPtmbeVXr06HHs8c6dO3n22WdZs2YN0dHR3Hjjja32xW9+Mdhms9HY2HhCGaVU1zPGkF9Ryzc55XyTW8aq3HLKa+oBGBDfg6vG9GNSejxnDogjpkfHnTi6i26X+L3ZwYMHiYyMJCoqiuLiYj799FOmT5/u6bCUUs1U1NSzfGcp3+SU8U1OOXsPHAagV1QIUwYncNbAeCYNjKNPzzAPR9p1NPG70JgxYxg2bBjDhw9nwIABTJo0ydMhKaWwmnBW7SpnwZp8Pt26j4YmQ8+wICYOiOPuKQM4a2B8t2666SwxrXUm9aCMjAzTciGWbdu2MXToUA9F5Dn+et5KuUpZdR3vritk0Zp89pTX0jMsiGvGJHHl6L6c3rcntgDfSfQiss4Yk+FMWa3xK6V8it1uWLmrnAWr8/ks26rdj0+N5ScXDOLi4X0IDbJ5OkSP08SvlPIJpYcctfu1+eSV1xIdHsTNE1OZNT6ZgYmRng7Pq2jiV0p1W3a74dvcchauaVa7T4vlgQsGM314b63dt0ETv1KqW1qXV8HjH20jq+AA0eFB3DIxlZnjUxiYGOHp0LyeU4lfRKYDzwI24GVjzFMt9vcH5gEJQAVwozGm0LGvCdjsKJpvjLnCRbErpfxQYWUtT33yHR9tKiYxMoTfXzOCGaP6ae2+EzpM/CJiA54HLgQKgbUissQYk92s2NPAfGPM6yJyHvAkcJNj32FjzCgXx62U8jPVdY28sDSHl1fsJkDgx+cN5K4p6d1mmgRv4sxCLOOBHGPMLmNMPbAImNGizDDgS8fjpa3s7/amTp3Kp59++r1tzzzzDPfcc0+bx0RE6E9OpU5Vk92waE0+U/+4jBeW5XLJ8N589dBUHpw2RJP+SXIm8fcDCpo9L3Rsay4LuMbx+CogUkTiHM9DRSRTRFaJyJWtvYGIzHGUySwtLe1E+O4za9YsFi1a9L1tixYtYtasWR6KSCnf921OGZf9bQWPvL+Z/nHh/OveSTwzczR9o313VK07OJP4Wxvh0HLU18PAFBHZAEwB9gJHJ6BJcQwqmA08IyLpJ7yYMXONMRnGmIyjC5x4m2uvvZaPPvqIuro6APbs2UNRURGjRo3i/PPPZ8yYMYwYMYLFixd7OFKlur/dZTXcOT+T2S+v5uDhBv42azTv3j2RUcnRng7NJzjzO6kQSG72PAkoal7AGFMEXA0gIhHANcaYqmb7MMbsEpFlwGgg96Qj/uQR2Le543Kd0XsEXPxUu0Xi4uIYP348//nPf5gxYwaLFi3ihhtuICwsjA8++ICoqCjKyso488wzueKKK/xm6LdSrlRV28Bfv9rJ/JV7CLYF8LOLhnDH5DS9cOtiziT+tcAgEUnDqsnPxKq9HyMi8UCFMcYO/AKrhw8iEgPUGmPqHGUmAX9wYfxudbS552jinzdvHsYYfvnLX/L1118TEBDA3r172b9/P7179/Z0uEp1K59n7+fn722israeGzKSeXDaYBIjQz0dlk/qMPEbYxpF5D7gU6zunPOMMVtF5HEg0xizBJgKPCkiBvgauNdx+FDgHyJix2pWeqpFb6DO66Bm3pWuvPJKHnzwwWMrbI0ZM4bXXnuN0tJS1q1bR1BQEKmpqa1OxayUal1dYxNPfvwdr327h+H9onjzjgkM6xvl6bB8mlOXxI0xHwMft9j2aLPH7wLvtnLct8CIU4zRa0RERDB16lRuv/32Yxd1q6qqSExMJCgoiKVLl5KXl+fhKJXqPvaU1XDfwvVs2XuQW89K5ReXnEZIoDbrdDXtC9VJs2bN4uqrrz7Ww+cHP/gBl19+ORkZGYwaNYrTTjvNwxEq1T0s3riX//fBFmwBwtybxjLtdG0edRdN/J101VVX0Xwq6/j4eFauXNlq2erqaneFpVS3UVvfyGNLtvJOZiEZ/WN4dtZo+mn3TLfSxK+Ucpvt+w5x34L15JRWc++56TxwwWACbc70KleupIlfKdXljDEsWlvAY0u2EhkaxBu3T2DyoHhPh+W3uk3iN8b4Vd94b1sZTamTdfBIA798fzMfbSrm7EHx/On6kdpN08O6ReIPDQ2lvLycuLg4v0j+xhjKy8sJDdU/DtW9ZRUc4P6FG9h74DA/u2gIP5qSToAPLXfYXXWLxJ+UlERhYSHeOo9PVwgNDSUpKcnTYSh1UowxvPbtHv7v420kRITw9pwzyUiN9XRYyqFbJP6goCDS0tI8HYZSygmNTXYeXbKVBavzuWBoL56+7gyiw4M9HZZqplskfqVU93DwSAP3vrWe5TvL+NHUdH42bYg27XghTfxKKZcorKzl9tfWsqu0ht9fM4IbxqV4OiTVBk38SqlTtrHgAD98PZO6xiZev308kwZqV01vpolfKXVKPtlczE/f3khiVAiL5kxgYGKkp0NSHdDEr5Q6KcYY/vH1Lp765DvGpEQz9+YM4iNCPB2WcoImfqVUpzU02fn1v7awaG0Bl53Rh6evG6mLpXQjmviVUp1SdbiBe95axzc55dx/3kAeuGCw9tzpZjTxK6WcVlBRy22vrSWvvIanrxvJtWN1kGF3pIlfKeWUdXmVzJmfSaPdMP/2CUxMj/N0SOokaeJXSnXo35uKeeCdjfTpGcq8W8eRnhDh6ZDUKdDEr5RqkzGGuV/v4slPviOjfwxzb84gtodOv9DdaeJXSrWqscnObz/M5o1VeVx6Rh/+pD13fIYmfqXUCWrrG7l/wQa+/K6Eu6YM4OcXnaY9d3yIU2ueich0EdkuIjki8kgr+/uLyJcisklElolIUrN9t4jITsftFlcGr5RyvZJDR5g5dxVLt5fwuyuH84uLh2rS9zEd1vhFxAY8D1wIFAJrRWSJMSa7WbGngfnGmNdF5DzgSeAmEYkFfgNkAAZY5zi20tUnopQ6dTklh7hl3loqaup56eYMzh/ay9MhqS7gTI1/PJBjjNlljKkHFgEzWpQZBnzpeLy02f6LgM+NMRWOZP85MP3Uw1ZKudqqXeVc/cK31DXaefuuMzXp+zBnEn8/oKDZ80LHtuaygGscj68CIkUkzsljEZE5IpIpIpn+tMqWUt5i8ca93PzKGhKjQvngnrM4Iyna0yGpLuRM4m+tca/lSuAPA1NEZAMwBdgLNDp5LMaYucaYDGNMRkJCghMhKaVcwRjD80tz+MmijYxOiea9u88iOTbc02GpLuZMr55CILnZ8ySgqHkBY0wRcDWAiEQA1xhjqkSkEJja4thlpxCvUupUNTVA/iqajhzirVW72bSzhEcHRHPThCSCcgrB2ME0gb3p+48DbBAWA2GxEB57/D4ozNNnpDpJjDmhAv79AiKBwA7gfKya/FpgtjFma7My8UCFMcYuIk8ATcaYRx0Xd9cBYxxF1wNjjTEVbb1fRkaGyczMPJVzUkq1piwHNsyHjQuhpsR1rxsY1uyLIAbC445/KfQZBYOmQaAO+upqIrLOGJPhTNkOa/zGmEYRuQ/4FLAB84wxW0XkcSDTGLMEq1b/pIgY4GvgXsexFSLyO6wvC4DH20v6SikXq6+F7MWwfj7kfwtioz79Qv6wbwyZleHcPXUQ00f0AwkAsVm1egmwbgE2a9vRx/ZGOFwJtRVwuKLFfSXUlluP92227o8csH4xhMfDyJkw+kZIHOrpfxGFEzV+d9Mav1KnyBgo3gjr34DN/4S6gxA7AEbfROXga5m1cA97ymv4+41jOXdIYtfF0dQIuV/Chjdg+yfWF0e/DOsLYPjVENqz697bD3Wmxq+JXylfcbgSNr8L61+3at2BoTDsShhzE/SfxIHDDcx+aTW5pdXMu3Wce9fFrS6Fze9YX0al26zmoWEzrC+B1MkgOkDsVGniV8qfFKyBNS/BtiXQeAT6jITRN8GI6yDM6pZZdbiBG19ezfZ9h3jplgymDPZQ7zljoGg9bHjT+pKqOwgxaTD6BzByNvQ8obe3cpImfqX8waF98NmvrZp0SE844zor4fcd9b1iB480cNMra8guqmLuTRmce1oXNu90Rn0tbPvQagras9y6ljBgqnVBOKovRPU7fh8eBwFOzTDjt1x6cVcp5WWaGmDNXFj6JDTVwTk/g8kPQHCPE4oeOtLALfOspP/3H4z1nqQPEBwOI2+wbhW7YeMC2PIe7P7auh7QXEAQRPVp9mXQ7IshdgD0Gq7NRZ2gNX6lupM9K+DfD1vt5IOmwfSnIC691aI1dY3cMm8NGwoO8PzsMUwf3tvNwZ4kux1qSuHgXjhY5Lg1e3zIcd945Pgx8YNh5Cyr91BUX8/F7kHa1KOUrzlYDJ/9Cra8C9EpMP33MOTiNmu5tfWN3PrqWtblVfLXmaO59Iw+bg64ixljXcw+uBf2rrPGJhSsAgTSz7WuF5x2qfWrwk9oU49SvqKpAVa/CMuesh5P+bnVrNPOaNnD9U3c8VommXsqeMYXkz5YX3jhjkFivUfA2FuhPBeyFkLWInj/hxASBadfaX0JpJypTUHNaI1fKW+1+2v4+GdQ+h0Mng7Tn7Tas9txpKGJO+dnsiKnjD9fP5KrRie1W94n2e2Qt8K6ZpC9BBpqrH+3o01B0SmejrBLaFOPUt3ZwSJHs857EN0fLnY063SgrrGJOfPX8fXOUv547UiuHeuHSb+lumqrm+vGBVbPIYDUs2HQhdYXQM8UiE6GHgnd/heBJn6luqvcr+Dtm6xeLZMfgEk/cWoStLrGJn705nq++q6E318zghvG+Wat9pRU5sGmt60vgcrd398XGAo9k60vgaP30f2PP47sY01b4cW0jV+p7ipzHoREwm2fQGyaU4c0NNm5b8EGvvquhP+7SpN+m2L6w5T/sW6HD0BVARwocNznW7eqAijeBLVl3z82IAh6D4fkMyFlgnUf1X2vnWjiV8pbGAP5qyH9PKeTPsDP393E59n7eXzG6cyeoEnfKWHR1q33iNb319dCVSFUOb4QKvdA4TpY9xqs/rtVJjrl+BdBykRIGNptBplp4lfKW1TssqZLTpng9CE79h/i/Q17+dHUdG6emNp1sfmb4HBIGGzdmmtqsH4RFKyC/FWw+7/WyGmwRk8nZVg9iJInQL+xEBLh/tidoIlfKW9RsNq6T5no9CHzVuwmNCiAO89uv7ePchFbECSNtW4T77V+pVXusT67/JXWL7alTxwv3yMBeiY5bsnNHjuee+iisiZ+pbxF/iprquL4IU4VL6uu4/0Ne7lubBKxPXShE48QsZrlYtOsrqJgDSwrWGtNjV1VYDUZle6AnC+hofb7x9tCrInpejouKvceAWfe3eVha+JXylvkr7KaCJxsJ35zVR71jXZun+z89QDlBmExMHiadWvu6GjjqsJmt4Ljj3O/ggN5mviV8hu1FVC23ZqwzAlHGpp4Y2UeFwxNJD3BO9uRVQvNRxv3OaP1Mna7W0LpHpeglfJ1BWus++QznSr+rw17Ka+p547J2rbvU9zUK0gTv1LeIH+l1Ve835gOixpjeHnFbk7vG8WZA2LdEJzyNZr4lfIGBautBVScGKX73x2l5JRU88Oz05BuPs2A8gxN/Ep5WmMd7F1vXdh1wisrdtMrKoRLR/jnvPPq1DmV+EVkuohsF5EcEXmklf0pIrJURDaIyCYRucSxPVVEDovIRsftRVefgFLdXtFGayWtlI7b97/bd5DlO8u45axUggO13qZOToe9ekTEBjwPXAgUAmtFZIkxJrtZsV8B7xhj/i4iw4CPgVTHvlxjzPcXAVVKHVewyrp3osb/yvLdhAXZmD1ep2ZQJ8+ZKsN4IMcYs8sYUw8sAma0KGOAKMfjnkCR60JUysflr4bYdIhofz3ckkNHWLyxiOsykogO1wFb6uQ5k/j7AQXNnhc6tjX3GHCjiBRi1fbvb7YvzdEE9F8RObu1NxCROSKSKSKZpaWlzkevVHdnjFXjd6KZ542VeTTY7dw+SQdsqVPjTOJvrdtAy0n8ZwGvGWOSgEuAN0QkACgGUowxo4EHgQUiEtXiWIwxc40xGcaYjISEhM6dgVLdWXkO1JZ32MxzuL6JN1flceHQXqTG93BTcMpXOZP4C4HkZs+TOLEp5w7gHQBjzEogFIg3xtQZY8od29cBuUCL6e6U8mP5jvb9DiZme39DIZW1DfxQJ2NTLuBM4l8LDBKRNBEJBmYCS1qUyQfOBxCRoViJv1REEhwXhxGRAcAgYJergleq28tfBWGxED+ozSJ2u+GVFbs5I6kn41Jj3Bic8lUdJn5jTCNwH/ApsA2r985WEXlcRK5wFHsIuFNEsoCFwK3GWtPxHGCTY/u7wN3GmIquOBGluqUCx8Rs7QzEWrajhF2lNdwxWQdsKddwapI2Y8zHWBdtm297tNnjbGBSK8e9B7x3ijEq5Ztqyqw2/tE3tVvs5eW76dMzlEtGdN+l/pR30REgSnnKsYVX2u7Rs7Woim9zy7n1rFSCbPrnqlxD/ycp5Sn5K8EWDH3aHt/4yvLdhAfbmKkDtpQLaeJXylPyV0PfMRAU2urufVVHWJJVxPUZyfQMC3JzcMqXaeJXyhMaDkPRhnYXVp+/cg92Y3TAlnI5TfxKeULRBrA3tLnwSm19I2+tzuei03uTEhfu5uCUr9PEr5Qn5Lc/Mdt76wqpOtzAD8/W2r5yPU38SnlCwWqIHww94k7YdXTA1qjkaMak6IAt5Xqa+JVyN7vdqvG3Udv/8rsS9pTX6gpbqsto4lfK3cp2wJEDbfbff2n5LvpFhzH99N5uDkz5C038SrlbQdsTs20qPMCa3RXcNimVQB2wpbqI/s9Syt3yV0F4PMSeONPm4o1FhAQGcP245FYOVMo1NPEr5W75joVXWmm/31lSzaBeEUSF6oAt1XU08SvlTof2Q+XuNtv3c0uqGZgQ4eaglL/RxK+UOx1bWP3ExF9T18jeA4cZmKiJX3UtTfxKuVP+aggMhT4jT9i1u6wGgHSt8asupolfKXcqWAX9xkJg8Am7ckqqAbTGr7qcJn6l3KW+Foqz2hy4lVNSjS1A6B+ni6mrrqWJXyl32bsO7I1tXtjNKammf2w4wYH6Z6m6lv4PU8pdjl3YHd/q7tzSatK1mUe5gSZ+pdwlfxUkDIWwEydea2yys6e8Rtv3lVto4lfKHex2KFjb5sIreRW1NDQZ7dGj3MKpxC8i00Vku4jkiMgjrexPEZGlIrJBRDaJyCXN9v3Ccdx2EbnIlcEr1W2UboO6qjYXXsnVHj3KjQI7KiAiNuB54EKgEFgrIkuMMdnNiv0KeMcY83cRGQZ8DKQ6Hs8ETgf6Al+IyGBjTJOrT0Qpr5a/0rpv68JuqZX40xO0R4/qes7U+McDOcaYXcaYemARMKNFGQNEOR73BIocj2cAi4wxdcaY3UCO4/WU8i/5qyGiF8Sktro7p6Sa3lGhROocPcoNnEn8/YCCZs8LHduaewy4UUQKsWr793fiWERkjohkikhmaWmpk6Er1Y0UOBZeaWNhldySatITtbav3MOZxN/a/1TT4vks4DVjTBJwCfCGiAQ4eSzGmLnGmAxjTEZCQoITISnVjRwsggP5rc6/D2CMIbe0RidnU27TYRs/Vi29+eTgSRxvyjnqDmA6gDFmpYiEAvFOHquUbzu6sHobPXr2H6yjuq5RL+wqt3Gmxr8WGCQiaSISjHWxdkmLMvnA+QAiMhQIBUod5WaKSIiIpAGDgDWuCl6pbqFgNQSFQ+8zWt19dI4e7cqp3KXDGr8xplFE7gM+BWzAPGPMVhF5HMg0xiwBHgJeEpEHsJpybjXGGGCriLwDZAONwL3ao0f5nfyV1sRsttYv3OaWaldO5V7ONPVgjPkY66Jt822PNnucDUxq49gngCdOIUaluq+6ati3Bc5+sM0iOSXVRIYGkhAZ4sbAlD/TkbtKdaW9mWCa2hy4BVbiT0+IQNro8aOUq2niV6or5a8CBJLHtVkkp7Ram3mUW2niV6or5a+CXqdDaM9Wd1cdbqD0UJ0mfuVWmviV6ipNjVC4ts2FV6DZhV3t0aPcSBO/Ul2lJBvqq9ucnweadeXUGr9yI038SnWV4o3Wfb+xbRbJLa0m2BZAckyYm4JSShO/Ul2neBMER0JMWptFckuqSYvvQaBN/xSV++j/NqW6SnEW9B4BAW3/meXo5GzKAzTxK9UV7E2wfwv0GdlmkSMNTeRX1OqFXeV2mviV6grlOdBQC31an58HIK+8FrvRC7vK/TTxK9UVirOs+3Zq/Do5m/IUTfxKdYXiLAgMhfghbRbJKalGRBO/cj9N/Ep1heIsSBwGtrbnQcwtraZfdBhhwTY3BqaUJn6lXM8Y2Lep3WYesGr8OlWD8gRN/Eq52oE8OFLVbuK32w27yqq1mUd5hCZ+pVzt2IXdtnv07D1wmCMNdq3xK4/QxK+UqxVngdgg8fQ2i+ToqlvKg/w78Zduhy3vgd3u6UiULyneBIlDISi0zSK52pVTeZBTSy/6lLpDsPUDWP8GFDrWfR+2GK76BwTpRFnqFBljTc428MJ2i+WUVBPbI5jYHsFuCkyp4/wj8RsDBautZL/1A2iogfjBcOHvwN4AX/4ODhbDrIXQI97T0aru7NA+qCntsEdPbmm1TtWgPMa3E/+h/ZC1EDa8CeU7ITgChl8NY26GpHFwdI3TuIHw/hx45UL4wbsQl+7ZuFX3tW+Tdd/OhV2wavzTh/dxQ0BKncipxC8i04FnARvwsjHmqRb7/wKc63gaDiQaY6Id+5qAzY59+caYK1wReJuaGmHnZ1ay3/Gf4wtdT/4pDLsSQlqpZQ2bAZF9YOFMePkCmLUIUtpeNUmpNh3t0dN7RJtFyqvrqKxtID1BZ+VUntFh4hcRG/A8cCFQCKwVkSXGmOyjZYwxDzQrfz8wutlLHDbGjHJdyG2oKYdv/2rV8Kv3Q49EOOs+GH0TxA/q+Pjk8XDH5/DWtfD65XD1P+D0q7o8bOVjirOsX5AhkW0WyS2tAbRHj/IcZ2r844EcY8wuABFZBMwAstsoPwv4jWvC64QAG6x9GdLOgdE3wqBpYAvq3GvEpcMdX8CiWfDPW6GqECbed7xJSKmOFG+CpIx2ixydnE0Tv/IUZ7pz9gMKmj0vdGw7gYj0B9KAr5ptDhWRTBFZJSJXtnHcHEeZzNLSUidDbyEsGh76zrpAe9qlnU/6R/WIg5sXW81Cn/0KPv6ZNbe6Uh2prYCqfKemaggLstG3p/YiU57hTOJvrbpr2ig7E3jXGNM8U6YYYzKA2cAzInLClVNjzFxjTIYxJiMhIcGJkNrQzs/rTgkKg2tfhbN+DGtfgkU/gPoa17y28l3HLux2kPhLqxmQ0IOAAP0lqTzDmcRfCCQ3e54EFLVRdiawsPkGY0yR434XsIzvt/97r4AAmPY7uORp2PkpvHap1UtIqbY4MQc/WIO3tJlHeZIziX8tMEhE0kQkGCu5L2lZSESGADHAymbbYkQkxPE4HphE29cGvNP4O2HmQmuU78sXWPdKtaY4C3omQ3hsm0Vq6xvZe+CwjthVHtVh4jfGNAL3AZ8C24B3jDFbReRxEWneNXMWsMgY07wZaCiQKSJZwFLgqea9gbqNIdPhto+hqc7q67/nG09HpLxR8Sbo3X7//V3ao0d5Aaf68RtjPgY+brHt0RbPH2vluG+Btjs0dyd9R8MPv4D5M+DDn8D9mZ6OSHmTumprnd0R17VbLFcnZ1NewL8naeus6BQYd6c1CvhAvqejUd5k/xbAONWjxxYg9I8Ld09cSrVCE39npZ9n3ecu9T99nx0AABiuSURBVGwcyrs4MQc/WIk/JTackEBdblF5jib+zkoYYk3vsEsTv2qmOAt6JFj/N9qRU6KrbinP08TfWSJWrX/XMh3YpY4rdqyx284o78YmO3vKa7R9X3mcJv6TkX4eHK605l1XquEIlG7rsEdPfkUtDU1GJ2dTHqeJ/2QMmGrd537VXinlL0qywd7o1IVd0B49yvM08Z+MHvFW7S53macjUd7Ayakajs7Kma6JX3mYXyf+vPIaXliWw6EjDZ0/OP08a1WvukOuD0x1L8VZENITYlLbLZZTUk1iZAhRoSc5gaBSLuK3iX/H/kNc++JK/vCf7Vz61xVsyK/s3Aukn2ct26ijeFXxJqsbZwfTd+eU6hw9yjv4ZeLfsreKmXNXIcCfrx9Jk91w3YsreWFZDnZ7WxOPtpByJgSGaTu/v2tqtAZvdXBh1xijk7Mpr+F3iX9DfiWzX1pFWJCNd+6ayNVjkvj4x2dz0em9+cN/tnPjK6vZf/BIxy8UGAKpk7Q/v78r2wGNRzps3y85VEd1XaMmfuUV/Crxr95Vzo0vryamRzBv33UmqfFWt7qe4UE8N3s0v79mBBvyDzD9ma/5ItuJKZjTz7P+8A8UdFxW+SZn5+B39OjRwVvKG/hN4l++s5RbXl1D756hvHPXRJJivj9Xiohww7gUPrx/Mn16hvHD+Zk8ungLRxraGaR1dPoGrfX7r+Isq8mvg3WdtSun8iZ+kfi/yN7PHa9lkhrXg7fvmkivqNA2yw5MjOCDe8/ijslpzF+Zx4znvmHH/jZ67iScZg3R13Z+/1WcBb2HW2s+tyO3tJrIkEASI0PcFJhSbfP5xP/vTcXc/eY6TusTyaI5ZxIf0fEfXkigjV9fNoxXbxtHWXUdl/9tBW+uyuP7Sw1g9eIYcK5O3+Cv7HbYt7nDZh6wavwDEiOQDnr+KOUOPp34319fyP0L1zMqOZo3fziB6PDgTh1/7pBEPvnp2YxPi+VX/9rCXW+s40Bt/fcLHZu+IcuFkatuoXI31B3ssEcPWIl/oLbvKy/hs4l/wep8HvpnFmcOiGP+HeNPetBMYmQor982nv93yVCWbi9h+jPLWbun4niBAVOte23u8T9OXtg9eKSBkkN12r6vvIZPJv55K3bzyw82M3VwAvNuHUd4sFMLjbUpIEC485wBvP+jSYQGBXDbq2vZU2YNvyciAXqP0Pn5/VFxFgQEQuLQdovlHuvRo5OzKe/gc4n/+aU5PP5RNtNP780/bsogNMh1C16MSOrJmz+cgC1AuHfB+uM9fo5N31DtsvdS3UBxlpX0A9u/bqQ9epS38ZnEb4zhT59t54+fbmfGqL48N3s0wYGuP72kmHD+dN1IthYd5Il/b7M2Hp2+IU+nb/Abxhyfg78DOaXVBNsCSInV5RaVd/CZxJ9bWsM//ruLGzKS+fP1owi0dd2pXTCsF3eencYbq/L4aFMRJOv0DX7nYBHUlkHvjhN/bkkNqfHhXfp/UqnOcOp/oohMF5HtIpIjIo+0sv8vIrLRcdshIgea7btFRHY6bre4MvjmBiZG8K97J/Hk1SOwBXR9l7n/mX4ao1OieeS9zeyuaoL+Z2ni9ydOXtgFqw+/jthV3qTDxC8iNuB54GJgGDBLRIY1L2OMecAYM8oYMwr4G/C+49hY4DfABGA88BsRiXHtKRw3rG8UAW5I+gBBtgCemz3Gau9/az0NaVOt6RuqCt3y/srDirMAsQZvtaOusYk8XW5ReRlnavzjgRxjzC5jTD2wCJjRTvlZwELH44uAz40xFcaYSuBzYPqpBOxN+kWH8efrR5JdfJC/F/S3NmrvnlOT8wW8Mg3+cQ7881b44rewfj7sWQFVe61BU96gOMuapiG4/Z46eeW12I1e2FXexZl+jv2A5rOQFWLV4E8gIv2BNOBom0drx/Zr5bg5wByAlJQUJ0LyHucP7cVd5wzgz1/nMic6gdDcr2DMTZ4Oq/vZtwU+/7XVXBbd30qqxVmw7UNrWcOjAkOtBU9i0iB2AMSmWbf4IRCd7L54izdB/4kdFtPJ2ZQ3cibxt9Z20tak9TOBd40xR+cvcOpYY8xcYC5ARkaGkxPie4+HLxrC2j0VfLp/KJflLMVmb+pw7hblcLAIvnoCNr4FoT3hov+DcT883kWyqRGqCqxRshW7oGI3VO6xHu9aBo2Hj7/WhY/DpJ90fcw1ZXCw0OmpGgAGaB9+5UWcSfyFQPOqVBJQ1EbZmcC9LY6d2uLYZc6H1z0cbe9/7tlRzKj7mrqCDYT0z/B0WN6t7hCseAZWPg+mCc66D85+CMJaXAKyBR6v1R+dDfUoY+DQPutLYfU/4PNHrdc99/91uBrWKTk6PYeTUzX0iw475UGESrmSM238a4FBIpImIsFYyX1Jy0IiMgSIAVY22/wpME1EYhwXdac5tvmcvtFhXDxjJgD//eRtD0fjxZoaYe3L8NfRsPxpOO1SuG8tTPvfE5N+R0Qgqo/Vo+raeTDmZvj6j/CfR7r2WsCxHj0dJ/7c0mpdXF15nQ6rIcaYRhG5Dyth24B5xpitIvI4kGmMOfolMAtYZJpNYWmMqRCR32F9eQA8boypwEedPep09n02mMi9K1iSVcQVI/t6OiTvYQxs/wS++I3V+6n/JJj9NvQb65rXD7DB5X+F4EhY9bw1ivqKv3ZNk1txFkSndPhFZbcbckurmZAW5/oYlDoFTv3+NMZ8DHzcYtujLZ4/1sax84B5Jxlft5Mw8iLiVv6ds95bw/C+FzBAL+rB3vXw2a8hbwXEDYKZC2DIJa5vjhGBi56A0ChY9iTUV8PVL0Fg52Zl7ZCTI3b3HjjMkQa79uhRXkeHErqYbeD5BNHImbZt3LtgQ/srePm6ku+sLpkvnQul38ElT8M9K63mna5qgxeBqY/AtCcg+1+waDbU17ru9Y8chIrcDhO/MYanPvkOW4CQkdplQ1eUOima+F0tZSIEhvI/g4rYVnyQxz/K9nRE7le6A969A144E3Z+Dmc/DD/eAOPvBNvJTY/daWfdB5c/a40LePMaK2G7wr7N1n0HUzW8sSqPf28u5uFpQxjcK9I1762Ui2jid7WgUOg/ieSK1dw9JZ0Fq/NZvHGvp6Nyj7IceH8OvDDBas+f9BP4ySY4/9dW84u7jb0VrnkZCtfA/Cug1gWXl5yYqiGr4AC/+yib805L5K5zBpz6eyrlYpr4u0L6uVC2nYcnhJPRP4Zfvr+ZXaU+PGVzeS58cDc8P84acDXxPvjpJrjwt9Cjay9sHjrSwDc5ZSxYnU9x1eETC4y41rqmsD8bXr3E6v55KoqzIKI3RPZqdXdVbQP3vLWexMhQ/nTdSLdNIaJUZ2jn4q7g6G8euOe//G32tUx/Zjm/XryFN++Y4Ftrrlbshq+fhqyFVhPOmfdYtfyIxC55u8YmO9v3H2JjwQE25h9gY8EBckqrOdqPzBYgXHR6L26ZmMr4tNjj/9aDL4Ib34WFs2DeRXDzYmv078kozmqzG6cxhof+uZGSQ0d4566JxPRw8UVlpVxEE39XSBwGEb0g9yv6jLmJh6YN5tHFW/l0636mD+/t6ehOXWWe1Qd/4wIQG0y4Cyb9tM1a8Mkqrjp8LMFvKDjA5sIqDjsulseEBzE6JYbLR/ZlVHI0vaJCeX99IYvWFvDx5n2c1juSmyemcuXovtbgqbRzrIT/5jUw72LrccLgzgXUcBhKt1sXp1sx9+tdfLGthN9cPozRKXpBV3kvadbt3itkZGSYzMxMT4dx6j64G3Z8Cj/LpdHAZX9bQXVdI188OMWlq4K51f6tsGYubHjTSvhjb4XJD1iDqFygyW5YkVPGe+sKWb27nP0H6wAItgUwrG8Uo5KjGZ0SzajkaFJiw1v99XS4vokPs4p47ds9ZBcfJCo0kOszkrlpYn/6x/Ww5gR64yprtPDsd6xxBM7+CitcBy+fB9e/AcOu+N6utXsqmDl3FdOG9eKFH4zxrV92qlsQkXXGGKemDNAaf1cZcK7VBLIvi8C+o/nN5acz66VVzP16Fz8+f5Cno3NedSls/idkLbB6tNiCYextcPaDEOWaAWp55TX8M7OQ99YXUlx1hJjwIM4ZnMDo5GhGpcQwtE8kIYHOfVmGBdu4flwy12UksS6vktdX5vHat3t45ZvdnDskkZsn9uecWz8m4I0r4eXzoUcC9B0NfUZZ931HQWSf1r8M9jmmamhxYbesuo77FqwnOSaM3197hiZ95fU08XeVAVOt+9yvoO9oJqbHcekZfXhhWQ7XjE2iX3SYJ6NrX2Od1SsnaxHkfG7Njtl3NFz8Bxh+rUsu2NbWN/LJ5n28k1nA6t0VBAhMGZzAo5cN47yhiU4n+raICBmpsWSkxrL/0qEsWJ3PgjX53PrqWlLjwrlzzOtcHbKGsNLNULzR6vZpHNM8RPT6/hdB39EQ2dtq3w+NtkbtOjTZDT9dtJHK2gbm3TOOqFA3dVdV6hRoU09X+vtkCIuGWz8CrJGc5/9pGecP7cXzs8d4OLgWjIHCTOtXypb34MgBq+Z7xvUwcpa1qPgpv4VhQ8EB/plZwIdZxVTXNZIaF851GclcMyaJ3j1DXXAibatvtPPJlmLmr8xjXV4lkaGB/OT8Qdw8MZVg+2GrGahog/VFULTBas8/OplsRG+rjb/vSLjlw2Ov+ewXO/nLFzt48uoRzBrfvaYUV75Fm3q8Rfq5sOrvUF8DwT3oFx3Gj6YM5C9f7OCmM8s5c4AXzOFSVWjV7LMWQflOa+3goZfByJlWc5UL5ropOXSED9bv5Z3MAnJLawgLsnHpGX24PiOZcakxbmsaCQ4MYMaofswY1Y/NhVU8/dl2/vff23hrdT6/vGQoFwwdj6Q0W2qirtpq3jr6RbBvC4y47tjuFTvLeObLHVw9uh8zx7lxLQClTpHW+LtS7lfWhcTZ/4TB0wA40tDE+X/6L5GhgXx0/2T3L8BdUwaFa6FgDeSvgvyVgIGUs2DULBh2pcsGW2UXHeSFZTl8smUfTXbD2P4xXJ+RxKVn9CUixDvqHEu3l/DEv7eRU1LNpIFx/OrSYQzt0/H57z94hEueXU5sj2AW3zdJp11WHqc1fm/hmL6B3K+OJf7QIBu/unQoP3prPQvX5HPTxNSue/+mRti/xUr0R5N95W5rn9is9WKn/Nyq3cemuext1+dX8vxXOXz5XQkRIYHcMTmN6zOSvXKysnOHJDJ5YDwLVufzly92cOlfl3PDuBQemjaY+IiQVo9pbLJz/4IN1NY3sWjOGE36qtvR/7FdKSjMmis+96vvbZ4+vDdnpcfx9Gc7uOyMvq4b6FNdcjzBF2ZC0XpocExQ1iMRksdbXTCTxlkXLIPDXfO+WO33K3PLeW5pDt/mlhMdHsSDFw7mlomp9Az37gueQbYAbjkrlStH9ePZL3cyf+UePswq4r7zBnLbpNQTLjQ//dkO1uyp4C83jGSQzsOjuiFt6ulq3/4NPvsVPJANPY8vN7x93yEu+etyZo9P4XdXDm//NeoOwaH9UL0Pqvcff9zy/nClVT4g0FodKnm8leSTxlk9UbqgLd0Yw9LtJfztqxw25B8gITKEOWcPYPaEFHp4SXNOZ+WWVvPkx9v4YlsJKbHh/OLi05g+vDciwpfb9nPH65nMGp/Ck1eP8HSoSh3TmaYeTfxdbd8WeHESRCVBSARIgOMmFFXVU1bTwKBeUYSFBFnNL0f32xuhpsRK6g01J76uLdjqaRKRaHU1jOhlTUOQPN7qZx7Utd1Fm+yGT7YU8/zSXLYVH6RfdBh3T03nurFJ3XeAWgvLd5byvx9tY/v+Q4xPi2XO2QN46J9Z9IsO4/17zvKZ81S+QRO/NzEGvngMDuRb/cRNk7XN2GlobGRVbikRITZGJUUhxg52x34RK6m3TO5H78NiunZd2TY0NNlZvLGIF5blsKu0hgEJPbhn6kBmjOpLkLsvVLtBY5OdtzML+NNnO6ioqScyJJAP759Marwunq68i17c9SYi1iyVrQgCClbn88sPNvO3S0ZzuZcu1VhV28Dq3eWs3FXOZ1v3s/fAYYb2ieL52WOYPrw3Nh+egTLQFsAPJvTn8pF9ee2bPWSkxmjSV92e1vg9rMluuOK5FVTU1PPlQ1O8oodIdV0ja3dXsHJXOd/mlrG16CDGQEhgAOPTYrltUirnDknUqQmU8iJa4+9GbAHCb684nWtfXMmLy3J5cNoQt8dwuL6JzLwKVuZatfpNhVU02Q3BtgBGpUTz4/MGcVZ6HKNSok95KgWllOdp4vcCGamxzBjVlxe/3sV1Gckkx7qum2Vbckur+femYlbsLGNDQSUNTYbAAOGMpJ78aEo6E9PjGJMSQ1iwJnqlfI1TiV9EpgPPAjbgZWPMU62UuR54DGtykyxjzGzH9ibAsVAp+caYK1oeq+AXFw/l8+z9/O+/s/nHTU79Wuu0ogOH+TCriCVZRWwtOogIjOjXk9snpzFxQBzjUmO7bRdMpZTzOvwrFxEb8DxwIVAIrBWRJcaY7GZlBgG/ACYZYypFpPkSTIeNMaNcHLfP6d0zlHvPHcgfP93O8p2lnD0owSWvW15dx8ebi1mSVcTaPVY//5HJ0fz6smFcdkYfekV17cRoSinv40z1bjyQY4zZBSAii4AZQHazMncCzxtjKgGMMSWuDtQf3DE5jXcyC/jth9l88pOzT7p75KEjDXy2dT9LsopYkVNGk90wKDGCh6cN5vKRfa0FSZRSfsuZxN8PKGj2vBCY0KLMYAAR+QarOegxY8x/HPtCRSQTaASeMsb8q+UbiMgcYA5ASor/Tm1rzeMzjDvnZ/LGyjxun9z6/DnGGBqaDA1Ndhqa7NQ32WloMmwqOMCSrCK++q6EukY7STFhzDlnAFeM7MtpvSO1F45SCnAu8beWLVr2AQ0EBgFTgSRguYgMN8YcAFKMMUUiMgD4SkQ2G2Nyv/dixswF5oLVnbOT5+BTLhiayDmDE3jqP9/x2rd7HMn9eJI/+rwt8REhzBqfwuUj+zImJVqTvVLqBM4k/kKg+WTjSUBRK2VWGWMagN0ish3ri2CtMaYIwBizS0SWAaOBXFSrRIT/u2o4z36xk4YmO0G2AIICAwi2BRBkE+u5LYDgwBbPbQEkxYQxPi3W/VM9K6W6FWcS/1pgkIikAXuBmcDsFmX+BcwCXhOReKymn10iEgPUGmPqHNsnAX9wWfQ+KikmnD9eN7LjgkopdRI6TPzGmEYRuQ/4FKv9fp4xZquIPA5kGmOWOPZNE5FsoAn4mTGmXETOAv4hInYgAKuNP7uNt1JKKeUGOmWDUkr5gM5M2aCNwUop5Wc08SullJ/RxK+UUn5GE79SSvkZTfxKKeVnNPErpZSf8brunCJSCuSdwkvEA2UuCqe70XP3X/58/v587nD8/PsbY5ya1tfrEv+pEpFMZ/uy+ho9d/88d/Dv8/fnc4eTO39t6lFKKT+jiV8ppfyMLyb+uZ4OwIP03P2XP5+/P587nMT5+1wbv1JKqfb5Yo1fKaVUOzTxK6WUn/GZxC8i00Vku4jkiMgjno7H3URkj4hsFpGNjjWOfZaIzBOREhHZ0mxbrIh8LiI7HfcxnoyxK7Vx/o+JyF7H579RRC7xZIxdRUSSRWSpiGwTka0i8hPHdp///Ns5905/9j7Rxi8iNmAHcCHWMpBrgVn+tOiLiOwBMowxPj+QRUTOAaqB+caY4Y5tfwAqjDFPOb74Y4wxP/dknF2ljfN/DKg2xjztydi6moj0AfoYY9aLSCSwDrgSuBUf//zbOffr6eRn7ys1/vFAjjFmlzGmHlgEzPBwTKqLGGO+BipabJ4BvO54/DrWH4RPauP8/YIxptgYs97x+BCwDeiHH3z+7Zx7p/lK4u8HFDR7XshJ/oN0Ywb4TETWicgcTwfjAb2MMcVg/YEAiR6OxxPuE5FNjqYgn2vqaElEUoHRwGr87PNvce7Qyc/eVxK/tLKt+7dhdc4kY8wY4GLgXkdzgPIffwfSgVFAMfAnz4bTtUQkAngP+Kkx5qCn43GnVs6905+9ryT+QiC52fMkoMhDsXiEMabIcV8CfIDV/OVP9jvaQI+2hZZ4OB63MsbsN8Y0GWPswEv48OcvIkFYie8tY8z7js1+8fm3du4n89n7SuJfCwwSkTQRCQZmAks8HJPbiEgPx8UeRKQHMA3Y0v5RPmcJcIvj8S3AYg/G4nZHk57DVfjo5y8iArwCbDPG/LnZLp///Ns695P57H2iVw+AowvTM4ANmGeMecLDIbmNiAzAquUDBAILfPn8RWQhMBVrOtr9wG+AfwHvAClAPnCdMcYnL4C2cf5TsX7qG2APcNfRNm9fIiKTgeXAZsDu2PxLrLZun/782zn3WXTys/eZxK+UUso5vtLUo5RSykma+JVSys9o4ldKKT+jiV8ppfyMJn6llPIzmviVUsrPaOJXSik/8/8BjzhNr89CJh4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history['accuracy'])\n",
    "plt.plot(model.history['val_accuracy'])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(model.history['loss'])\n",
    "plt.plot(model.history['val_loss'])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 100)          18771100  \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100, 128)          117248    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 18,937,886\n",
      "Trainable params: 18,937,886\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, LSTM, Dense, Dropout\n",
    "from keras.initializers import Constant\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "e = Embedding(len(word_index), 100, input_length = max_length, trainable=True)\n",
    "\n",
    "model.add(e)\n",
    "model.add(LSTM(128, return_sequences=True, activation='tanh', dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(LSTM(64, return_sequences=False, activation='tanh', dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"NN_LSTM_1.model\", monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 40000 samples\n",
      "Epoch 1/25\n",
      "120000/120000 [==============================] - 734s 6ms/step - loss: 0.6723 - accuracy: 0.5445 - val_loss: 0.5683 - val_accuracy: 0.7457\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.56830, saving model to NN_LSTM_1.model\n",
      "Epoch 2/25\n",
      "120000/120000 [==============================] - 738s 6ms/step - loss: 0.5723 - accuracy: 0.7363 - val_loss: 0.5721 - val_accuracy: 0.7305\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.56830\n",
      "Epoch 3/25\n",
      "120000/120000 [==============================] - 738s 6ms/step - loss: 0.5965 - accuracy: 0.6979 - val_loss: 0.5981 - val_accuracy: 0.6763\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.56830\n",
      "Epoch 4/25\n",
      "120000/120000 [==============================] - 740s 6ms/step - loss: 0.6364 - accuracy: 0.6107 - val_loss: 0.6538 - val_accuracy: 0.5738\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.56830\n",
      "Epoch 5/25\n",
      " 68608/120000 [================>.............] - ETA: 4:45 - loss: 0.6388 - accuracy: 0.6025"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-78637af61b26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded_docs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpadded_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = model.fit(padded_docs, y_train, batch_size=512, epochs=25, validation_data=[padded_val, y_val], callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history['accuracy'])\n",
    "plt.plot(model.history['val_accuracy'])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(model.history['loss'])\n",
    "plt.plot(model.history['val_loss'])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 100)          18780300  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 128)          117248    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 18,947,086\n",
      "Trainable params: 18,947,086\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec Embedding\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, LSTM, Dense, Dropout, SpatialDropout1D\n",
    "from keras.initializers import Constant\n",
    "\n",
    "model = Sequential()\n",
    "e = Embedding(embedding_matrix.shape[0], 100, embeddings_initializer=Constant(embedding_matrix), input_length = max_length, trainable=True)\n",
    "\n",
    "model.add(e)\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(LSTM(128, return_sequences=True, activation='tanh', dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(LSTM(64, return_sequences=False, activation='tanh', dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"NN_LSTM1.model\", monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-78637af61b26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded_docs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpadded_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'History' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "model = model.fit(padded_docs, y_train, batch_size=512, epochs=25, validation_data=[padded_val, y_val], callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120000 samples, validate on 40000 samples\n",
      "Epoch 1/25\n",
      "120000/120000 [==============================] - 170s 1ms/step - loss: 0.2267 - accuracy: 0.9111 - val_loss: 0.2736 - val_accuracy: 0.8901\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 0.27017\n",
      "Epoch 2/25\n",
      "120000/120000 [==============================] - 924s 8ms/step - loss: 0.2203 - accuracy: 0.9141 - val_loss: 0.2748 - val_accuracy: 0.8907\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.27017\n",
      "Epoch 3/25\n",
      "120000/120000 [==============================] - 889s 7ms/step - loss: 0.2146 - accuracy: 0.9168 - val_loss: 0.2777 - val_accuracy: 0.8911\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.27017\n",
      "Epoch 4/25\n",
      "120000/120000 [==============================] - 823s 7ms/step - loss: 0.2075 - accuracy: 0.9193 - val_loss: 0.2820 - val_accuracy: 0.8900\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.27017\n",
      "Epoch 5/25\n",
      "120000/120000 [==============================] - 824s 7ms/step - loss: 0.1993 - accuracy: 0.9242 - val_loss: 0.2800 - val_accuracy: 0.8905\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.27017\n",
      "Epoch 6/25\n",
      "120000/120000 [==============================] - 824s 7ms/step - loss: 0.1936 - accuracy: 0.9255 - val_loss: 0.2858 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.27017\n",
      "Epoch 7/25\n",
      "120000/120000 [==============================] - 826s 7ms/step - loss: 0.1861 - accuracy: 0.9292 - val_loss: 0.2919 - val_accuracy: 0.8885\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.27017\n",
      "Epoch 8/25\n",
      "119808/120000 [============================>.] - ETA: 1s - loss: 0.1808 - accuracy: 0.9315"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('NN_LSTM1.model')\n",
    "\n",
    "model2 = model.fit(padded_docs, y_train, batch_size=512, epochs=25, validation_data=[padded_val, y_val], callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXhU5dn48e+dnaxkY00gCUtYZQuggoi4sAgCahXcl5/WVm1frbbaqrUu72vf9m1t3bUi7tQNQQVRC7giJOwEBAKEMEkISSAQsifz/P44ExxilkkyySSZ+3Ndc03mzDnPPIeQc895lvsRYwxKKaWUj6croJRSqmPQgKCUUgrQgKCUUspBA4JSSilAA4JSSikHP09XoDliYmJMQkKCp6uhlFKdysaNGwuMMbFN7depAkJCQgJpaWmeroZSSnUqInLQlf20yUgppRSgAUEppZSDBgSllFJAJ+tDqE9VVRU2m43y8nJPV6VdBAUFERcXh7+/v6eropTqYjp9QLDZbISFhZGQkICIeLo6bcoYQ2FhITabjcTERE9XRynVxXT6JqPy8nKio6O7fDAAEBGio6O95m5IKdW+On1AALwiGNTypnNVSrWvLhEQlFKqK7LbDamZR3nko51U1djb/PM6fR+CpxUWFnL++ecDcPjwYXx9fYmNtSYEbtiwgYCAgCbLuPHGG7nvvvtITk5u07oqpTqHHw6f4MPNOXy0NYfsojKC/H24dGxfRvSNaNPP1YDQStHR0WzZsgWAhx9+mNDQUO65557T9jHGYIzBx6f+G7JXXnmlzeuplOrYbMdKWb41h2Wbc9idV4yvj3DOoBjunZ7MhcN6EhLY9pdrDQhtJCMjg3nz5jF58mTWr1/Pxx9/zJ/+9Cc2bdpEWVkZV155JQ899BAAkydP5umnn2bEiBHExMRw2223sXLlSoKDg1m2bBk9evTw8NkopdrC0ZJKPtmey/It2aRmHgNgXP9IHp07nFkjexMdGtiu9elSAeFPH6WzM+eEW8sc1iecP84Z3qJjd+7cySuvvMLzzz8PwBNPPEFUVBTV1dWcd955XH755QwbNuy0Y44fP865557LE088wd13382iRYu47777Wn0eSqmOobSyms935rFsSw5f7cmn2m4Y1COUe6cnc8moPsRHBXusbl0qIHQ0AwYMYPz48adev/3227z88stUV1eTk5PDzp07fxIQunXrxsyZMwEYN24cX3/9dbvWWSnlfpXVdr7em8+yLTl8sSuP0soa+kQEcfM5icwd1ZehvcM6xAjCLhUQWvpNvq2EhISc+nnv3r384x//YMOGDXTv3p1rrrmm3vkEzp3Qvr6+VFdXt0tdlVLuZbcb1h84yvKtOazckUtRaRXdg/2ZN6Yvc0f1YXxCFD4+ng8CzrpUQOjITpw4QVhYGOHh4eTm5rJq1SpmzJjh6WoppdzIGMOO7BMs25LNR9tyyDtRQXCALxcN68klo/sweWAsAX4dd7S/BoR2MnbsWIYNG8aIESNISkpi0qRJnq6SUspNMo6cZPlWa5jogYIS/H2Fqck9uGRUHy4Y2pNuAb6erqJLxBjj6Tq4LCUlxdRdIGfXrl0MHTrUQzXyDG88Z6U6mpyiMj7amsPyrTmk55xABM4eEM0lo/owY3hvIoI7TgJKEdlojElpaj+X7hBEZAbwD8AX+Jcx5ok67/cHFgGxwFHgGmOMzfHe9cADjl0fM8a86tg+DlgMdANWAL82nSk6KaW8TuHJClZsz2X51pxTw0RHxXfnodnDmH1Gb3qEB3m4hq3TZEAQEV/gGeBCwAakishyY8xOp93+CrxmjHlVRKYB/wNcKyJRwB+BFMAAGx3HHgOeA24FvscKCDOAle47NaWUar0T5VV8lp7H8q05fJtRQI3dMLhnKPdcNJg5o/rQPzqk6UI6CVfuECYAGcaY/QAisgSYCzgHhGHAXY6f1wAfOn6eDnxujDnqOPZzYIaIrAXCjTHrHNtfA+ahAUEp1QGUV9Xwn11HWL41mzW786msthMf1Y2fT0niktF9GNIr3NNVbBOuBIS+wCGn1zZgYp19tgKXYTUrzQfCRCS6gWP7Oh62erb/hIjcinUnQb9+/VyorlJKNV9VjZ1v9hawfGsOn6UfpqSyhtiwQK6e2I85o/owJr57h5gr0JZcCQj1/QvUbeu/B3haRG4AvgKygepGjnWlTGujMS8CL4LVqexCfZVSyiXVNXbWHzjKR1tz+DT9MEWlVUR082fOqD5cMqoPE5Oi8e1gcwXakisBwQbEO72OA3KcdzDG5ACXAohIKHCZMea4iNiAqXWOXesoM66xMpVSqi3UppT+eFsuK3fkUnCykpAAXy4c1pPZZ/RhyuCOPVegLbkSEFKBQSKSiPXNfwFwlfMOIhIDHDXG2IH7sUYcAawC/ltEIh2vLwLuN8YcFZFiETkTWA9cBzzV6rPxgKlTp3L//fczffr0U9uefPJJ9uzZw7PPPlvvMaGhoZw8ebK9qqiU1zPGsOVQER9tzWXF9lwOnygnyN+H84f0ZPYZvTlvSA+C/DvHXIG21GRAMMZUi8gdWBd3X2CRMSZdRB4B0owxy7HuAv5HRAxWk9HtjmOPisijWEEF4JHaDmbgF/w47HQlnbRDeeHChSxZsuS0gLBkyRL+8pe/eLBWSiljDOk5J/hoWw6fbMvFdqyMAF8fzk2O5f4zhnDB0PZJKd2Z6MS0ViosLGTIkCHYbDYCAwPJzMxkypQppKenM2/ePI4dO0ZVVRWPPfYYc+fOBVp/h+Dpc1aqIztYWMKHm3NYtiWb/QUl+PkIkwfFMPuMPlw0vCfhQR1nwlh7cevEtE5j5X1weLt7y+w1EmY+0eDb0dHRTJgwgU8//ZS5c+eyZMkSrrzySrp168bSpUsJDw+noKCAM888k0suuaTLj1JQyhOOllTyybYclm7OZlNWESIwMTGKW6YkMWN4LyJDml65UHW1gOAhtc1GtQFh0aJFGGP4/e9/z1dffYWPjw/Z2dnk5eXRq1cvT1dXqS6hdq7A0s3ZrN19hGq7IblnGPfNHMIlo/rQp3s3T1ex0+laAaGRb/Jtad68edx9992nVkMbO3YsixcvJj8/n40bN+Lv709CQkK96a6VUq6z2w3fHyjkw83ZrNx+mOKKanqGB3LT5ETmj+nL0N4dfMKYMVBVClXlUFPpeFRBTYXTz5VQXfHjz7WPIbMhqG3Pr2sFBA8JDQ1l6tSp3HTTTSxcuBCwVj7r0aMH/v7+rFmzhoMHD3q4lkp1XhlHinlvYzbLtmSTe7yc0EA/ZozoxfwxfTnTXXMFyoqgJB+M3bpw106NOtXP2sDrqnIoOwblRdZz2TGrrIa22ataVr/bx2lA6CwWLlzIpZdeypIlSwC4+uqrmTNnDikpKYwePZohQ4Z4uIZKdS41dsOaH46w+LtMvskowM9HOHdwLL+fNbT5KaWNsS72RYfgeJbj+RAUOf1c4cbldwPDIag7dHM8egyFbpE/bvMPBl9/8A0E3wDHzwHgF+B4HfDT98PrTebgVhoQ3GT+/Pk4j9iKiYlh3bp19e6rcxCUatjxsireTTvEq+syOXS0jN4RQdw7PZkrx8cT09ii85WlcOwAHN3/4+PYQetif9wG1XWabAPDoXs/65EwCSLiIawX+NQGGsddh0idn+u85xtoXexrH0ER4Ns5L62ds9ZKqS5nb14xi7/L5INN2ZRV1TAhIYr7ZgzlouE98fd1zByuLIGjB+Dovh8v+oWO5+I6yQ66RUFkAvQcDoNnWBf+iHjoHm89d+ve7ufY0WlAUEp5TI3dsPqHI7z6XSabMmzE+RXx64E+XJwoxPvuhexl8EMOFB+2mneKc08vICQWopIgaar1HJUI0QMgMlEv+C3QJQKCMcZrxvd3pomESp1SXWG11RdlwrFMygsOcujgPk4cySKxupAXfI4RElRm7ZvpeAAEhFnNOOG9YcA0x0Xf6dHGnazeptMHhKCgIAoLC4mOju7yQcEYQ2FhIUFBnXtVJtUF2Wusb+/HDkLRQafnTDh2EFOcizglNPYxvnQjEntALCG9R9Ctb6J10Q/r4wgAjufAMM+dkxfq9AEhLi4Om81Gfn6+p6vSLoKCgoiLi2t6R6XcwV4DpYVWk83JI3AyD046fj617bDVaVtT6XSgUBPam2OBvcn0GckW33PYWRbJIdODqvB4hicns3BiAiP6Rnjs1NRPdfqA4O/vT2JioqeroVTnVVEMR3ZB3g7IS7e+3Z/Msy72Jflgan56TGA4hPaA0F7QezQMnUNFaDw/VETxTUEonx7yY3ueNaonops/kwZGM2lgDL8eGEO/qOAufzffWXX6gKCUcpHdbg3LzEt3PHZYj2OZP+4TGAFRCRDWG/qMhtCedR49rOeAYACyCktZvjWbr/YWsDnrGFU1hgA/O+MTQvjtmP6cMzCWYX3CvWqRmc5MA4JSnV11BVSchMpia1hm7c8VJ61v+UfS4fAO6y6gqsQ6RnwgeiD0GQNjroGeI6xHRJzTWPv6FZdXsSI1i/c3ZrMh8ygiMKJPBDdPTmLywBhSEiJ1bYFOSgOCUh3dsUzY/SnsX2u151eePP2i31QqhG6R1sV+7HXWmPyewyF2yKlv+a6osRu+zSjg/U02VqUfprzKTlJMCPdOT2b+mL6aSK6L0ICgVEdjt0POJti9wgoER9Kt7VEDrG/woT0gIBQCQ52ew+p/HRxtNfG0sM0+48hJ3t9kY+mmbA6fKCc8yI/LxsZx2bg4r1h03ttoQFCqI6gshQNf/hgESo6A+EK/s+CixyF5pjXhqh0UlVby0dYc3tuUzdZDRfg6cgg9OHsY5w/VpSa7MpcCgojMAP6BtYTmv4wxT9R5vx/wKtDdsc99xpgVInI1cK/TrmcAY40xW0RkLdAbcMxG4SJjzJHWnIxSnUpxHuz5FHavtJqDqsusb/aDLoDkWTDwAgiOarfq7D5czLNrM1i5/TCVNXaG9ArjgYuHcsnoPvQI07kv3qDJgCAivsAzwIWADUgVkeXGmJ1Ouz0AvGOMeU5EhgErgARjzJvAm45yRgLLjDFbnI672hhz+pqYSnV1R3bBp/fD/jXW64h4GHutdRfQf7KV8bIdpecc56n/ZPBp+mGCA3y5amI/Lh8Xx/A+4dok5GVcuUOYAGQYY/YDiMgSYC7gHBAMUDuHPAKok2UKgIXA2y2vqlKdXPkJ+PLP8P1zVsqFqfdbi570HN7iNv7W2HqoiKdW7+WLXUcIC/TjzmkDuWlSoi436cVcCQh9gUNOr23AxDr7PAx8JiJ3AiHABfWUcyVWIHH2iojUAO8Dj5l6EvWIyK3ArQD9+vVzobpKdTDGwI73YdUfrFm9Y6+H8/8IIdEeqU5a5lH+uTqDr/bkE9HNn7svHMz1ZycQ0c37Fp9Xp3MlINT31aXuhXshsNgY838ichbwuoiMMMbYAURkIlBqjNnhdMzVxphsEQnDCgjXAq/95IOMeRF4ESAlJUUzu6nO5cgPsOIeyPzamtG74E2IS2n3ahhj+H7/UZ5avZfv9hUSFRLA72YM4dqz+hMaqGNLlMWV/wk2IN7pdRw/bRK6GZgBYIxZJyJBQAxQ20m8gDrNRcaYbMdzsYi8hdU09ZOAoFSnVHHS0Tz0rDUU9OK/wbgbnBZfaR/GGL7eW8BTq/eSmnmM2LBAHrh4KFdN7EdwgAYCdTpX/kekAoNEJBHIxrq4X1VnnyzgfGCxiAwFgoB8ABHxAX4GTKndWUT8gO7GmAIR8QdmA1+08lyU8jxjIH2p1TxUnANjroULHoaQmHatRo3d8PnOPJ7/ch9bDhXROyKIP10ynCvHx+uwUdWgJgOCMaZaRO4AVmENKV1kjEkXkUeANGPMcuA3wEsichdWc9INTv0BUwBbbae0QyCwyhEMfLGCwUtuOyulPCF/D6y81xpC2usMuOJViJ/QrlU4WVHNO6mHWPxdJllHS4mL7MZ/zx/JZeP6EuingUA1TjrTgispKSkmLU1HqaoOpvgwrH8evnvaSgcx7UFIualdm4cOHS3l1e8y+XfqIYorqknpH8nNkxO5cFhP/GqXn1ReS0Q2GmOa7LzSRkSlmqOyBHK2QHYa2NIgexOcsFnvjb4aLvgThMa2S1WMMWw8eIyXvznAqvTD+Igwa2RvbpqcyOh4XT5SNZ8GBKUaYrdDwR7HxT8VbBvhyM4f1wfo3h/6TYS+t0PiFOg1ol2qVVVjZ8X2XBZ9c4CttuNEdPPn1ikDuP7s/vSO0CRzquU0ICjlrPgwpC2CrO8hZzNUnLC2B0ZA37Fwzt3QNwX6jmu3O4Fax0ureGtDFq+tyyT3eDlJMSE8Onc4l42L0xFDyi30f5FSAOXH4dt/WsNEqyusb/sjf2bNGeibYq0d4OOZtvjqGjuvfJvJk1/soaSyhkkDo3l8/gimDu6Bjy48o9xIA4LybtUVkPoyfPUXKDsKIy6DaQ9AVJKnawbApqxj/GHpDnblnuD8IT24Z3oyQ3uHN32gUi2gAUF5J7sdtr8Lax6DoixImmrNF+gzxrP1cjheWsX/rvqBtzZk0Ss8iBeuHcdFw3pqsjnVpjQgKO9iDGT8B754GPK2W/MFrv0HDJjm6ZoB1sih5VtzePTjnRwtqeSmSYncdeFgTS+h2oX+L1PeI3sjfP5HK69QZAJc9jIMv9RjfQN1HSgo4cEPd/BNRgGj4ruz+MYJjOgb4elqKS+iAUF1fYX74D+PwM4PITgGZv7FyivUzusONKSiuobn1u7j2bX7CPTz4dF5I7hqQj98tcNYtTMNCKrrKsiAdU/B5jfANxDO/R2cfScEhnm6Zqd8l1HAAx/uYH9BCXNG9eHB2UN1dTLlMRoQVNdijNUktO4Za3lK30DrbmDKbyGsp6drd0rByQoe/2QXSzdn0z86mNdumsCUwe07r0GpujQgqK6hutJahGbdM1ZncXCMtSJZys3tPoGsKTlFZVz23HcUnKzgzmkDuf28gZqBVHUIGhBU51ZSCBsXwYaX4GQexA6BS56CkVeAf8drejlWUsm1L6/nZHk1S385STuNVYeiAUF1Tvl7rFnFW5dAdRkMOB/mPWcNH+2gY/VLK6u5cXEqh46V8fpNOoJIdTwaEFTnYQwc+BLWPQt7V1n9A6OuhDN/CT2Gerp2jaqqsXP7m5vYZiviuWvGMTHJM+spK9UYDQiqczh6AJbfaXUYh8TC1N9baw50sP6B+hhj+N3721izO5//nj+S6cN7ebpKStVLA4Lq2Ox2SH3Jmlns4wez/motS9kB+wca8sSnP/DBpmzuvnAwV03s5+nqKNUgl6ZoisgMEdktIhkicl897/cTkTUisllEtonILMf2BBEpE5EtjsfzTseME5HtjjL/KZqkRdVVuA9enQ0rfwv9z4ZfroMJt3SqYPCvr/fzwpf7ufbM/tw5baCnq6NUo5q8QxARX+AZ4ELABqSKyHJjzE6n3R4A3jHGPCciw4AVQILjvX3GmNH1FP0ccCvwvWP/GcDKlp6I6kLsdtjwAnzxJ/ANgLnPwuirOmxncUOWbrbx2Ce7mDWyFw9fMlwT06kOz5UmowlAhjFmP4CILAHmAs4BwQC1OXkjgJzGChSR3kC4MWad4/VrwDw0IKiCDFh2Oxz6HgZNhzlPQngfT9eq2dbuPsK9727jrKRo/n7laE1DoToFVwJCX+CQ02sbMLHOPg8Dn4nInUAIcIHTe4kishk4ATxgjPnaUaatTpl96/twEbkV606Cfv20/bXLstdYw0hXPwZ+gTD/BTjjyk53VwCwOesYv3hjE4N7hvHideMI9NNJZ6pzcCUg1PcXaeq8XggsNsb8n4icBbwuIiOAXKCfMaZQRMYBH4rIcBfLtDYa8yLwIkBKSkq9+6hOLn8PLPultW5x8iyY/XcI65wjcfbln+SmxanEhgWy+KbxhAX5e7pKSrnMlYBgA+KdXsfx0yahm7H6ADDGrBORICDGGHMEqHBs3ygi+4DBjjLjmihTdXX2Glj3NKx+HAKC4dJ/wcjLO+VdAcDh4+Vc9/IGfH2E126aoEnqVKfjyiijVGCQiCSKSACwAFheZ58s4HwAERkKBAH5IhLr6JRGRJKAQcB+Y0wuUCwiZzpGF10HLHPLGanOoaQAXr4IPn8IBl8Ev1wPZ/ys0waD46VVXL9oA0WllSy+cQIJMSGerpJSzdbkHYIxplpE7gBWAb7AImNMuog8AqQZY5YDvwFeEpG7sJp+bjDGGBGZAjwiItVADXCbMeaoo+hfAIuBblidydqh7C2MgY/vgsPb4PJF1iI1nTQQAJRX1fD/XkvlQEEJr9w4XlNSqE5LjOk8zfIpKSkmLS3N09VQrbX9PXj/ZrjgTzD5vzxdm1ax2w2/fHMTq3Ye5qmFY5h9RucbEaW6PhHZaIxJaWq/jrF2oPIexXmw4h6IG28tVtPJPfHpD3yafpg/zBqqwUB1ehoQVPupbSqqKrMyk/p07uGYb3x/kBe/2s91Z/Xn5smJnq6OUq2mAUG1n23vwO5PYNqDEDPI07VplbW7j/DH5emclxzLQ7OH6Sxk1SVoQFDt40QOrLwX4s+EM3/h6dq0yq7cE9zx1maSe4bx1FVj8fPVPyPVNej/ZNX2jIGPfm0tcznv2U7dVJR3opybFqcSGujHohvGExqoCYNV1+E9/5uN6dRDGzu1LW/C3s9gxp8heoCna9NiJRXV3PxqKsfLqnj3trPoFaETz1TX4h13CGv+20qhrNrfcRt8ej/0nwwTbvV0bVqsxm749ZLN7Mw5wdNXjWF4H51roLoe7wgIlSWw4UXI+MLTNfEuxlirnNlrYO7T4NN5/7s99slOvth1hIcvGc60IT09XR2l2kTn/QttjmkPQuwQWHYHlB3zdG28x6ZXYd9quOgRiOq8wzIXf3uAV77N5KZJiVx3VoKnq6NUm/GOgOAfBPOfh5J8WHGvp2vjHYqyYNUfIPFcGHeTp2vTYv/ZlccjH+/kwmE9+cPFQz1dHaXalHcEBIA+Y2DKb2H7u5D+oadr07XZ7dYiN9Cpm4p2ZB/nzrc3M7xPBP9YoIvcqK6vc/6lttQ5d1uB4eO7rBQKqm1sXAQHvoLpj0N3zy5qdKK8ikNHS6mxNy9nV05RGTctTqV7N39evj6F4ADvGZCnvJd3/S/39bdW4nphijUufuHbOhTV3Y4egM8eggHTYOz1Hq3KgYIS5j3zLcfLqvD3FeKjgkmMDqF/dAgJMcEkRIeQEB1Cn+5Bp00uO1lRzU2LUymtrOG9X5xFj3AdXqq8g3cFBIDYZDj/j7Dqftj8Boy91tM16jrsdqvj3scXLnnKo8G2uLyKW15Lw0fg0XkjyD5WxsHCEjILS1m3v5DSyppT+/r7CvGRwfSPDqZ/dAi7ck+w98hJFt0wniG9whv5FKW6Fu8LCAATb4PdK6zx8YlTILK/p2vUNaS+BAe/gbnPQERc0/u3EbvdcNe/t3KgoITXb57A2QNiTnvfGEN+cQWZhaVkFpSQWVjCwcJSMgtL2HDgKBXVdh6bN4JzB8d66AyU8gzvDAg+PtZF67lJVufndcs7bcdnh1G4Dz7/Iwy6CEZf7dGqPPnFHr7YlcfDc4b9JBgAiAg9woPoER7EhMSo094zxlBRbSfIv/Om11CqpVy6CorIDBHZLSIZInJfPe/3E5E1IrJZRLaJyCzH9gtFZKOIbHc8T3M6Zq2jzC2ORw/3nZYLIvvDjP+BzK9hwwvt+tFd0vJfgV8AzPmHR5uKVm7P5Z+rM7giJY7rz05o9vEiosFAea0mA4JjTeRngJnAMGChiAyrs9sDwDvGmDFYay4/69heAMwxxowErgder3Pc1caY0Y7HkVacR8uMuQYGz4AvHob8Pe3+8V3GkV1WU9G5v4Nwzy0Ssyv3BL95dytj+nXn0XkjNCW1Us3kyh3CBCDDGLPfGFMJLAHm1tnHALW9bxFADoAxZrMxJsexPR0IEpHA1lfbTURgzj/BPxiW/hxqqj1do85p+3sgPjDyZx6rwtGSSm55LY2wID9euGYcgX76LV+p5nIlIPQFDjm9tjm2OXsYuEZEbMAKoL61ES8DNhtjKpy2veJoLnpQGvg6JyK3ikiaiKTl5+e7UN1mCusJs/8GOZvgm7+5v/yuzhjY8R4kTYXQ9m31q1VdY+eOtzZxpLiCF65N0WGiSrWQKwGhvgt13Vk+C4HFxpg4YBbwuoicKltEhgN/Bn7udMzVjqakcxyPesd/GmNeNMakGGNSYmPbaNTH8PnWt9sv/ww5W9rmM7qq7I1wLBNGXO6xKjy+Yhff7Svkf+aPZHR8d4/VQ6nOzpWAYAPinV7H4WgScnIz8A6AMWYdEATEAIhIHLAUuM4Ys6/2AGNMtuO5GHgLq2nKc2b9BUJiYeltUFXu0ap0KtvfBd9AGDrbIx//TtohXvk2k5snJ3LZOM8NdVWqK3AlIKQCg0QkUUQCsDqNl9fZJws4H0BEhmIFhHwR6Q58AtxvjPm2dmcR8ROR2oDhD8wGdrT2ZFqlWyRc8jTk74I1j3m0Kp1GTTXs+AAGT4eg9l8fYFPWMR5YuoPJA2O4f+aQdv98pbqaJgOCMaYauANYBezCGk2ULiKPiMgljt1+A9wiIluBt4EbjDHGcdxA4ME6w0sDgVUisg3YAmQDL7n75Jpt0AUw7kb47mk4+J2na9PxZX4NJUdgZPs3F+WdKOe21zfSKyKIp68ao+saK+UGYl23O4eUlBSTlpbWth9ScRKen2T9fNu3EBjatp/XmX14O+xaDvfsAf9u7fax5VU1LHjxe/bkFbP0l5NI7hXWbp+tVGckIhuNMSlN7adfq+oKDIV5z1sdpRtf8XRtOq6qcisYDJ3TrsHAGMMflu5gy6Ei/nbFaA0GSrmRBoT69D8LQntC/g+erknHlfE5VJyAEZe168e+8m0m72+y8V8XDGLGiF7t+tlKdXUaEBoSlWSlclb12/6uNSor8dx2+8iv9uTz+IpdXDSsJ7+aNqjdPlcpb6EBoSGRiRoQGlJ+AnZ/CsMvBd/2yY+45ocj3PJaGoN6hPK3K0fjo6uXKeV2GhAaEpUExTlQVebpmnQ8P3wCNRXtNrpo5fZcbn09jcE9w3j7lqHEDHIAAB7zSURBVDMJDfTOJL1KtTUNCA2JSrSej2V6tBod0vZ3raUx48a3+Uct3Wzj9rc2cUZcd968ZSKRIQFt/plKeSsNCA2pDQhH93u2Hh3NyXzYv9ZKVdHG2UTfWp/F3e9s5cykaF67aQLhQf5t+nlKeTu9925IZG1A0H6E0+z8EExNm2c2/dfX+3nsk11MG9KDZ68eq2sUKNUONCA0JDgKgrrrHUJd29+FHsOhZ90lMdzn6dV7+etne5g1shdPXjmGAD+9kVWqPehfWmOikuCY3iGccuwgHFoPI9tm7oExhv/99Af++tkeLh3Tl38u0GCgVHvSv7bGRCXqHYKzHe9bz20wGc1uN/zpo508u3YfV0/sx19/NkrzEynVzvQvrjFRSVB0CGqqPF2TjmH7exA/ESIT3Fpsjd1w/wfbWfxdJv9vciKPzRuh8wyU8gANCI2JTLQ6UIuyPF0Tz8vbCUfS3b4QTlWNnbvf2cK/0w7xq/MH8YeLh+payEp5iAaExkQlWc860shaJlN8Yfg8txVZUV3D7W9uYtmWHH43Ywh3XzhYg4FSHqSjjBpzanKalwcEY6zmoqSpbls3uaK6hlte28hXe/L50yXDuf7sBLeUq5RqOb1DaExoT/AP1o5lWxoUHXRrqoo3vs/iqz35PHHpSA0GSnUQGhAaI6JJ7uDHdZOHuGfd5PKqGl78ah9nJkWxYEI/t5SplGo9lwKCiMwQkd0ikiEi99Xzfj8RWSMim0Vkm4jMcnrvfsdxu0VkuqtldhjePvS0phrSP4DkGRAU7pYi39toI+9EBXdqCmulOpQmA4KI+ALPADOBYcBCEak7TfUBrLWWxwALgGcdxw5zvB4OzACeFRFfF8vsGKKSrAR3druna+IZmV9BSb7bRhdV1dh5bu0+xvTrztkDot1SplLKPVy5Q5gAZBhj9htjKoElwNw6+xig9utjBJDj+HkusMQYU2GMOQBkOMpzpcyOISrRSvVcnNP0vl3R9vcgMBwGXeSW4pZuzia7qIxfTRukI4qU6mBcCQh9gUNOr22Obc4eBq4RERuwAriziWNdKRMAEblVRNJEJC0/P9+F6rrZqaGnXthsVFUOuz5yrJsc1OriauyGZ9dkMLxPOFOTY91QQaWUO7kSEOr7GmfqvF4ILDbGxAGzgNdFxKeRY10p09pozIvGmBRjTEpsrAcuIt6c9XTvZ9a6yW4aXfTxthwyC0u5c9pAvTtQqgNyZR6CDYh3eh3Hj01CtW7G6iPAGLNORIKAmCaObarMjiEiDnz8vfMOYfu7ENIDEqa0uii73fDMmgwG9QjlomG93FA5pZS7uXKHkAoMEpFEEQnA6iReXmefLOB8ABEZCgQB+Y79FohIoIgkAoOADS6W2TH4+EJkf++bnFZ+HPasguHz3bJu8mc789iTd5I7pg3UPEVKdVBN/qUbY6pF5A5gFeALLDLGpIvII0CaMWY58BvgJRG5C6vp5wZjjAHSReQdYCdQDdxujKkBqK/MNjg/94hK8r47hFPrJrd+IRxjDE+t3ktiTAizz+jjhsoppdqCS1/9jDErsDqLnbc95PTzTmBSA8c+DjzuSpkdVlQSHFxnpXDwlrbv7e9C9/4Ql9Lqotbuzic95wT/e/kZ+OrdgVIdls5UdkVkIlQWQ0mBp2vSPk4esdZNHtn6dZONMfxz9V76du/G/DH1DiRTSnUQGhBc4W1DT3d8AMbuluaidfsK2ZxVxG1TB+CvC94o1aHpX6grvCnr6fFs+PIJiBsPPYa2urh/rt5Lj7BAfjYuzg2VU0q1JQ0IrujeD8Sn698h2Gvgg1usFeLmv9Dq4lIzj/L9/qP8/NwBBPn7uqGCSqm2pOshuMIvEMLjuv7ktK/+Age/tYJB9IBWF/f06gyiQwJYOCG+6Z2VUh6ndwiu6upZTzO/gS//DKMWwqgFrS5um62IL/fkc/M5iQQH6PcOpToDDQiuikrsun0IpUfh/Vus0VSz/uqWIp9enUF4kB/XntnfLeUppdqeBgRXRSVBaaE1g9ddju6HnM3uK68ljIEPfwmlBfCzVyAwtNVF7so9wWc787hxUiJhQf5uqKRSqj1oQHDVqaGnbrxLWHEvvHG51ZnrKetfgD0r4cJHofcotxT5zJoMQgP9uHFSglvKU0q1Dw0IrjqV9dRN/Qh2OxxKtb6Z29LcU2Zz5W6Fzx+EwTNh4s/dUuS+/JN8sj2Xa8/qT/fgALeUqZRqHxoQXBXl5oBQsAcqHM1Puz2QwaOiGN69EYJjYN6zbkvJ8eyafQT6+XDz5ES3lKeUaj8aEFwVEAKhPd3XsWxLtZ4jE2D3SveU2Rwr7rXO5bJ/QXCUW4rMKizlwy3ZXDWhPzGhgW4pUynVfjQgNEdUkvv6EGypEBQBE38BBbuhcJ97ynXFlrdh69tw7u8god6chC3y3Jf78BXh1ilJbitTKdV+NCA0R2SiewNC3HgYMst63V53CQUZ8MlvoP9kmHKv24rNPV7GexsPccX4OHpFtH65TaVU+9OA0BxRSVCcA1VlrSun/AQc2WUFhO79oOfI9gkI1RXw3o3WzOtLX7QW/3GTF77cjzHw8ymtn+GslPIMDQjNcSrJXWbrysneCBgrIAAkz4Ss76wJYm3p8z/C4W1WJ3KE+1JRZxaU8NaGLOaP6Ut8VLDbylVKtS8NCM3hrpFGtcNM+46znpNnWumm937WunIbs3slrH/O6rNInum2Yo0xPLhsB4G+Ptw7Pdlt5Sql2p9LAUFEZojIbhHJEJH76nn/7yKyxfHYIyJFju3nOW3fIiLlIjLP8d5iETng9N5o955aG3DXugi2DRA7BLp1t173Hg1hvdtu+OnxbGs2cq8z4MI/ubXoj7fl8vXeAu6ZnkyPcO07UKozazLrmIj4As8AFwI2IFVEljuWzQTAGHOX0/53AmMc29cAox3bo4AMwPlr8L3GmPfccB7to1skBHVvXceyMVaH8pCLf9zm4wODZ1jLVlZXWG387lKb0rq6Ai5/xa1lnyiv4tGPdzKybwTXaM4ipTo9V+4QJgAZxpj9xphKYAkwt5H9FwJv17P9cmClMaa0+dXsQKKSWneHULgPyo792H9QK3kWVJ6EzK9bV7+6tr1jpbS++K8QM9CtRf/tsz3kn6zg8fkjdK1kpboAVwJCX+CQ02ubY9tPiEh/IBFYXc/bC/hpoHhcRLY5mpzq/eoqIreKSJqIpOXn57tQ3TbW2qyntRPS4iacvj1xCvgHu3+00YYXISbZSmvtRtttx3ltXSbXntmfM+K6u7VspZRnuBIQ6vvqZxrYdwHwnjHmtGxtItIbGAmsctp8PzAEGA9EAb+rr0BjzIvGmBRjTEpsbKwL1W1jUUlQdMhaVawlbKkQEAaxdTpg/YNgwDQrIJiG/nmbKXsj5GyC8f/PbakpAGrshj98uJ3o0EDu0Y5kpboMVwKCDXBe8ioOyGlg3/ruAgCuAJYaY05dRY0xucZSAbyC1TTV8UUmgqmBoqyWHW/bAHHj6p8DkDwLTmRbQ0PdIfVlCAh1y4I3zt5cf5BttuM8OHsY4ZreWqkuw5WAkAoMEpFEEQnAuugvr7uTiCQDkcC6esr4Sb+C464BERFgHrCjeVX3kNakwa4sgbz0n/Yf1Bo8HRD3NBuVHoUd78MZV0JQeOvLczhSXM5fPt3N5IExzDmjt9vKVUp5XpMBwRhTDdyB1dyzC3jHGJMuIo+IyCVOuy4ElhhzenuHiCRg3WF8WafoN0VkO7AdiAEea+lJtKvagNCSfoTsTdZ8g7r9B7VCYiB+onuGn25+A6rLreYiN3rs411U1Nh5dN4IxI3NUEopz3NpsVtjzApgRZ1tD9V5/XADx2ZSTye0MWaaq5XsUEJ7gH9Iy0YanepQTml4n+SZ8MUfrbkDLZ1NbLdD2svQfxL0HNayMurxzd4Clm/N4dfnDyIxJsRt5SqlOgadqdxcItZIo5YGhOiBjaebTnYku9vTimajff+x0muMv7nlZdRRXlXDg8t2kBAdzC+mar4ipboiDQgtEZnQ/D6E2glpDfUf1IoZBFEDWtePsOEla+2GIXNaXkYdL3y5nwMFJTw6bwRB/u5LiqeU6jg0ILREVJL1Ddxud/2YY5lQkt94cxFYdyDJM+HAV9aqZs11LNPKiTTuBvBzzxKWBwpKeGZtBnNG9eGcQR1g6K9Sqk1oQGiJqESoqbBSYbuqNqFdQx3KzpJnQU0l7Ktvfl8T0haB+FgBwQ2MMTzkSF734MVD3VKmUqpj0oDQEi1JcmdLtTqje7jQyRs/0cqb1Nxmo6py2PS6lScpvE/zjm2AJq9TyntoQGiJyNo02M3oR7BtgL5jwdeFgV2+fjBoOuxZBTXVrn9G+gdQdhQm3OL6MY04UV7FI5q8TimvoQGhJSLiwMff9TuEqjI4vL3p/gNnyTOti7ttg+vHpP7LyluUcI7rxzTib5/toUCT1ynlNTQgtISPr2OkkYsBIWcL2Ktd6z+oNfB88A1wfZJa9iYrd5Gb8hbVJq+7TpPXKeU1NCC0VHOynp6akNbEkFNngWHWN31X+xFSX7b6KEZd6fpnNMA5ed1vNHmdUl5DA0JLRSVZfQiuZCa1bbDuKEKbOWQzeSYUZkDB3sb3Kz0KO96zgkFQRPM+ox6avE4p76QBoaUiE60FbUoKGt/PGDjkwoS0+tSufdxUs5Eb8xZp8jqlvJcGhJZydejpcRucPNyygBARZ62D3FizUW3eon5nQ8/hzf+MOh7/ZBcV1XYemTtck9cp5WU0ILRUlGPoaVP9CC3pP3CWPAsOrW/4TqQ2b9GE1t8dfLO3gGVbcrht6gCSYkNbXZ5SqnPRgNBS3ftZM4KbukOwpYFfEPQc0bLPSZ5ppcze+1n97294CUJ6tDpvUUV1DQ8t20H/6GB+qcnrlPJKGhBayi/QatJpanKabQP0GdPyvEK9R0FYn/r7EdyYt+iFL/ezv6CER+dq8jqlvJUGhNaIbCINdnUF5G5t3oS0umqT3WWstlJTOHNT3qKDhSU8vSaDi8/ozZTBmrxOKW/lUkAQkRkisltEMkTkvnre/7uIbHE89ohIkdN7NU7vLXfanigi60Vkr4j827E8Z+cSldR4QMjdZiWpa86EtPokz4KqEsj8+sdtp/IWzWr5QjrUJq9LJ8DXh4dmu28xHaVU59NkQBARX+AZYCYwDFgoIqddOYwxdxljRhtjRgNPAR84vV1W+54xxnnJzT8DfzfGDAKOAe5bzaW9RCVa6SXKiup/v7UdyrUSz4GA0NObjdKXWp89vnV5i1buOMyXe/K5+8LB9NTkdUp5NVfuECYAGcaY/caYSmAJMLeR/RcCbzdWoFjjGacB7zk2vQrMc6Eu7aKy2s61L69n9Q95je/Y1PrKtg0QEQ/hrRzP7xcIA6ZZw09rJ8KlvgQxgyFxSouLPVlRzSMf7WRY73CuO0uT1ynl7VwJCH2BQ06vbdSzRjKAiPQHEgHnRP5BIpImIt+LSO1FPxooMsbUpvJssExPWJV+mK/3FvDU6ozGd2wq66ktrXX9B86GXAzFuZw8mEaNzT15i/7++R7yist5fP4I/Hy1O0kpb+dCLmbqu+I0lK9hAfCeMabGaVs/Y0yOiCQBq0VkO3DC1TJF5FbgVoB+/fq5UN3We+P7gwBszirih8MnGNIrvP4da+ci1NePcCIXjh+CM3/pnkoNuggjPryx+HkGBR3nPP9gfEYtaHFx6TnHWfxdJldN6MeYfpHuqaNSqlNz5WuhDYh3eh0HNLRU2ALqNBcZY3Icz/uBtcAYoADoLiK1AanBMo0xLxpjUowxKbGxbT8CJuNIMesPHOXnU5II8PVhyYZDDe8cEGKtXVxfk5G7+g9qBUeRFXIG0+3fMKlsLUtrJrMxr6bp4+phtxse+HAHkcH+/Hb6EPfUTynV6bkSEFKBQY5RQQFYF/3ldXcSkWQgEljntC1SRAIdP8cAk4CdxhgDrAEud+x6PbCsNSfiLm98n4W/r3DrlCRmjOjFB5tslFc1cuGtTXJXly3VSl/d+wy31Cv3eBlvHx9Bos9hgqSKjwNnseDF73lz/cFml7Uk9RCbs4r4/ayhRARr8jqllKXJgOBo578DWAXsAt4xxqSLyCMi4jxqaCGwxHGxrzUUSBORrVgB4AljzE7He78D7haRDKw+hZdbfzqtU1pZzfubbMwc0Zvo0EAWTIjnRHk1K3fkNnxQQ0NPbanWpDK/QLfU7anVGXxhH2u96Hc2T955DWcPiOEPS3dw/wfbqKh27W6h4GQFf/70B85MimL+mA7TbaOU6gBc6UPAGLMCWFFn20N1Xj9cz3HfASMbKHM/1gimDuPjrbkUl1efWi7yrKRoEqKDeXv9IeaPiav/oMhEKM6FylIICLa21VRBzmZIuckt9coqLOWd1EMsnDARut8PAy8gItifRTeM52+f7+aZNfvYlVvM89eMo1dE40NH/2fFD5RWVvPYvBGavE4pdRodWuLkjfUHGdwzlPEJVieriLBgQj82ZB4l48jJ+g86leQu88dth7db6ajd1H/w5Bd78PUR7pg2EKbed2rkkq+PcO/0ITx39Vj25BUz+6lvSM082mA56/cX8v4mG7dOSWJgjzC31E0p1XVoQHDYZitim+04V0/sf9o358vGxuHnI/w7Nav+A+vLempLs57dEBD25hWzdEs215+d0ODEsZkje/Ph7ZMIC/Jj4Yvf8/q6TEydhXsqq+088OEO4iK7ccd5g1pdL6VU16MBweHN77Po5u/L/LGnt6vHhgVy4bCevLfRVn87fX3rItg2QFhvK/ldK/3t8z2EBPhx27mNZyAd3DOMD2+fxJTBsTy4LJ3fvrfttM7wl785wN4jJ3lk7nC6BWjyOqXUT2lAAI6XVbF8aw5zR/epd8nIhRP6cay0is/S65m53C0SgrqfPtLIlmo167SyjX5H9nFW7jjMTZMTiQppOtVTRDd//nVdCr+aNpB3N9q48oV15B4vw3aslH/+Zy/Th/dk2pCeraqTUqrr0oAALN1ko6yqhqsn1p++YfLAGOIiu7GkwWYjp5FGJ/Ot/oTWJrQD/vrZbiK6+fP/zkl0+RgfH+Hui5J54dpx7MsvYc5T3/CrtzcjAn+c0/oV1ZRSXZfXBwRjDG+uz2JUXAQj4+pfoN7HR7gyJZ5vMwo5WFjy0x2ikn7sQ3DThLS0zKOs3Z3PL6YOaNFC99OH9+LD288mvJs/m7KK+K8LBtGne7dW1Ukp1bV5fUDYcOAoe4+c5OozG0/u9rOUeHx9hCWp9cxcjkqEoiyorrQCgo8f9Bnd4joZY/jLqt3EhgVy/VkJLS5nYA+rX+Hpq8Zw0yTX7zKUUt7J6wPCm+uzCA/yY84ZfRrdr1dEEOcl9+DdNBtVNfbT34xKspa5PH7ICgi9RoJ/y7+Nf5NRwPoDR7njvIGt7gAOD/Jn9hl9NHmdUqpJXn2VKDhZwcoduVw2Ls6lC+/CCfEUnKzgP7vqdC7XZj0t2AvZm1rVXGSM4a+rdtO3ezcWTIhv+gCllHITrw4I1rd9w9UTXcuieu7gWHpHBPF23YR3tUNPd39irWzWig7lz3fmsdV2nF+fP4hAPx0eqpRqP14bEOx2w1sbDnJmUpTLs3b9fH34WUo8X+3N59DR0h/fCO0B/iGQ7sjP18I1EOx2w/99toekmBAuHat5hpRS7ctrA4J1US9rcKhpQ65IsSabvZvmdJcgYnUsVxyHkFiITGhRnT7alsPuvGL+68LB2uavlGp3XnvVeeP7LGJCA5g+vFezjouLDObcwbG8k2aj2rlzuTYIxI1v0YS0qho7f/98D0N6hTF7ZCuX3FRKqRbwyoCQU1TG6h/yuCIlngC/5v8TLBjfj8Mnylm7O//HjbX9CC3sUH5/o43MwlJ+c1EyPj6ahVQp1f68MiAs2ZCFwUpJ0RLnD+1BTGjg6TOXWxEQKqpr+Od/9jIqvjsXDO3RojoppVRrubQeQldSVWNnSeohpg6OJT4quEVl+Pv6cEVKHM9/uY/Dx8utNQiGz4PyIuh3VrPLe2t9FjnHy/nfy0fpGgVKKY/xujuEL3bmcaS44tQiOC115fh47Abeqe1c7hYJk+8C3+bF2NLKap5Zk8GZSVFMGhjdqjoppVRruBQQRGSGiOwWkQwRua+e9/8uIlscjz0iUuTYPlpE1olIuohsE5ErnY5ZLCIHnI5rea6HZnhzfRZ9u3djanLrmmb6R4cwaWA0/049hN1umj6gAYu/y6TgZCX3Tk/WuwOllEc1GRBExBd4BpgJDAMWisgw532MMXcZY0YbY0YDTwEfON4qBa4zxgwHZgBPikh3p0PvrT3OGLPFDefTqAMFJXyTUcDCCVZeotZaOKEf2UVlfJ1R0KLjj5dV8cKX+zkvOZZx/aNaXR+llGoNV+4QJgAZxpj9xphKYAkwt5H9FwJvAxhj9hhj9jp+zgGOALGtq3LLvbX+IH4+whXj3ZMS4sJhPYkKCeDt9Q2kxW6E7Vgpv/9gO8fLqvjNRcluqY9SSrWGKwGhL+Ccq8Hm2PYTItIfSARW1/PeBCAA2Oe0+XFHU9LfRSSwgTJvFZE0EUnLz8+vbxeXlFfV8O5GG9OH96JHWOML0bsq0M+Xy8b25YtdeeQXV7h0zO7Dxdz97y1M/ctaVqUf5o7zBjKib/1pt5VSqj25EhDqa1tpqNF8AfCeMea0tSZFpDfwOnCjMaZ2Ntf9wBBgPBAF/K6+Ao0xLxpjUowxKbGxLb+5WLE9l6LSKpfzFrlqwYR+VNsN7220NbpfWuZRbl6cyvQnv+LT9MNcd1YCX/32PO6ZrncHSqmOwZUhMTbAuY0lDshpYN8FwO3OG0QkHPgEeMAY833tdmNMruPHChF5BbjH1Uq3xBvfHyQpNoSzBrh3JM+A2FAmJEaxJDWLn09JOm1Smd1uWLP7CM+t3UfawWNEBvtz1wWDue6s/kS6sCSmUkq1J1cCQiowSEQSgWysi/5VdXcSkWQgEljntC0AWAq8Zox5t87+vY0xuWINrZkH7GjxWTRhZ84JNmUV8eDsYW0ykmfhhHju+vdWvt9fyNkDY6iqsfPxthyeX7uf3XnF9O3ejYfnDOOK8fEEB3jd1A+lVCfR5NXJGFMtIncAqwBfYJExJl1EHgHSjDHLHbsuBJYYY5ybk64ApgDRInKDY9sNjhFFb4pILFaT1BbgNrecUT3eXH+QQD8fLmujDKIzR/Tm4eU7eXVdJnvyinnp6wNkF5UxuGcof7tiFHNG9cFfk9UppTo4Of363bGlpKSYtLS0Zh/39Oq9HC+r4g8XD2t65xZ6eHk6i7/LBCClfyS/mDqA85J7aF4ipZTHichGY0yTefm9ov3ijmmD2vwzbjt3AHZjmDOqD+MTdE6BUqrz8YqA0B56RQTxyNwRnq6GUkq1mDZsK6WUAjQgKKWUctCAoJRSCtCAoJRSykEDglJKKUADglJKKQcNCEoppQANCEoppRw6VeoKEckHDrbw8BigZUubdX7efO7g3efvzecO3n3+zufe3xjT5PoBnSogtIaIpLmSy6Mr8uZzB+8+f28+d/Du82/JuWuTkVJKKUADglJKKQdvCggveroCHuTN5w7eff7efO7g3eff7HP3mj4EpZRSjfOmOwSllFKN0ICglFIK8JKAICIzRGS3iGSIyH2erk97EpFMEdkuIltEpPnrj3YyIrJIRI6IyA6nbVEi8rmI7HU8R3qyjm2lgXN/WESyHb//LSIyy5N1bCsiEi8ia0Rkl4iki8ivHdu7/O++kXNv9u++y/chiIgvsAe4ELABqcBCY8xOj1asnYhIJpBijPGKyTkiMgU4CbxmjBnh2Pa/wFFjzBOOLwSRxpjfebKebaGBc38YOGmM+asn69bWRKQ30NsYs0lEwoCNwDzgBrr4776Rc7+CZv7uveEOYQKQYYzZb4ypBJYAcz1cJ9VGjDFfAUfrbJ4LvOr4+VWsP5Yup4Fz9wrGmFxjzCbHz8XALqAvXvC7b+Tcm80bAkJf4JDTaxst/MfqpAzwmYhsFJFbPV0ZD+lpjMkF648H6OHh+rS3O0Rkm6NJqcs1mdQlIgnAGGA9Xva7r3Pu0MzfvTcEBKlnW9duJzvdJGPMWGAmcLujWUF5j+eAAcBoIBf4P89Wp22JSCjwPvBfxpgTnq5Pe6rn3Jv9u/eGgGAD4p1exwE5HqpLuzPG5DiejwBLsZrQvE2eo521tr31iIfr026MMXnGmBpjjB14iS78+xcRf6wL4pvGmA8cm73id1/fubfkd+8NASEVGCQiiSISACwAlnu4Tu1CREIcnUyISAhwEbCj8aO6pOXA9Y6frweWebAu7ar2Yugwny76+xcRAV4Gdhlj/ub0Vpf/3Td07i353Xf5UUYAjuFWTwK+wCJjzOMerlK7EJEkrLsCAD/gra5+7iLyNjAVK/VvHvBH4EPgHaAfkAX8zBjT5TpfGzj3qVhNBgbIBH5e26belYjIZOBrYDtgd2z+PVZbepf+3Tdy7gtp5u/eKwKCUkqppnlDk5FSSikXaEBQSikFaEBQSinloAFBKaUUoAFBKaWUgwYEpZRSgAYEpZRSDv8fwNDAgcrar6sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model.history['accuracy'])\n",
    "plt.plot(model.history['val_accuracy'])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(model.history['loss'])\n",
    "plt.plot(model.history['val_loss'])\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine with PCA W2V and TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 100)          18780300  \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100, 128)          117248    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 18,947,086\n",
      "Trainable params: 18,947,086\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "chosen_model = keras.models.load_model('NN_LSTM.model')\n",
    "chosen_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 100)          18780300  \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 100, 128)          117248    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 64)                49408     \n",
      "=================================================================\n",
      "Total params: 18,946,956\n",
      "Trainable params: 18,946,956\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "capped_model = keras.Sequential()\n",
    "\n",
    "for layer in chosen_model.layers[:-1]:\n",
    "    capped_model.add(layer)\n",
    "    \n",
    "print(capped_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:75: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea3d2dfbe654fcba47066c3f75c40ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=160000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:80: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(120000, 100)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "### Constructing train features\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import glob\n",
    "import os\n",
    "import string\n",
    "\n",
    "#Load training file\n",
    "\n",
    "text_file = open(\"train.txt.txt\", \"r\", encoding=\"utf8\")\n",
    "lines = text_file.read().split('\\n')\n",
    "\n",
    "labels = []\n",
    "for item in lines:\n",
    "    first_four_letters = item[:10]\n",
    "    if first_four_letters == '__label__1':\n",
    "        labels.append(int(1))\n",
    "    else:\n",
    "        labels.append(int(2))\n",
    "        \n",
    "def remove_label(s):\n",
    "    return s[11:]\n",
    "lines = [remove_label(s) for s in lines]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['text'] = lines\n",
    "df['label'] = labels\n",
    "\n",
    "df = df.sample(160000)\n",
    "df = df.reset_index(drop=True)\n",
    "print(len(df))\n",
    "df.head()\n",
    "\n",
    "#Clean text\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "#lowercase and remove punctuation, remove stopwords        \n",
    "df['text'] = df['text'].str.lower()\n",
    "df['text'] = df['text'].str.replace('-', ' ')\n",
    "df['text'] = df['text'].str.split(' ')\n",
    "df['text'] = df['text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].apply(lemmatize_text)\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].str.replace('\\\\', ' ')\n",
    "\n",
    "\n",
    "#Train Word2Vec\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "text = [row.split() for row in df['text']]\n",
    "model_w2v = Word2Vec.load('model_w2v.bin')\n",
    "\n",
    "#Average Word2Vec Vectors for BOW\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "text_vec = []\n",
    "text_avg_vec = []\n",
    "count = 0\n",
    "for row in tqdm(range(len(text))):\n",
    "    [word.split(' ', 1) for word in text[row]]\n",
    "  \n",
    "    for i in range(len(text[row])):\n",
    "        try:\n",
    "            text_vec.append(model_w2v[text[row][i]])\n",
    "            count = count + 1\n",
    "        except KeyError as e:\n",
    "            text_vec.append([0]*100)\n",
    "  \n",
    "    average = np.add.reduce(text_vec)\n",
    "    if count==0:\n",
    "        count = 1\n",
    "    average = np.divide(average, count)\n",
    "    text_avg_vec.append(average)\n",
    "    text_vec = []\n",
    "    count = 0\n",
    "\n",
    "for i in range(len(text_avg_vec)):\n",
    "    if type(text_avg_vec[i]) != np.ndarray:\n",
    "        text_avg_vec[i] = np.zeros(100)\n",
    "        \n",
    "text_avg_vec = np.array(text_avg_vec).reshape(-1, 100)\n",
    "x_train = pd.DataFrame(text_avg_vec)\n",
    "\n",
    "df['label'] = df['label'] - 1\n",
    "\n",
    "y_train= np.asarray(df.label)\n",
    "        \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=40000, random_state=42)\n",
    "\n",
    "train_indices = x_train.index\n",
    "val_indices = x_val.index\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=29900)\n",
    "\n",
    "tfidf_features = tfidf.fit_transform(df['text'].loc[train_indices])\n",
    "tfidf_val = tfidf.transform(df['text'].loc[val_indices])\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "x_train = sparse.csr_matrix(x_train)\n",
    "x_val = sparse.csr_matrix(x_val)\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train = sparse.hstack([x_train, tfidf_features])\n",
    "x_val = sparse.hstack([x_val, tfidf_val])\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "max_length = 100\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    t = pickle.load(handle)\n",
    "\n",
    "encoded_docs = t.texts_to_sequences(df['text'].loc[train_indices])\n",
    "encoded_val = t.texts_to_sequences(df['text'].loc[val_indices])\n",
    "\n",
    "word_index = t.word_index\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "padded_val = pad_sequences(encoded_val, maxlen=max_length, padding='post')\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#padded_docs = np.reshape(padded_docs, (120000,100,100))\n",
    "#padded_val = np.reshape(padded_val, (40000,100,100))\n",
    "pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 100)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = np.reshape(padded_docs[0], (1,100))\n",
    "y_predict_train = capped_model.predict(pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "y_predict_train = capped_model.predict(padded_docs)\n",
    "\n",
    "y_predict_train = np.array(y_predict_train)\n",
    "\n",
    "y_predict_train = y_predict_train.reshape((120000, 64))\n",
    "y_predict_train.shape\n",
    "\n",
    "#### PCA to reduce dimensions of TFIDF\n",
    "\n",
    "#x_train_tfidf = x_train[:,100:]\n",
    "#x_train_tfidf.shape\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=200)\n",
    "\n",
    "svd_data = svd.fit_transform(x_train)\n",
    "\n",
    "svd_data.shape\n",
    "\n",
    "y_predict_train.shape\n",
    "\n",
    "#### Combine PCA result with last layer of NN\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "x_train_new = np.hstack([svd_data, y_predict_train])\n",
    "x_train_new.shape\n",
    "\n",
    "#y_train = np.argmax(y_train, axis=1)\n",
    "y_train\n",
    "\n",
    "#x_train = normalize(x_train)\n",
    "\n",
    "\n",
    "#same process to validation set\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "y_predict_val = capped_model.predict(padded_val)\n",
    "\n",
    "y_predict_val = np.array(y_predict_val)\n",
    "\n",
    "#x_val_tfidf = x_val[:,100:]\n",
    "\n",
    "svd_data_val = svd.transform(x_val)\n",
    "\n",
    "y_predict_val = y_predict_val.reshape((40000, 64))\n",
    "\n",
    "x_val_new = np.hstack([svd_data_val, y_predict_val])\n",
    "\n",
    "#y_val = np.argmax(y_val, axis=1)\n",
    "y_val\n",
    "\n",
    "#y_val = np.argmax(y_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8949916666666666\n",
      "0.892725\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression(random_state=42, max_iter=8000)\n",
    "\n",
    "log_model.fit(x_train_new, y_train)\n",
    "\n",
    "print(log_model.score(x_train_new, y_train))\n",
    "print(log_model.score(x_val_new, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8927333333333334\n",
      "0.89325\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=5)\n",
    "\n",
    "rf.fit(x_train_new, y_train)\n",
    "\n",
    "print(rf.score(x_train_new, y_train))\n",
    "print(rf.score(x_val_new, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9078\n",
      "0.893225\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=10)\n",
    "\n",
    "rf.fit(x_train_new, y_train)\n",
    "\n",
    "print(rf.score(x_train_new, y_train))\n",
    "print(rf.score(x_val_new, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999833333333333\n",
      "0.892425\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "rf.fit(x_train_new, y_train)\n",
    "\n",
    "print(rf.score(x_train_new, y_train))\n",
    "print(rf.score(x_val_new, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense net output + RNN output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 128)               3840128   \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 2)                 514       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 4,042,882\n",
      "Trainable params: 4,040,578\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "chosen_model = keras.models.load_model('NN3.model')\n",
    "\n",
    "chosen_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_64 (Dense)             (None, 128)               3840128   \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 256)               65792     \n",
      "=================================================================\n",
      "Total params: 4,041,344\n",
      "Trainable params: 4,039,552\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b496c8d776643db8a8114f71340fbe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=120000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fba454424324ff5ba7b3616e777d3cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dense net output + RNN output\n",
    "\n",
    "capped_model = keras.Sequential()\n",
    "\n",
    "for layer in chosen_model.layers[:-4]:\n",
    "    capped_model.add(layer)\n",
    "    \n",
    "capped_model.summary()\n",
    "\n",
    "x_train = x_train.tocsr()\n",
    "x_val = x_val.tocsr()\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "y_predict_train_dense = []\n",
    "\n",
    "for i in tqdm(range(x_train.shape[0])):\n",
    "    array = x_train[i].toarray()\n",
    "    prediction = capped_model.predict(array)\n",
    "    y_predict_train_dense.append(prediction)\n",
    "\n",
    "y_predict_train_dense = np.array(y_predict_train_dense)\n",
    "\n",
    "y_predict_train_dense = y_predict_train_dense.reshape((120000, 256))\n",
    "\n",
    "x_train_new_2 = np.hstack([y_predict_train_dense, y_predict_train])\n",
    "\n",
    "#same process to validation set\n",
    "\n",
    "y_predict_val_dense = []\n",
    "\n",
    "for i in tqdm(range(x_val.shape[0])):\n",
    "    array = x_val[i].toarray()\n",
    "    prediction = capped_model.predict(array)\n",
    "    y_predict_val_dense.append(prediction)\n",
    "\n",
    "y_predict_val_dense = np.array(y_predict_val_dense)\n",
    "\n",
    "y_predict_val_dense = y_predict_val_dense.reshape((40000, 256))\n",
    "\n",
    "x_val_new_2 = np.hstack([y_predict_val_dense, y_predict_val])\n",
    "\n",
    "#y_val = np.argmax(y_val, axis=1)\n",
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8929166666666667\n",
      "0.8917\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression(random_state=42, max_iter=8000)\n",
    "\n",
    "log_model.fit(x_train_new_2, y_train)\n",
    "\n",
    "print(log_model.score(x_train_new_2, y_train))\n",
    "print(log_model.score(x_val_new_2, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2ae5c8f4964e1f9d43df5c0bffddc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=160000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:81: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(120000, 30000)\n"
     ]
    }
   ],
   "source": [
    "### Constructing train features\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import glob\n",
    "import os\n",
    "import string\n",
    "\n",
    "#Load training file\n",
    "\n",
    "text_file = open(\"train.txt.txt\", \"r\", encoding=\"utf8\")\n",
    "lines = text_file.read().split('\\n')\n",
    "\n",
    "labels = []\n",
    "for item in lines:\n",
    "    first_four_letters = item[:10]\n",
    "    if first_four_letters == '__label__1':\n",
    "        labels.append(int(1))\n",
    "    else:\n",
    "        labels.append(int(2))\n",
    "        \n",
    "def remove_label(s):\n",
    "    return s[11:]\n",
    "lines = [remove_label(s) for s in lines]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['text'] = lines\n",
    "df['label'] = labels\n",
    "\n",
    "df = df.sample(160000)\n",
    "print(len(df))\n",
    "df.head()\n",
    "\n",
    "#Clean text\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "#lowercase and remove punctuation, remove stopwords        \n",
    "df['text'] = df['text'].str.lower()\n",
    "df['text'] = df['text'].str.replace('-', ' ')\n",
    "df['text'] = df['text'].str.split(' ')\n",
    "df['text'] = df['text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].apply(lemmatize_text)\n",
    "df['text'] = df['text'].apply(', '.join)\n",
    "df['text'] = df['text'].str.replace('[{}]'.format(string.punctuation), '')\n",
    "df['text'] = df['text'].str.replace('\\\\', ' ')\n",
    "\n",
    "\n",
    "#Train Word2Vec\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "text = [row.split() for row in df['text']]\n",
    "model_w2v = Word2Vec(text)\n",
    "\n",
    "model_w2v.save('model_w2v.bin')\n",
    "\n",
    "#Average Word2Vec Vectors for BOW\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "text_vec = []\n",
    "text_avg_vec = []\n",
    "count = 0\n",
    "for row in tqdm(range(len(text))):\n",
    "    [word.split(' ', 1) for word in text[row]]\n",
    "  \n",
    "    for i in range(len(text[row])):\n",
    "        try:\n",
    "            text_vec.append(model_w2v[text[row][i]])\n",
    "            count = count + 1\n",
    "        except KeyError as e:\n",
    "            text_vec.append([0]*100)\n",
    "  \n",
    "    average = np.add.reduce(text_vec)\n",
    "    if count==0:\n",
    "        count = 1\n",
    "    average = np.divide(average, count)\n",
    "    text_avg_vec.append(average)\n",
    "    text_vec = []\n",
    "    count = 0\n",
    "\n",
    "for i in range(len(text_avg_vec)):\n",
    "    if type(text_avg_vec[i]) != np.ndarray:\n",
    "        text_avg_vec[i] = np.zeros(100)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=29900)\n",
    "\n",
    "tfidf_features = tfidf.fit_transform(df['text'])\n",
    "\n",
    "x_train = text_avg_vec\n",
    "x_train = np.array(x_train).reshape(-1, 100)\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "x_train = sparse.csr_matrix(x_train)\n",
    "x_train.shape\n",
    "\n",
    "x_train = sparse.hstack([x_train, tfidf_features])\n",
    "x_train.shape\n",
    "\n",
    "df['label'] = df['label'] - 1\n",
    "\n",
    "y_train= np.asarray(df.label)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=40000, random_state=42)\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "#print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size, shuffle):\n",
    "    number_of_batches = X.shape[0]/batch_size\n",
    "    counter = 0\n",
    "    sample_index = np.arange(X.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(sample_index)\n",
    "    while True:\n",
    "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
    "        X_batch = X[batch_index,:].toarray()\n",
    "        X_batch = np.reshape(X_batch, (X_batch.shape[0], X_batch.shape[1], 1))\n",
    "        y_batch = y[batch_index]\n",
    "        counter += 1\n",
    "        yield X_batch, y_batch\n",
    "        if (counter == number_of_batches):\n",
    "            if shuffle:\n",
    "                np.random.shuffle(sample_index)\n",
    "            counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 30000)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_val = x_val.toarray()\n",
    "x_val = np.reshape(x_val, (x_val.shape[0], x_val.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\danie\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=2, dtype='int32')\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes=2, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\danie\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 29998, 32)         128       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 29996, 32)         3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 14998, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 14996, 64)         6208      \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 14994, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 7497, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 7495, 128)         24704     \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 7493, 128)         49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 3746, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 3744, 256)         98560     \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 3742, 256)         196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 748, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 191488)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 191488)            765952    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               38297800  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 39,475,254\n",
      "Trainable params: 39,092,278\n",
      "Non-trainable params: 382,976\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CNN Training\n",
    "\n",
    "shape = (x_train.shape[1], 1)\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv1D(32, kernel_size=3, activation='relu', input_shape=shape))\n",
    "model.add(keras.layers.Conv1D(32, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(keras.layers.MaxPooling1D(pool_size=2))\n",
    "          \n",
    "model.add(keras.layers.Conv1D(64, kernel_size=3, activation='relu'))\n",
    "model.add(keras.layers.Conv1D(64, kernel_size=3, activation='relu'))\n",
    "          \n",
    "model.add(keras.layers.MaxPooling1D(pool_size=2))\n",
    "          \n",
    "model.add(keras.layers.Conv1D(128, kernel_size=3, activation='relu'))\n",
    "model.add(keras.layers.Conv1D(128, kernel_size=3, activation='relu'))\n",
    "          \n",
    "model.add(keras.layers.MaxPooling1D(pool_size=2))\n",
    "          \n",
    "model.add(keras.layers.Conv1D(256, kernel_size=3, activation='relu'))\n",
    "model.add(keras.layers.Conv1D(256, kernel_size=3, activation='relu'))\n",
    "          \n",
    "model.add(keras.layers.MaxPooling1D(pool_size=5))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "          \n",
    "model.add(keras.layers.Dense(200, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(2, activation='relu'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"CNN.model\", monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " 680/3750 [====>.........................] - ETA: 2:01:38 - loss: 0.7412 - accuracy: 0.7585"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-126e786e1330>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model1 = model.fit_generator(generator=batch_generator(x_train, y_train, 32, True), validation_data=(x_val, y_val), steps_per_epoch=(x_train.shape[0])/32,epochs=25)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Full.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
